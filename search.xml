<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[PLSQL Developer乱码解决]]></title>
    <url>%2Fposts%2F7c1a91cc.html</url>
    <content type="text"><![CDATA[查编码1select userenv('language') from dual Window环境变量1234567GBK编码：NLS_LANG=CHINESE_CHINA.ZHS16GBK或者NLS_LANG=AMERICAN_AMERICA.ZHS16GBKUTF-8编码：NLS_LANG=AMERICAN_AMERICA.AL32UTF8]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>PLSQL Developer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[硬盘挂载和扩容]]></title>
    <url>%2Fposts%2F9d08c77f.html</url>
    <content type="text"><![CDATA[挂载查看磁盘列表1sudo fdisk -l 格式化磁盘查看系统支持的文件系统格式1sudo cat /etc/filesystems 据结果进行格式化1sudo mkfs.xfs /dev/sdc 永久挂载磁盘123sudo vim /etc/fstab/dev/sdc /app xfs defaults 0 0 即时生效挂载信息1sudo mount -a 取消挂载1sudo umount /dev/sdc 扩容PV 物理卷1234[yl@app ~]$ sudo pvs PV VG Fmt Attr PSize PFree /dev/sda2 centos lvm2 a-- &lt;48.00g 4.00m /dev/sdb vg_data lvm2 a-- &lt;50.00g 0 VG 卷组：卷组是用来管理物理卷的集合1234[yl@app ~]$ sudo vgs VG #PV #LV #SN Attr VSize VFree centos 1 2 0 wz--n- &lt;48.00g 4.00m vg_data 1 1 0 wz--n- &lt;50.00g 0 LV 逻辑卷12345[yl@app ~]$ sudo lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert root centos -wi-ao---- 45.99g swap centos -wi-ao---- 2.00g lv_data vg_data -wi-ao---- &lt;50.00g 挂载 LV 逻辑卷创建 LV 逻辑卷的文件系统1mkfs.xfs /dev/vg_data/lv_data 创建挂载目录1mkdir /data 挂载1mount /dev/vg_data/lv_data /data df -h查询是否挂载信息1/dev/mapper/vg_data-lv_data 52399108 31733300 20665808 61% /data 新硬盘，创建 PV 物理卷1sudo pvcreate /dev/sdc 扩容 VG 卷组1sudo vgextend vg_data /dev/sdc 扩容 LV 卷 扩容指定空间到 LV 12# -r 选项一定要加，这样可以将逻辑卷和文件系统一起扩容sudo lvextend -r -L +100G /dev/vg_data/lv_data 扩容剩余全部空间 1sudo lvextend -r -l +100%FREE /dev/vg_data/lv_data]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>挂载</tag>
        <tag>扩容</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[H5 加载小程序标签]]></title>
    <url>%2Fposts%2F9b163e06.html</url>
    <content type="text"><![CDATA[使用 rem 单位问题需要在小程序标签里面指定以下样式 1234567html &#123; font-size: 50px;&#125;.text &#123; font-size: .26rem;&#125; 可以通过以下代码，可以动态获取页面 html 标签上的 font-size 值，小程序标签里面 html 的 font-size 应该要和页面的保持一致 123var docEl = window.document.documentElement;// 在使用 rem 的情况下，获取页面 html 标签上的 font-size 值var fontSize = parseFloat(window.getComputedStyle(docEl)["font-size"]); 动态加载小程序标签问题进入页面的时候，调用wx.config初始化小程序标签。如果页面需要通过 js 动态加载小程序标签，需要在每次加载前都调用wx.config初始化配置，否则会报错，导致动态加载的小程序标签无法正常显示。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586var config;function wxJsApiInit() &#123; if (config) &#123; wx.config(config); &#125; else &#123; $.post('获取 jsticket 接口', &#123; url: window.location.href &#125;, function (data) &#123; if (0 === data.errcode) &#123; config = &#123; // 必填，公众号的唯一标识 appId: '后端返回的 appId', // 必填，生成签名的时间戳 timestamp: '后端返回的 timestamp', // 必填，生成签名的随机串 nonceStr: '后端返回的 nonceStr', // 必填，签名 signature: '后端返回的 signature', // 必填，需要使用的JS接口列表，所有JS接口列表见附录2 jsApiList: [ 'chooseImage', 'onMenuShareTimeline', 'onMenuShareAppMessage' ], // 小程序标签 openTagList: ['wx-open-launch-weapp'] &#125; // 初始化配置 wx.config(config); &#125; &#125;, 'json'); &#125;&#125;$(function () &#123; wxJsApiInit();&#125;);function search() &#123; $.get('搜索接口获取小程序数据', function (data) &#123; var item = data.item; var html = miniapp(item.username, miniapp.path, miniapp.name); // 动态添加小程序到页面，需要重新 wx.config 初始化 wxJsApiInit(); $('#miniapp_1').html(html); &#125;);&#125;/** * 拼接小程序 html 代码 * @param username 需要打开的小程序账号 * @param path 需要打开的小程序路径 * @param name 小程序标签展示的名称 * @returns &#123;string&#125; */function miniapp(username, path, name) &#123; var docEl = window.document.documentElement; // 在使用 rem 的情况下，获取页面 html 标签上的 font-size 值 var fontSize = parseFloat(window.getComputedStyle(docEl)["font-size"]); return '&lt;wx-open-launch-weapp username="' + username + '" path="' + path + '" style="display:block; width: 60px"&gt;' + ' &lt;template&gt;' + ' &lt;style&gt;' + ' html &#123;' + ' font-size: ' + fontSize + 'px' + ' &#125;' + ' html,' + ' body &#123;' + ' margin: 0;' + ' padding: 0;' + ' border: 0;' + ' outline: 0;' + ' font-weight: inherit;' + ' font-style: inherit;' + ' font-family: "Microsoft YaHei", simsun, Arial, Helvetica, sans-serif;' + ' vertical-align: baseline;' + ' text-align: center;' + ' &#125;' + ' * &#123;' + ' color: #fff;' + ' font-size: .26rem;' + ' font-weight: normal;' + ' &#125;' + ' &lt;/style&gt;' + name + ' &lt;/template&gt;' + '&lt;/wx-open-launch-weapp&gt;';&#125;]]></content>
      <categories>
        <category>微信公众号</category>
      </categories>
      <tags>
        <tag>小程序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tinymce 解决微信公众号图文消息图片跨域问题]]></title>
    <url>%2Fposts%2Fc3440175.html</url>
    <content type="text"><![CDATA[原理 原理是把请求头的referer去掉。 某些场景HTML文件增加&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot; /&gt;也可以解决跨域问题。 思路 通过Nginx反向代理微信图片的链接，并把请求的 referer 去掉。 Nginx反向代理 1234567891011121314server &#123; listen 8810; server_name localhost; # 指定字符集为 UTF-8 charset utf-8; # https://mmbiz.qpic.cn/mmbiz_gif/NefTdbK1pb3a06nvwCX5ROeNSsd2DVOGfwAEGgpT94ZnqlYNZgvEJTU9MVU7ExGAVCpWo3rIpU7rfA71PzKaJg/640?wx_fmt=gif location ~ /mmbiz_(.*)/ &#123; proxy_pass https://mmbiz.qpic.cn; proxy_set_header Host &quot;mmbiz.qpic.cn&quot;; proxy_set_header Referer &quot;&quot;; &#125;&#125; 访问地址 http://localhost:8810/mmbiz_gif/NefTdbK1pb3a06nvwCX5ROeNSsd2DVOGfwAEGgpT94ZnqlYNZgvEJTU9MVU7ExGAVCpWo3rIpU7rfA71PzKaJg/640?wx_fmt=gif]]></content>
      <categories>
        <category>tinymce</category>
      </categories>
      <tags>
        <tag>微信公众号</tag>
        <tag>tinymce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OkHttp 池配置]]></title>
    <url>%2Fposts%2Fc17653b2.html</url>
    <content type="text"><![CDATA[Dispatcher 调度 内部执行 http 请求的实际线程池 每一个OkHttpClient 实例将请求 Call 使用 Dispatcher 进行线程分发，在 Dispatcher 中通过 ExecutorService 线程池来执行每一个请求的。 初始化 12345Dispatcher dispatcher = new Dispatcher();// Dispatcher dispatcher = new Dispatcher(Executors.newCachedThreadPool());dispatcher.setMaxRequests(64);dispatcher.setMaxRequestsPerHost(4);builder.dispatcher(dispatcher); 主要参数说明 参数 描述 备注 maxRequests 当前 OkHttpClient 实例最大的并发请求数 默认：64。这个值一般要大于maxRequestPerHost。 maxRequestPerHost 单个主机最大请求并发数，这里的主机指被请求方主机，一般可以理解对调用方有限流作用 默认：4这个值设置，有如下几个场景考虑：- 如果被调用方的并发能力只能支持100，那这个值最好不要超过100，否则对调用方有压力- 如果当前 OkHttpClient 实例只对一个调用方发起调用，那这个值与 maxRequests 保持一致- 如果当前 OkHttpClient 实例在一个事务中对 n 个调用方发起调用，n * maxReuestPerHost 要接近 maxRequest executorService 构造参数：内部线程池 可根据情况自定义线程池 executorService 默认初始化代码 123456public synchronized ExecutorService executorService() &#123; if (executorService == null) &#123; executorService = new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), Util.threadFactory("OkHttp Dispatcher", false)); &#125; return executorService;&#125; ConnectionPool 连接池1）从 ConnectionPool 获取一个 RealConnection 对象，如果缓冲池里面没有就创建一个 RealConnection 对象并且放入 ConnectionPool 中，实际是放入 ConnectionPool 的 ArrayDeque 队列中 2）获取 RealConnection 对象后调用其 connect 打开 Socket 链接]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>OkHttp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[oracledb_exporter 监控使用]]></title>
    <url>%2Fposts%2F65c8c0a4.html</url>
    <content type="text"><![CDATA[参数说明oracledb_up 数据库状态 “text”: “DEAD”, “value”: “0” “text”: “ALIVE”, “value”: “1”oracledb_exporter_scrapes_total 总收集oracledb_activity_execute_count 执行计数oracledb_activity_user_commits 用户提交数oracledb_tablespace_free 表空间状态oracledb_sessions_value 活动会话oracledb_exporter_last_scrape_duration_seconds 最后收集用时oracledb_process_count 进程计数oracledb_activity_user_rollbacks 用户回滚oracledb_wait_time_concurrency 并发等待时间oracledb_wait_time_commit 提交等待时间oracledb_wait_time_application 应用等待oracledb_wait_time_network 网络等待oracledb_resource_current_utilization 资源利用率oracledb_wait_time_system_io 系统I/O等待oracledb_wait_time_user_io 用户I/O等待oracledb_wait_time_configuration 组态等待时间oracledb_wait_time_scheduler Scheduler 等待时间]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>exporter</tag>
        <tag>prometheus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java、Oracle 的 DES 加解密方式互转]]></title>
    <url>%2Fposts%2F5145849a.html</url>
    <content type="text"><![CDATA[本文主要实现Oracle DES加解密和Java DES加解密的互转。 Oracle 加解密实现包定义1234567891011CREATE OR REPLACE PACKAGE WX_CRYPTO IS -- 定义 DES encrypt 函数 FUNCTION DES_ENCRYPT(INPUT_STRING IN VARCHAR2) RETURN VARCHAR2; FUNCTION DES_ENCRYPT(INPUT_STRING IN VARCHAR2, KEY_STRING IN VARCHAR2) RETURN VARCHAR2; -- 定义 DES decrypt 函数 FUNCTION DES_DECRYPT(INPUT_STRING IN VARCHAR2) RETURN VARCHAR2 DETERMINISTIC; FUNCTION DES_DECRYPT(INPUT_STRING IN VARCHAR2, KEY_STRING IN VARCHAR2) RETURN VARCHAR2 DETERMINISTIC;END WX_CRYPTO; 包体定义123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869CREATE OR REPLACE PACKAGE BODY WX_CRYPTO IS -- 实现 DES encrypt 函数（一个参数） FUNCTION DES_ENCRYPT(INPUT_STRING IN VARCHAR2 -- 明文 ) RETURN VARCHAR2 AS BEGIN RETURN WX_CRYPTO.DES_ENCRYPT(INPUT_STRING =&gt; INPUT_STRING, KEY_STRING =&gt; '12345678'); END; -- 实现 DES encrypt 函数（两个参数） FUNCTION DES_ENCRYPT(INPUT_STRING IN VARCHAR2, -- 明文 KEY_STRING IN VARCHAR2 -- 密钥 ) RETURN VARCHAR2 AS V_TEXT VARCHAR2(4000); -- 明文。长度要是 8 的倍数，若不足 8 的倍数，则用隐藏字符串 chr(0) 补足 V_TEXT_RAW RAW(2048); -- 明文 V_KEY_RAW RAW(128); -- 密钥 V_ENCRYPT_RAW RAW(2048); -- 加密后的字符串 BEGIN IF INPUT_STRING IS NULL THEN RETURN NULL; END IF; IF INSTR(INPUT_STRING, '&#123;DES&#125;') = 1 THEN RETURN INPUT_STRING; END IF; -- 向右补足。CHR(0) 隐藏字符串 V_TEXT := RPAD(INPUT_STRING, (TRUNC(LENGTHB(INPUT_STRING) / 8) + 1) * 8, CHR(0)); -- 转换成 16 进制 V_TEXT_RAW := SYS.UTL_I18N.STRING_TO_RAW(V_TEXT, 'ZHS16GBK'); V_KEY_RAW := SYS.UTL_I18N.STRING_TO_RAW(KEY_STRING, 'ZHS16GBK'); V_ENCRYPT_RAW := SYS.DBMS_OBFUSCATION_TOOLKIT.DESENCRYPT(INPUT =&gt; V_TEXT_RAW, KEY =&gt; V_KEY_RAW); RETURN '&#123;DES&#125;' || RAWTOHEX(V_ENCRYPT_RAW); END; -- 实现 DES decrypt 函数（一个参数） FUNCTION DES_DECRYPT(INPUT_STRING IN VARCHAR2 -- 明文 ) RETURN VARCHAR2 DETERMINISTIC AS BEGIN RETURN WX_CRYPTO.DES_DECRYPT(INPUT_STRING =&gt; INPUT_STRING, KEY_STRING =&gt; '12345678'); END; -- 实现 DES decrypt 函数（两个参数） FUNCTION DES_DECRYPT(INPUT_STRING IN VARCHAR2, -- 密文 KEY_STRING IN VARCHAR2 -- 密钥 ) RETURN VARCHAR2 DETERMINISTIC AS V_TEXT_RAW RAW(2048); -- 密文 V_KEY_RAW RAW(128); -- 密钥 V_DECRYPT_RAW RAW(2048); -- 解密后的明文 V_DECRYPT_STRING VARCHAR2(4000); -- 解密后的明文 BEGIN IF INPUT_STRING IS NULL THEN RETURN NULL; END IF; IF INSTR(INPUT_STRING, '&#123;DES&#125;') = 1 THEN V_TEXT_RAW := HEXTORAW(SUBSTR(INPUT_STRING, 6)); -- 转换成 16 进制 V_KEY_RAW := SYS.UTL_I18N.STRING_TO_RAW(KEY_STRING, 'ZHS16GBK'); -- 解密 V_DECRYPT_RAW := SYS.DBMS_OBFUSCATION_TOOLKIT.DESDECRYPT(INPUT =&gt; V_TEXT_RAW, KEY =&gt; V_KEY_RAW); -- RAW_TO_CHAR 转换成字符串 V_DECRYPT_STRING := SYS.UTL_I18N.RAW_TO_CHAR(V_DECRYPT_RAW, 'ZHS16GBK'); -- RTRIM 去除字符串右侧的隐藏字符串 CHR(0) RETURN RTRIM(V_DECRYPT_STRING, CHR(0)); END IF; RETURN INPUT_STRING; END;END WX_CRYPTO; 注意： 1、sql中默认密钥为12345678 2、加密后会加上：{DES}前缀；解密的时候会用SUBSTR掉截取掉{DES}前缀 JAVA 加解密实现DES 工具类实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122import javax.crypto.BadPaddingException;import javax.crypto.Cipher;import javax.crypto.IllegalBlockSizeException;import javax.crypto.NoSuchPaddingException;import javax.crypto.SecretKey;import javax.crypto.SecretKeyFactory;import javax.crypto.spec.DESKeySpec;import javax.crypto.spec.IvParameterSpec;import java.io.UnsupportedEncodingException;import java.security.InvalidAlgorithmParameterException;import java.security.InvalidKeyException;import java.security.NoSuchAlgorithmException;import java.security.spec.InvalidKeySpecException;import java.util.ArrayList;import java.util.Arrays;import java.util.List;/** * Oracle des 加解密 java 实现 * * @author YL */public class Des &#123; private static String ALGORITHM_1 = "DES"; private static String ALGORITHM_2 = "DES/CBC/NoPadding"; private static String CHARSET = "gbk"; /** * 加密 * * @param str 原始字符 * @param key 加密 key */ public static String encrypt(String str, String key) &#123; try &#123; DESKeySpec desKey = new DESKeySpec(key.getBytes(CHARSET)); SecretKey secretKey = SecretKeyFactory.getInstance(ALGORITHM_1).generateSecret(desKey); Cipher cipher = Cipher.getInstance(ALGORITHM_2); cipher.init(Cipher.ENCRYPT_MODE, secretKey, new IvParameterSpec(new byte[8])); byte[] bytes = str.getBytes(CHARSET); System.out.println("src ---&gt; " + Arrays.toString(bytes)); byte[] inBytes = new byte[((bytes.length / 8) + 1) * 8]; for (int i = 0; i &lt; bytes.length; i++) &#123; inBytes[i] = bytes[i]; &#125; System.out.println("inBytes ---&gt; " + Arrays.toString(inBytes)); byte[] eBytes = cipher.doFinal(inBytes); String hexStr = HexUtils.encodeHexString(eBytes, false); System.out.println(str + " encrypted (hex) :" + hexStr); return hexStr; &#125; catch (InvalidKeyException e) &#123; throw new RRException(e.getMessage(), -99, e); &#125; catch (InvalidKeySpecException e) &#123; throw new RRException(e.getMessage(), -99, e); &#125; catch (NoSuchAlgorithmException e) &#123; throw new RRException(e.getMessage(), -99, e); &#125; catch (BadPaddingException e) &#123; throw new RRException(e.getMessage(), -99, e); &#125; catch (InvalidAlgorithmParameterException e) &#123; throw new RRException(e.getMessage(), -99, e); &#125; catch (NoSuchPaddingException e) &#123; throw new RRException(e.getMessage(), -99, e); &#125; catch (IllegalBlockSizeException e) &#123; throw new RRException(e.getMessage(), -99, e); &#125; catch (UnsupportedEncodingException e) &#123; throw new RRException(e.getMessage(), -99, e); &#125; &#125; /** * 解密 * * @param str 加密字符 * @param key 解密 key */ public static String decrypt(String str, String key) &#123; try &#123; DESKeySpec desKey = new DESKeySpec(key.getBytes(CHARSET)); SecretKey secretKey = SecretKeyFactory.getInstance(ALGORITHM_1).generateSecret(desKey); Cipher cipher = Cipher.getInstance(ALGORITHM_2); cipher.init(Cipher.DECRYPT_MODE, secretKey, new IvParameterSpec(new byte[8])); byte[] bytes = HexUtils.decodeHex(str); byte[] dBytes = cipher.doFinal(bytes); System.out.println("decryptBytes ---&gt; " + Arrays.toString(dBytes)); List&lt;Byte&gt; list = new ArrayList&lt;&gt;(); for (byte dByte : dBytes) &#123; if (dByte != 0) &#123; list.add(dByte); &#125; &#125; byte[] copy = new byte[list.size()]; for (int i = 0; i &lt; list.size(); i++) &#123; copy[i] = list.get(i); &#125; return new String(copy, CHARSET); &#125; catch (InvalidKeyException e) &#123; throw new RRException(e.getMessage(), -99, e); &#125; catch (InvalidKeySpecException e) &#123; throw new RRException(e.getMessage(), -99, e); &#125; catch (NoSuchAlgorithmException e) &#123; throw new RRException(e.getMessage(), -99, e); &#125; catch (BadPaddingException e) &#123; throw new RRException(e.getMessage(), -99, e); &#125; catch (InvalidAlgorithmParameterException e) &#123; throw new RRException(e.getMessage(), -99, e); &#125; catch (NoSuchPaddingException e) &#123; throw new RRException(e.getMessage(), -99, e); &#125; catch (IllegalBlockSizeException e) &#123; throw new RRException(e.getMessage(), -99, e); &#125; catch (UnsupportedEncodingException e) &#123; throw new RRException(e.getMessage(), -99, e); &#125; &#125;&#125; HexUtils 工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146/** * hex 编码 * * @author YL */public abstract class HexUtils &#123; private HexUtils() &#123;&#125; /** * Used to build output as Hex */ private static final char[] DIGITS_LOWER = &#123;'0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f'&#125;; /** * Used to build output as Hex */ private static final char[] DIGITS_UPPER = &#123;'0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F'&#125;; /** * 将表示十六进制值的String转换为这些相同值的字节数组 * * @param data 十六进制数字的字符串 * * @return 包含从提供的char数组解码的二进制数据的字节数组 */ public static byte[] decodeHex(final String data) &#123; return decodeHex(data.toCharArray()); &#125; /** * 将表示十六进制值的字符数组转换为这些相同值的字节数组 * * @param data 十六进制数字的字符数组 * * @return 包含从提供的char数组解码的二进制数据的字节数组 */ public static byte[] decodeHex(final char[] data) &#123; final int len = data.length; if ((len &amp; 0x01) != 0) &#123; throw new IllegalArgumentException("Odd number of characters."); &#125; final byte[] out = new byte[len &gt;&gt; 1]; // two characters form the hex value. for (int i = 0, j = 0; j &lt; len; i++) &#123; int f = toDigit(data[j], j) &lt;&lt; 4; j++; f = f | toDigit(data[j], j); j++; out[i] = (byte) (f &amp; 0xFF); &#125; return out; &#125; /** * 将字节数组转换为字符数组，按顺序表示每个字节的十六进制值 * * @param data 需要转换为十六进制字符数组的 byte 数组 * * @return 十六进制字符数组 */ public static char[] encodeHex(final byte[] data) &#123; return encodeHex(data, true); &#125; /** * Converts an array of bytes into an array of characters representing the hexadecimal values of each byte in order. * The returned array will be double the length of the passed array, as it takes two characters to represent any * given byte. * * @param data a byte[] to convert to Hex characters * @param toLowerCase &lt;code&gt;true&lt;/code&gt; converts to lowercase, &lt;code&gt;false&lt;/code&gt; to uppercase * * @return A char[] containing hexadecimal characters in the selected case */ public static char[] encodeHex(final byte[] data, final boolean toLowerCase) &#123; return encodeHex(data, toLowerCase ? DIGITS_LOWER : DIGITS_UPPER); &#125; /** * Converts an array of bytes into an array of characters representing the hexadecimal values of each byte in order. * The returned array will be double the length of the passed array, as it takes two characters to represent any * given byte. * * @param data a byte[] to convert to Hex characters * @param toDigits the output alphabet (must contain at least 16 chars) * * @return A char[] containing the appropriate characters from the alphabet * For best results, this should be either upper- or lower-case hex. */ private static char[] encodeHex(final byte[] data, final char[] toDigits) &#123; final int l = data.length; final char[] out = new char[l &lt;&lt; 1]; // two characters form the hex value. for (int i = 0, j = 0; i &lt; l; i++) &#123; out[j++] = toDigits[(0xF0 &amp; data[i]) &gt;&gt;&gt; 4]; out[j++] = toDigits[0x0F &amp; data[i]]; &#125; return out; &#125; /** * Converts an array of bytes into a String representing the hexadecimal values of each byte in order. The returned * String will be double the length of the passed array, as it takes two characters to represent any given byte. * * @param data a byte[] to convert to Hex characters * * @return A String containing lower-case hexadecimal characters */ public static String encodeHexString(final byte[] data) &#123; return encodeHexString(data, true); &#125; /** * Converts an array of bytes into a String representing the hexadecimal values of each byte in order. The returned * String will be double the length of the passed array, as it takes two characters to represent any given byte. * * @param data a byte[] to convert to Hex characters * @param toLowerCase &lt;code&gt;true&lt;/code&gt; converts to lowercase, &lt;code&gt;false&lt;/code&gt; to uppercase * * @return A String containing lower-case hexadecimal characters */ public static String encodeHexString(final byte[] data, final boolean toLowerCase) &#123; return new String(encodeHex(data, toLowerCase)); &#125; /** * Converts a hexadecimal character to an integer. * * @param ch A character to convert to an integer digit * @param index The index of the character in the source * * @return An integer */ private static int toDigit(final char ch, final int index) &#123; final int digit = Character.digit(ch, 16); if (digit == -1) &#123; throw new IllegalArgumentException("Illegal hexadecimal character " + ch + " at index " + index); &#125; return digit; &#125;&#125; 测试 Oracle 12345678910111213141516171819-- Oracle 加密SELECT WX_CRYPTO.DES_ENCRYPT('测试123！@#。【】[] ', '7agyrpho') FROM DUAL;-- 输出&#123;DES&#125;EBD9F4F8AC29DDFCD74FD951A2B84F064D5CD6976143B08644AC7B62569BB4E6-- Oracle 解密SELECT WX_CRYPTO.DES_DECRYPT('&#123;DES&#125;EBD9F4F8AC29DDFCD74FD951A2B84F064D5CD6976143B08644AC7B62569BB4E6', '7agyrpho') FROM DUAL;-- 输出测试123！@#。【】[] -- Oracle 解密 Java 的密文SELECT WX_CRYPTO.DES_DECRYPT('&#123;DES&#125;EBD9F4F8AC29DDFCD74FD951A2B84F064D5CD6976143B086', '7agyrpho') FROM DUAL;-- 输出测试123！@#。【】[] Java 12345678910111213141516171819202122232425import org.junit.Test;public class DesTest &#123; @Test public void test() &#123; String str = "测试123！@#。【】[] "; String key = "7agyrpho"; // Java 加密 String ee = Des.encrypt(str, key); System.out.println("ee ---&gt; " + ee); // Java 解密 String dd = Des.decrypt(ee, key); System.out.println("dd ---&gt; " + dd); &#125;&#125;// 日志输出ee ---&gt; EBD9F4F8AC29DDFCD74FD951A2B84F064D5CD6976143B086dd ---&gt; 测试123！@#。【】[] // Java 解密 Oracle 的密文String dd = Des.decrypt("EBD9F4F8AC29DDFCD74FD951A2B84F064D5CD6976143B08644AC7B62569BB4E6", "7agyrpho");System.out.println("dd ---&gt; " + dd);// 日志输出dd ---&gt; 测试123！@#。【】[]]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
        <tag>DES</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle 批量修改字段长度]]></title>
    <url>%2Fposts%2F246b5f2e.html</url>
    <content type="text"><![CDATA[Oracle不同字符集导入导出GBK导入UTF8：GBK字符集（一个汉字占用两位），UTF8字符集（一个汉子占用三位） 修改 varchar2 类型长度 123456789101112131415161718CREATE OR REPLACE PROCEDURE m_varchar2 AS CURSOR TEMP IS SELECT TABLE_NAME, COLUMN_NAME, CEIL(DATA_LENGTH * 3 / 2) DATA_LENGTH FROM USER_TAB_COLUMNS WHERE DATA_TYPE = 'VARCHAR2' AND DATA_LENGTH &lt; 2000; STR VARCHAR2(500) := '';BEGIN DBMS_OUTPUT.ENABLE(1000000); FOR S IN TEMP LOOP STR := 'ALTER TABLE ' || S.TABLE_NAME || ' MODIFY(' || S.COLUMN_NAME || ' VARCHAR2(' || S.DATA_LENGTH || '))'; DBMS_OUTPUT.PUT_LINE(STR); EXECUTE IMMEDIATE STR; END LOOP;END; 执行 1call m_varchar2(); 修改 char 类型长度 123456789101112131415161718CREATE OR REPLACE PROCEDURE m_char AS CURSOR TEMP IS SELECT TABLE_NAME, COLUMN_NAME, CEIL(DATA_LENGTH * 3 / 2) DATA_LENGTH FROM USER_TAB_COLUMNS WHERE DATA_TYPE = 'CHAR' AND DATA_LENGTH &lt; 2000; STR VARCHAR2(500) := '';BEGIN DBMS_OUTPUT.ENABLE(1000000); FOR S IN TEMP LOOP STR := 'ALTER TABLE ' || S.TABLE_NAME || ' MODIFY(' || S.COLUMN_NAME || ' VARCHAR2(' || S.DATA_LENGTH || '))'; DBMS_OUTPUT.PUT_LINE(STR); EXECUTE IMMEDIATE STR; END LOOP;END; 执行 1call m_char();]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>expdp</tag>
        <tag>impdp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[httpclient 使用]]></title>
    <url>%2Fposts%2F812c7f75.html</url>
    <content type="text"><![CDATA[连接池配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061private static final int MAX_CONN_TOTAL = 500;private static final int MAX_CONN_PER_ROUTE = 50;private static final int TIMEOUT = 4000;private static CloseableHttpClient client;static &#123; Builder builder = RequestConfig.custom(); builder.setSocketTimeout(TIMEOUT).setConnectTimeout(TIMEOUT).setConnectionRequestTimeout(TIMEOUT); /* * 4.3以上版本推荐使用HttpClientBuilder来创建client * * &lt;pre&gt; * 1、HttpClientBuilder.setRetryHandler(HttpRequestRetryHandler retryHandler);请求重试处理。 * 2、HttpClientBuilder.setRedirectStrategy(RedirectStrategy redirectStrategy);设置重定向。 * 3、httpClientBuilder.setDefaultCookieStore(BasicCookieStore cookieStore);设置cookie store * 4、HttpClientBuilder.setProxy(HttpHost proxy);设置代理服务器。 * 5、HttpClientBuilder.setDefaultRequestConfig(RequestConfig config);在此亦可设置RequestConfig。 * 6、HttpClientBuilder.setUserAgetn(String userAgent);设置用户代理。 * &lt;/pre&gt; */ HttpClientBuilder clientBuilder = HttpClients.custom(); // 配置 SSL、TLS // httpClientBuilder.setSSLSocketFactory(sslSocketFactory); // builder.setExpectContinueEnabled(true).setStaleConnectionCheckEnabled(true) // .setTargetPreferredAuthSchemes(Arrays.asList(AuthSchemes.NTLM, // AuthSchemes.DIGEST)) // .setProxyPreferredAuthSchemes(Arrays.asList(AuthSchemes.BASIC)); builder.setCookieSpec(CookieSpecs.IGNORE_COOKIES); RequestConfig defaultRequestConfig = builder.build(); clientBuilder.setDefaultRequestConfig(defaultRequestConfig); // 主要连接池配置代码 // 默认是：20 clientBuilder.setMaxConnTotal(MAX_CONN_TOTAL); // 默认是：2 clientBuilder.setMaxConnPerRoute(MAX_CONN_PER_ROUTE); // SSL try &#123; // TLS SSLContext sc = SSLContext.getInstance("SSL"); MyX509TrustManager trustManager = new MyX509TrustManager(); sc.init(null, new TrustManager[]&#123;trustManager&#125;, new java.security.SecureRandom()); // // 设置协议http和https对应的处理socket链接工厂的对象 // Registry&lt;ConnectionSocketFactory&gt; registry = RegistryBuilder.&lt;ConnectionSocketFactory&gt;create() // .register("http", PlainConnectionSocketFactory.INSTANCE) // .register("https", new SSLConnectionSocketFactory(sc)).build(); // PoolingHttpClientConnectionManager connManager = new PoolingHttpClientConnectionManager(registry); // 主要连接池配置代码 // 默认是：20 // connManager.setMaxTotal(MAX_CONN_TOTAL); // 默认是：2 // connManager.setDefaultMaxPerRoute(MAX_CONN_PER_ROUTE); // clientBuilder.setConnectionManager(connManager); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; client = clientBuilder.build();&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>apache</tag>
        <tag>httpclient</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS dns 配置]]></title>
    <url>%2Fposts%2Fb5386f83.html</url>
    <content type="text"><![CDATA[查询网卡名12345nmcli connection show# 输出信息名称 UUID 类型 设备 ens192 03da7500-2101-c722-2438-d0d006c28c73 802-3-ethernet ens192 查看配置1234# 查看网络配置cat /etc/sysconfig/network-scripts/ifcfg-ens192# 查看网络配置nmcli c show ens192 配置 dns 12345# 如果系统开启了IPv4、IPv6，需要配置这个。参考：http://www.spingdraft.com/article-10081.html# ens192 是网卡名称sudo nmcli con mod ens192 ipv4.dns-options "timeout:2 attempts:3 rotate single-request-reopen"sudo nmcli con mod ens192 ipv4.dns "192.168.2.10"sudo nmcli con up ens192 取消 dns 配置123sudo nmcli con mod ens192 ipv4.dns-options ""sudo nmcli con mod ens192 ipv4.dns ""sudo nmcli con up ens192 测试 dns 速度 tst.sh 12345678910111213141516171819202122232425262728#!/bin/bash# by yl 2020-10-30baiduHttps()&#123; curl "http://www.baidu.com" \ -so /dev/null \ -w "%&#123;http_code&#125; %&#123;time_namelookup&#125; %&#123;time_total&#125;" \ | xargs printf " %6s%8s%8s |"&#125;baiduHttp()&#123; curl "http://www.baidu.com" \ -so /dev/null \ -w "%&#123;http_code&#125; %&#123;time_namelookup&#125; %&#123;time_total&#125;" \ | xargs printf "| %6s%8s%8s |"&#125;printf "==========================================================\n"for((i=0;i&lt;100000;i++))do if [ $((i%20)) -eq "0" ]; then printf "| %6s%8s%8s | %6s%8s%8s | %20s\n" "http" "dns" "total" "https" "dns" "total" "timeStamp" fi baiduHttp baiduHttps date "+ %F %T" sleep 6done 执行脚本 123456789nohup sh tst.sh &amp;# nohup.out| http dns total | https dns total | timeStamp| 200 0.012 0.018 | 200 0.012 0.019 | 2020-11-02 18:27:59| 200 0.012 0.018 | 200 0.012 0.021 | 2020-11-02 18:28:05| 200 0.012 0.019 | 200 0.012 0.018 | 2020-11-02 18:28:11| 200 0.012 0.018 | 200 0.012 0.018 | 2020-11-02 18:28:17| 200 0.012 0.018 | 200 0.012 0.018 | 2020-11-02 18:28:23]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>dns</tag>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle 修改默认监听端口]]></title>
    <url>%2Fposts%2Fedff79be.html</url>
    <content type="text"><![CDATA[查看监听状态1$ lsnrctl status 停止监听1$ lsnrctl stop 修改配置文件12$ vi $ORACLE_HOME/network/admin/listener.ora1521-----&gt;21521 登录并查看local_listener参数123$ sqlplus / as sysdbaSQL&gt; show parameter local_listener(这个时候VALUE这个值应该是空的) 修改local_listener参数12SQL&gt; alter system set local_listener="(address = (protocol = tcp)(host = 192.168.123.10)(port = 21521))";#host后面加的主机名称或者IP 查看local_listener参数1SQL&gt; show parameter local_listener 启动监听1$ lsnrctl start 查看状态12$ netstat -an|grep 21521$ lsnrctl status]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ntp 时间同步]]></title>
    <url>%2Fposts%2Fb3b5b23f.html</url>
    <content type="text"><![CDATA[假设有3台服务器 192.168.1.10（ntp服务端） 192.168.1.11（ntp客户端） 192.168.1.12（ntp客户端） ntp 服务端 /etc/ntp.conf 1234567891011121314151617181920212223# 注释原有的server#server 0.centos.pool.ntp.org iburst#server 1.centos.pool.ntp.org iburst#server 2.centos.pool.ntp.org iburst#server 3.centos.pool.ntp.org iburst# 第一种：读取远端服务器时钟server 远端IP# 第二种：以本机时钟为准。注意：不是127.0.0.1，而是127.127.1.0server 127.127.1.0# 如果启用了chronyd，需要禁用 chronyd 否则 ntpd 配置开机启动会不生效## 查看是否开机启动# systemctl is-enabled chronyd# sudo systemctl disable chronyd# 开机启动sudo systemctl enable ntpdsudo systemctl start ntpdsudo systemctl restart ntpdsystemctl status ntpdntpq -pntpstat ntp 客户端分别在192.168.1.11、192.168.1.12做以下配置 /etc/ntp.conf 1234567891011121314151617# 注释原有的server#server 0.centos.pool.ntp.org iburst#server 1.centos.pool.ntp.org iburst#server 2.centos.pool.ntp.org iburst#server 3.centos.pool.ntp.org iburst# 配置允许NTP Server时间服务器主动修改本机的时间restrict 192.168.1.10 nomodify notrap noquery# 读取内网ntp服务器时间server 192.168.1.10sudo systemctl start ntpd;sudo systemctl restart ntpd;sudo systemctl enable ntpd;systemctl status ntpd;ntpq -p;ntpstat; 查看状态 123456789[yl@192.168.1.11 home]# ntpq -p remote refid st t when poll reach delay offset jitter============================================================================== 192.168.1.10 LOCAL(0) 6 u 46 64 3 0.622 -158833 0.014 [yl@192.168.1.11 home]# ntpstatsynchronised to NTP server (192.168.1.10) at stratum 7 time correct to within 20 ms polling server every 128 s 说明配置成功]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>ntp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle 整库迁移]]></title>
    <url>%2Fposts%2Fd5d4c80.html</url>
    <content type="text"><![CDATA[导出123456789101112expdp 用户名/密码 directory=DMP logfile=e_T_C_CNCM_EXTINFO.log dumpfile=T_C_CNCM_EXTINFO%U.dmp PARALLEL=6 cluster=no compression=ALL tables=(table1,table2)directory=DMP -- 这个是虚拟目录（日志文件和DMP文件存放路径）， 需求提前在数据库里面创建，需要DBA权限。create directory DMP as '/dmp/backup';grant read,write,EXECUTE on directory DMP to 用户名;logfile=e_T_C_CNCM_EXTINFO.log -- EXPDP日志dumpfile=T_C_CNCM_EXTINFO%U.dmp -- 输出的DMP文件，其中%U为并行导出产生的序号，如果开6个并行，就可能会有六个文件，自动从01-06编号PARALLEL=6 -- 并行导出，可以根据主机CPU增加，最好不要超过CODE数cluster=no -- 关闭cluster（防止非共享磁盘写文件问题）compression -- 压缩tables=() -- 可以写多个table 导入123456impdp 用户名/密码 directory=DMP logfile=i_T_C_APT_TEMPLATE_DETAIL.log dumpfile=T_C_APT_TEMPLATE_DETAIL%U.dmp PARALLEL=4 table_exists_action=truncate -- table_exists_action 可选参数：-- trauncate：导入时 trauncate 清空原表数据再导入-- replace：先 drop 表，然后创建表，最后插入数据 -- append：在原来数据的基础上增加数据 SELECT DIRECTORY_NAME ,DIRECTORY_PATH FROM DBA_DIRECTORIES; /data/app/oracle/admin/orcl/dpdump/ create directory DATA_PUMP_DIR as ‘/data/dmp’;]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>expdp</tag>
        <tag>impdp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle 编码配置]]></title>
    <url>%2Fposts%2Fa4a638d8.html</url>
    <content type="text"><![CDATA[查编码1select userenv('language') from dual 编码配置123456789101112131415oracle数据库的编码select * from nls_database_parameters where parameter ='NLS_CHARACTERSET';oracle客户端编码select * from nls_instance_parameters where parameter='NLS_LANGUAGE';conn /as sysdba;shutdown immediate;startup mount;alter system enable restricted session;alter system set job_queue_processes=0;ALTER SYSTEM SET AQ_TM_PROCESSES=0;alter database open;ALTER DATABASE character set INTERNAL_USE AL32UTF8;shutdown immediate;startup;]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elastic-job 使用]]></title>
    <url>%2Fposts%2F33cc482c.html</url>
    <content type="text"><![CDATA[2.1.5 版本 context-path配置修改 context-path com.dangdang.ddframe.job.restful.RestfulServer 12345private ServletContextHandler buildServletContextHandler() &#123; ServletContextHandler result = new ServletContextHandler(ServletContextHandler.SESSIONS); result.setContextPath("/"); return result;&#125; 修改成 12345private ServletContextHandler buildServletContextHandler() &#123; ServletContextHandler result = new ServletContextHandler(ServletContextHandler.SESSIONS); result.setContextPath("/elasticjob"); return result; &#125; 修改前端接口地址把前端/api的地方改成api 默认中文 console/index.html 12345&lt;div id="content" class="lang-en"&gt; &lt;/div&gt;&lt;!-- 修改成 --&gt;&lt;div id="content" class="lang-zh"&gt; &lt;/div&gt;]]></content>
      <categories>
        <category>elastic-job</category>
      </categories>
      <tags>
        <tag>elastic-job</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle spool操作]]></title>
    <url>%2Fposts%2Feaf10d0a.html</url>
    <content type="text"><![CDATA[123456789101112131415161718192021#!/bin/kshecho "set echo off;set heading off;set line 100;set long 2000000000;set longchunksize 255;set wra on;set newpage none;set pagesize 0;set numwidth 12;set termout off;set trimout on;set trimspool on;set feedback off;set timing on;execute dbms_logmnr.add_logfile(LogFileName=&gt;'/oracle/app/oracle/logs/hrbfct_1_4156_748575599.arc',Options=&gt;dbms_logmnr.new);execute dbms_logmnr.start_logmnr(DictFileName=&gt;'/oracle/app/oracle/logs/dict.ora');spool /oracle/app/oracle/logs/record3.txt;select id||'|'||name from t_user;spool off;" | sqlplus '/as sysdba'&gt;/dev/null]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>spool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle 归档日志]]></title>
    <url>%2Fposts%2Fe34c2a97.html</url>
    <content type="text"><![CDATA[开启、关闭归档 开启 12345678910-- 关闭数据库shutdown immediate;-- 打开数据库startup mount;-- 开启归档日志alter database archivelog;-- 开启数据库alter database open;-- 查看归档日志是否开启archive log list; 关闭 123456-- 关闭数据库SQL&gt; shutdown immediate；-- 开启数据库至mount状态SQL&gt; startup mount;-- 修改数据库模式SQL&gt; alter datebase noarchivelog; 查询归档模式是否开启123456SQL&gt; archive log list;Database log mode No Archive ModeAutomatic archival DisabledArchive destination USE_DB_RECOVERY_FILE_DESTOldest online log sequence 10107Current log sequence 10109 问题归档日志空间占满 ORA-00257: archiver error. Connect internal only, until freed 查看归档12SQL&gt; select * from V$FLASH_RECOVERY_AREA_USAGE;SQL&gt; quit 查询归档日志文件大小12345678Select to_char(completion_time,'yyyy-mm-dd') as date1, -- CNT 为每天归档次数 count(0) as cnt, -- MB 为每天的归档量 round(sum((blocks*block_size)/1024/1024)) as mb from v$archived_log group by to_char(completion_time,'yyyy-mm-dd') order by date1 desc; 调整归档日志大小123456-- 查看归档日志信息SQL&gt; show parameter db_recovery;-- 查看归档日志大小SQL&gt; show parameter db_recovery_file_dest_size;-- 调整归档日志大小SQL&gt; alter system set db_recovery_file_dest_size=400g 一般日志文件路径：/data/app/oracle/fast_recovery_area/ORCL/archivelog/ 删除归档日志123456789101112131415$ rman$ connect target sys/oracleRMAN&gt; crosscheck archivelog all;RMAN&gt; delete expired archivelog all;-- 注：删除过期的归档-- 这样就把归档文件删除了。再进入sqlplus 查看ARCHIVELOG日志使用率！-- 以上处理方法是当遇到出现日志写满报错时的处理，建议最好做个任务，定时删除日志，如下：-- 删除七天前的归档RMAN&gt; DELETE ARCHIVELOG ALL COMPLETED BEFORE 'SYSDATE-7';-- 删除七天到现在的归档 RMAN&gt; DELETE ARCHIVELOG FROM TIME 'SYSDATE-7';DELETE ARCHIVELOG FROM TIME 'SYSDATE-1'; del_archivelog.sh 1234567891011121314#!/bin/bashecho "--------------------------`date`--------------------------"source ~/.bash_profilemkdir -p /data/del_archivelogLOG_DIR=/data/del_archivelog/DATEL=`date '+%Y-%m-%d'`LOG_NAME=$&#123;LOG_DIR&#125;$&#123;DATEL&#125;".log"rman log=$LOG_NAME target / &lt;&lt;EOFcrosscheck archivelog all;delete noprompt archivelog all completed before 'sysdate-2';EOFecho -e "\n"echo "--------------------------finished--------------------------" 每天6点执行脚本 del_archivelog.sh，并将执行结果输出到 task.log 10 6 * * * sh ~/del_archivelog.sh &gt;&gt; ~/del_archivelog/task.log 2&gt;&amp;1 &amp;]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>archiver</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle dblink操作]]></title>
    <url>%2Fposts%2F5bb4128a.html</url>
    <content type="text"><![CDATA[创建1234-- 语法-- create &lt;public&gt; database link &lt;dblink_name&gt; connect to &lt;user&gt; identified by &lt;user_pwd&gt; using &lt;dblink&gt;create database link db_test connect to scott identified by tiger using '(DESCRIPTION=(ADDRESS_LIST =(ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.1.1)(PORT = 1521)))(CONNECT_DATA=(SERVER = DEDICATED)(SERVICE_NAME = orcl)))'; 删除1drop &lt;public&gt; database link db_test]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>dblink</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux ftp 命令]]></title>
    <url>%2Fposts%2F3a2165c2.html</url>
    <content type="text"><![CDATA[登录1ftp &lt;ip&gt; &lt;port&gt; 下载1get &lt;file_name&gt; 上传 put 1put /path/file.xls mput 123456# 如果有多个文件，每个文件都要确认一次mput /path/*.xls# prompt模式，多个文件也不需要手动确认promptmput *.xls 删除12promptmdelete *.txt 批量删除脚本 ftp_clear.sh 123456789101112#!/bin/bashFTPHOST="192.168.1.10"USERNAME="test"PASSWORD="test_password"ftp -nv $FTPHOST &lt;&lt;!FTPRUNuser $USERNAME $PASSWORDcd test_dirpromptmdelete *.txtbye!FTPRUN 登入FTP 服务器并传送备份ftp -nv \$FTPHOST 用户名、密码user \$USERNAME \$PASSWORD 进入指定目录cd test_dir 开启prompt模式prompt 批量删除mdelete *.txt 退出bye crontab 定时器 1*/30 * * * * sh ftp_clear.sh &gt;&gt; ftp_clear.log 2&gt;&amp;1 &amp;]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>ftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker pentaho-kettle 安装和配置]]></title>
    <url>%2Fposts%2F3e7d19cc.html</url>
    <content type="text"><![CDATA[docker配置 docker-compose.yml 123456789101112131415161718version: "3.8"services: jenkins_agent: container_name: ts_kettle image: hiromuhota/webspoon:0.9.0.22 ports: - "8081:8080" volumes: - "./pdi/kettle:/home/tomcat/.kettle" - "./pdi/pentaho:/home/tomcat/.pentaho" - "./pdi/tomcat/plugins:/usr/local/tomcat/plugins" - "./pdi/tomcat/system:/usr/local/tomcat/system" - "./pdi/tomcat/simple-jndi:/usr/local/tomcat/simple-jndi" - "./pdi/tomcat/webapps/spoon:/usr/local/tomcat/webapps/spoon" - "/var/run/docker.sock:/var/run/docker.sock" - "/etc/localtime:/etc/localtime" restart: always 权限配置1sudo chown -R 999:999 pdi/ 语言配置 /home/tomcat/.kettle/.languageChoice 1LocaleDefault=zh_CN]]></content>
      <categories>
        <category>kettle</category>
      </categories>
      <tags>
        <tag>pentaho-kettle</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle 表空间操作]]></title>
    <url>%2Fposts%2F2fa1c46f.html</url>
    <content type="text"><![CDATA[空间回收1purge recyclebin; 使用delete删除数据回收空间方法1234-- 开启行迁移功能ALTER TABLE T_FTP_ARREARS_RESULT ENABLE ROW MOVEMENT;-- 收缩表并降低hwm，并且回收相应的索引ALTER TABLE T_FTP_ARREARS_RESULT SHRINK SPACE CASCADE; 修改表空间1234567891011121314151617181920-- 修改表空间SELECT 'ALTER TABLE WWTEST.' || T.TABLE_NAME || ' MOVE TABLESPACE USERS;' FROM ALL_TABLES T WHERE T.OWNER = 'WX_KBT_TEST';---- 如果有分区，使用这条语句SELECT 'alter table ' || TABLE_NAME || ' move partition ' || PARTITION_NAME || ' tablespace USERS;' FROM USER_TAB_PARTITIONS WHERE TABLE_NAME IN ('IM_WX_QX_TEMPLATE_RESULT', 'IM_WX_QX_TEMPLATE');-- 修改索引的表空间SELECT 'alter index ' || INDEX_NAME || ' rebuild tablespace USERS;' FROM ALL_INDEXES I WHERE I.OWNER = 'WX_KBT_TEST' AND I.PARTITIONED = 'YES';---- 如果有分区，使用这条语句SELECT 'alter index ' || P.INDEX_NAME || ' rebuild PARTITION ' || P.PARTITION_NAME || ' tablespace USERS;' FROM USER_IND_PARTITIONS P WHERE P.INDEX_NAME IN ('I_IM_WX_LOG_PROCESSTYPE', 'I_IM_WX_LOG_USERNO'); 大小扩展数据文件大小1234567891011121314151617181920212223SELECT A.TABLESPACE_NAME, ROUND(A.BYTES / 1024 / 1024 / 1024, 2) "sum GB", ROUND(A.BYTES / 1024 / 1024, 2) "sum MB", ROUND((A.BYTES - B.BYTES) / 1024 / 1024 / 1024, 2) "used GB", ROUND((A.BYTES - B.BYTES) / 1024 / 1024, 2) "used MB", ROUND(B.BYTES / 1024 / 1024, 2) "free MB", ROUND(((A.BYTES - B.BYTES) / A.BYTES) * 100, 2) "used%" FROM (SELECT TABLESPACE_NAME, SUM(BYTES) BYTES FROM DBA_DATA_FILES GROUP BY TABLESPACE_NAME) A, (SELECT TABLESPACE_NAME, SUM(BYTES) BYTES, MAX(BYTES) LARGEST FROM DBA_FREE_SPACE GROUP BY TABLESPACE_NAME) B WHERE A.TABLESPACE_NAME = B.TABLESPACE_NAME ORDER BY ((A.BYTES - B.BYTES) / A.BYTES) DESC;SELECT T.TABLESPACE_NAME, T.FILE_NAME, T.BYTES / 1024 / 1024 || 'M' AS TOTAL, T.AUTOEXTENSIBLE, T.MAXBYTES / 1024 / 1024 || 'M' AS MAXSIZE FROM DBA_DATA_FILES T WHERE T.TABLESPACE_NAME = 'USERS'; 表空间追加文件（大小）1234567-- 固定大小（会马上分配 30GB 硬盘空间）alter tablespace users add datafile '/data/app/oracle/oradata/orcl/users12.dbf' size 30G;-- 自动扩展大小（初始大小 500MB，最大 30GB），推荐这种配置方式alter tablespace users add datafile '/data/app/oracle/oradata/orcl/im_data07.dbf' size 500M autoextend on next 5M maxsize 30G;SELECT T.bytes/1024/1024,T.* FROM Dba_Segments t WHERE t.tablespace_name='users' ORDER BY T.bytes DESC; 重设大小12345678910SELECT 'alter database datafile ' || FILE_NAME || ' resize 500M;' FROM DBA_DATA_FILES F WHERE F.TABLESPACE_NAME = 'USERS';SELECT 'ALTER database datafile ' || FILE_NAME || ' autoextend on next 10M maxsize 30G;' FROM DBA_DATA_FILES F WHERE F.TABLESPACE_NAME = 'USERS';ALTER database datafile '/data/app/oracle/oradata/orcl/users55.dbf' resize 500M;ALTER database datafile '/data/app/oracle/oradata/orcl/users55.dbf' autoextend on next 10M maxsize 30G; 删除表空间1234567891011-- 删除空的表空间，不包含物理文件drop tablespace tablespace_name;-- 删除非空表空间，不包含物理文件drop tablespace tablespace_name including contents;-- 删除空表空间，包含物理文件drop tablespace tablespace_name including datafiles;-- 删除非空表空间，包含物理文件drop tablespace tablespace_name including contents and datafiles;-- 如果其他表空间中的表有外键等约束关联到了本表空间中的表的字段，就要加上CASCADE CONSTRAINTSdrop tablespace tablespace_name including contents and datafiles CASCADE CONSTRAINTS;drop tablespace &lt;tablespace_name&gt; including contents and datafiles;]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows 默认软件不可用的问题]]></title>
    <url>%2Fposts%2Fd6d2f549.html</url>
    <content type="text"><![CDATA[命令打开服务1services.msc 命令行打开网络中心1ncpa.cpl 软链1234# 建立软链接mklink /D "C:\Program Files\VanDyke Software\Clients" "D:\Program Files\SecureCRT"# 删除软链接rmdir "C:\Program Files\VanDyke Software\Clients"]]></content>
      <categories>
        <category>软件</category>
      </categories>
      <tags>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh无密码登录]]></title>
    <url>%2Fposts%2F6402dc33.html</url>
    <content type="text"><![CDATA[主控节点设置ssh无密码跳转到受控节点的信任关系 假设有3台服务器 主控服务器 192.168.123.1 受控服务器 192.168.123.2 192.168.123.3 其中192.168.123.1需要无密码登录到192.168.123.2和192.168.123.3 即在192.168.123.1上执行 1ssh -p22 user@192.168.123.2 可以无密码登录到192.168.123.2 主控服务器生成密钥 192.168.123.1 12cd ~ssh-keygen -t rsa 会在用户目录下生成.ssh目录和id_rsa私钥文件、id_rsa.pub公钥文件 拷贝私钥到受控服务器 在不知道受控服务器密码的情况下 在用户目录下新建.ssh/authorized_keys 12345678# 如果没有.ssh目录，手动创建cd ~mkdir .ssh# 如果没有authorized_keys文件，手动创建一个cd .sshtouch authorized_keys# 将主控服务器生成的id_rsa.pub公钥追加到authorized_keys# cat -n ~/.ssh/主控_id_rsa.pub authorized_keys 注意：这样就将公钥内容追加到authorized_keys中了，然后需要配置权限，否则SSH不会工作的。 123456# 将.ssh目录的权限为700cd ~chmod -R 700 .ssh# 将authorized_keys目录的权限为600cd ~/.sshchmod -R 600 authorized_keys 知道受控服务器密码的情况下 192.168.123.1 12cd ~ssh-copy-id -i .ssh/id_rsa.pub -p22 user@192.168.123.2]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 使用]]></title>
    <url>%2Fposts%2Fdeb080b.html</url>
    <content type="text"><![CDATA[打包镜像 save 1docker save -o nginx.tar nginx:1.18.0-alpine-perl load 1docker load --input nginx.tar 删除none镜像在docker反复build后，会存留很多none镜像，下面命令一键删除所有none镜像 123456docker rmi `docker images | grep '&lt;none&gt;' | awk '&#123;print $3&#125;'`# 更简单方法docker rmi `docker images -q -f dangling=true`# 或docker rmi $(docker images -q -f dangling=true) 删除容器删除所有停止的容器，运行中的容器不会被删除 1docker rm $(docker ps -a -q)]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker kafka 安装和配置]]></title>
    <url>%2Fposts%2F212ff189.html</url>
    <content type="text"><![CDATA[scala版本2.13 kafka版本2.6.0 docker pull wurstmeister/kafka:2.13-2.6.0 docker-compose.yml 12345678910111213141516171819202122232425version: "3.8"services: kafka: container_name: ts_kafka image: wurstmeister/kafka:2.13-2.6.0 ports: - "9092:9092" volumes: - "KAFKA_ADVERTISED_HOST_NAME=172.54.102.25" # 在 kafka 集群中，每个 kafka 都有一个 BROKER_ID 来区分自己 - "KAFKA_BROKER_ID=0" # 配置 kafka 的监听端口 - "KAFKA_LISTENERS=PLAINTEXT://9092" # 把 kafka 的地址端口注册给 zookeeper - "KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://9092" # 配置 zookeeper - "KAFKA_ZOOKEEPER_CONNECT=zookeeper01:2181,zookeeper02:2181/kafka" # 关闭 Topic 自动创建 - "KAFKA_AUTO_CREATE_TOPICS_ENABLE=false" - "./logs:/tmp/kafka-logs" - "/var/run/docker.sock:/var/run/docker.sock" # 容器时间同步虚拟机的时间 - "/etc/localtime:/etc/localtime" restart: always /var/run/docker.sock挂载了之后，在容器内就可以执行”docker ps”、”docker port”这些命令了，这是docker官方提供的能力。假设kafka容器的9092映射到宿主机的30001端口，那么kafka注册到ZK的时候，要注册的IP应该是宿主机的IP，端口应该是30001，这样才能保证外部可访问，所以kafka容器启动时会执行一个名为start-kafka.sh的脚本，里面用docker port命令来获取宿主机的端口，因此必须要挂载/var/run/docker.sock才能执行docker port命令]]></content>
      <categories>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker gitlab安装和配置]]></title>
    <url>%2Fposts%2Fa4f9cef0.html</url>
    <content type="text"><![CDATA[使用docker安装 docker-compose.yaml 123456789101112131415161718version: "3.8"services: gitlab: container_name: ts_gitlab image: gitlab/gitlab-ce:13.2.6-ce.0 ports: - "8082:8082" volumes: - "./data:/var/opt/gitlab" - "./logs:/var/log/gitlab" - "./config:/etc/gitlab" - "/etc/localtime:/etc/localtime" environment: GITLAB_OMNIBUS_CONFIG: | external_url "http://ip:8082" gitlab_rails['time_zone']=CST restart: always GITLAB_OMNIBUS_CONFIG查看https://docs.gitlab.com/omnibus/docker/ 编辑站点信息 vi /etc/gitlab.rb 配置 gitlab-ctl reconfigure]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker mysql安装和配置]]></title>
    <url>%2Fposts%2F1299dfc1.html</url>
    <content type="text"><![CDATA[mysql docker-compose.yml 123456789101112131415161718version: "3.8"services: mysql: container_name: ts_mysql image: mysql:5.7.31 ports: - "3306:3306" volumes: - "./data/:/var/lib/mysql" - "./logs/:/var/log/mysql" - "./conf/conf.d:/etc/mysql/conf.d" - "./conf/mysql.conf.d:/etc/mysql/mysql.conf.d" - "./conf/my.cnf:/etc/mysql/my.cnf" - "/etc/localtime:/etc/localtime" environment: MYSQL_ROOT_PASSWORD: "test123456" restart: always my.cnf 123456789101112131415161718192021222324# Copyright (c) 2016, Oracle and/or its affiliates. All rights reserved.## This program is free software; you can redistribute it and/or modify# it under the terms of the GNU General Public License, version 2.0,# as published by the Free Software Foundation.## This program is also distributed with certain software (including# but not limited to OpenSSL) that is licensed under separate terms,# as designated in a particular file or component or in included license# documentation. The authors of MySQL hereby grant you an additional# permission to link the program and your derivative works with the# separately licensed software that they have included with MySQL.## This program is distributed in the hope that it will be useful,# but WITHOUT ANY WARRANTY; without even the implied warranty of# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the# GNU General Public License, version 2.0, for more details.## You should have received a copy of the GNU General Public License# along with this program; if not, write to the Free Software# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA!includedir /etc/mysql/conf.d/!includedir /etc/mysql/mysql.conf.d/]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker nexus3安装和配置]]></title>
    <url>%2Fposts%2F5ed27d2e.html</url>
    <content type="text"><![CDATA[nexus3 docker-compose.yml 123456789101112version: "3.8"services: nexus3: container_name: ts_nexus3 image: sonatype/nexus3:3.26.1 ports: - "8081:8081" volumes: - "./data:/nexus-data" - "/etc/localtime:/etc/localtime" restart: always 问题：Error creating bundle cache.Unable to update instance pid: Unable to create directory /nexus-data/instances 解决：sudo chmod -R 775 data/]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>nexus3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker nginx-1.18.0-alpine 配置]]></title>
    <url>%2Fposts%2F8b6eb00b.html</url>
    <content type="text"><![CDATA[nginx 自定义证书1234567891011121314151617181920212223242526272829#!/bin/sh# create self-signed server certificate:read -p "Enter your domain [www.example.com]: " DOMAINecho "Create server key..."openssl genrsa -des3 -out $DOMAIN.key 1024echo "Create server certificate signing request..."SUBJECT="/C=US/ST=Mars/L=iTranswarp/O=iTranswarp/OU=iTranswarp/CN=$DOMAIN"openssl req -new -subj $SUBJECT -key $DOMAIN.key -out $DOMAIN.csrecho "Remove password..."mv $DOMAIN.key $DOMAIN.origin.keyopenssl rsa -in $DOMAIN.origin.key -out $DOMAIN.keyecho "Sign SSL certificate..."openssl x509 -req -days 3650 -in $DOMAIN.csr -signkey $DOMAIN.key -out $DOMAIN.crtecho "TODO:"echo "cp $DOMAIN.crt to /etc/nginx/ssl/$DOMAIN.crt"echo "cp $DOMAIN.key to /etc/nginx/ssl/$DOMAIN.key"echo "Add configuration in nginx:"echo "server &#123;"echo " ..."echo " listen 443 ssl;"echo " ssl_certificate /etc/nginx/ssl/$DOMAIN.crt;"echo " ssl_certificate_key /etc/nginx/ssl/$DOMAIN.key;"echo "&#125;" docker-compose.yml12345678910111213141516version: '3.8'services: nginx: container_name: ts_nginx image: nginx:1.18.0-alpine ports: - "8810:8810" - "8820:8820" volumes: - "./config/nginx.conf:/etc/nginx/nginx.conf" - "./config/conf.d/:/etc/nginx/conf.d/" - "./ssl:/etc/nginx/ssl" - "./html:/usr/share/nginx/html" - "/etc/localtime:/etc/localtime" restart: always 注意：其中nginx.conf、default.conf、server_*.conf、upstream_*.conf等是文件，要提前在宿主机建好 /etc/nginx/nginx.conf 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798user nginx;worker_processes auto;worker_rlimit_nofile 65535;error_log /var/log/nginx/error.log error;pid /var/run/nginx.pid;events &#123; use epoll; worker_connections 65535;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; # ngx_http_core_module server_tokens off; client_max_body_size 50m; underscores_in_headers on; open_file_cache max=65535 inactive=60s; open_file_cache_errors on; open_file_cache_min_uses 2; open_file_cache_valid 60s; # ngx_http_core_module # ngx_http_proxy_module proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_cache_path /dev/shm/nginx_cache levels=1:2 keys_zone=shmCache:10m max_size=1g inactive=180m use_temp_path=off; # ngx_http_proxy_module # ngx_http_limit_conn_module limit_conn_status 444; limit_conn_zone $binary_remote_addr zone=perip:32m; limit_conn_zone $server_name zone=perserver:10m; # ngx_http_limit_conn_module # log_format main '$remote_addr - $remote_user [$time_local] "$request" ' # '$status $body_bytes_sent "$http_referer" ' # '"$http_user_agent" "$http_x_forwarded_for"'; # # access_log /var/log/nginx/access.log main; log_format logJson '&#123;' '"accessTime": "$time_local", ' '"remote_addr": "$remote_addr", ' '"referer": "$http_referer", ' '"request": "$request", ' '"status": $status, ' '"bytes": $body_bytes_sent, ' '"agent": "$http_user_agent", ' '"x_forwarded": "$http_x_forwarded_for", ' '"up_addr": "$upstream_addr",' '"up_host": "$upstream_http_host",' '"up_resp_time": "$upstream_response_time",' '"request_time": "$request_time"' '&#125;'; access_log /var/log/nginx/access.log logJson; sendfile on; #tcp_nopush on; keepalive_timeout 65; # ngx_http_gzip_module gzip on; gzip_comp_level 2; gzip_min_length 1000; gzip_proxied expired no-cache no-store private auth; gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript; # ngx_http_gzip_module # include /usr/local/nginx/conf/objects/server0_default.conf; # include /usr/local/nginx/conf/objects/server_*.conf; # include /usr/local/nginx/conf/objects/server6_*.conf; # include /usr/local/nginx/conf/objects/upstreams_*.conf; # include /etc/nginx/conf.d/*.conf; #include /etc/nginx/conf.d/default.conf; include /etc/nginx/conf.d/server_*.conf; include /etc/nginx/conf.d/upstreams_*.conf; server &#123; listen unix:/tmp/nginx.sock; ##以下配置为符合基线合规化处理 location = /50x.html &#123; # 返回错误页面 limit_conn perip 32; # 每个IP并发连接数为32 limit_conn perserver 32; # 每个主机的最大并发数为32 limit_rate 1024k; # 下载速率为1024k client_body_timeout 10; #指定客户端与服务端建立连接后发送 request body 的超时时间 send_timeout 10; #服务端向客户端传输数据的超时时间 return 444; &#125; client_header_timeout 10; #客户端向服务端发送一个完整的 request header 的超时时间 error_page 400 401 402 403 404 413 500 502 503 504 /50x.html; #自定义nginx返回的错误信息 &#125;&#125; /etc/nginx/conf.d/server_0_433.conf 123456789101112131415161718192021222324252627282930313233343536373839404142server &#123; listen 8810; listen [::]:8810; # ssl_certificate /usr/local/nginx/ssl/4113665.pem; # ssl_certificate_key /usr/local/nginx/ssl/4113665.key; # ssl_session_timeout 5m; # ssl_ciphers "ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:DHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA:AES256-GCM-SHA384:AES128-GCM-SHA256:AES256-SHA256:AES128-SHA256:AES256-SHA:AES128-SHA:!aNULL:!eNULL:!EXPORT:!DES:!MD5:!PSK:!RC4"; # ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # ssl_session_cache shared:SSL:10m; # ssl_prefer_server_ciphers on; limit_conn perip 50; limit_rate 15000k; # 添加几条有关安全的响应头；与 Google+ 的配置类似，详情参见文末。 add_header X-Frame-Options "SAMEORIGIN"; add_header X-XSS-Protection "1; mode=block"; add_header X-Content-Type-Options "nosniff"; # 指定字符集为 UTF-8 charset utf-8; # 关闭 [/favicon.ico] 和 [/robots.txt] 的访问日志，即使它们不存在，也不写入错误日志。 location = /favicon.ico &#123; access_log off; log_not_found off; &#125; location = /robots.txt &#123; access_log off; log_not_found off; &#125; location / &#123; root /usr/share/nginx/html; index index.html index.htm; &#125; location ^~ /xmt/ &#123; proxy_store off; proxy_redirect off; # 注意：这里最好不要使用下划线，upstream 最好改成 xmt-srv，具体查看RFC1-1034规范 proxy_pass http://xmt_srv; &#125; # 引入公共配置，包括错误页面、维护通知、图标、反爬虫协议等 include /etc/nginx/conf.d/agent_deny.conf;&#125; /etc/nginx/conf.d/upstream_0_433.conf 123456# 注意：这里最好不要使用下划线，最好改成 xmt-srv，具体查看RFC1-1034规范upstream xmt_srv &#123; server 192.168.123.1:8015; server 192.168.123.2:8015; server 192.168.123.3:8015;&#125; /etc/nginx/conf.d/agent_deny.conf 123456789101112131415if ($http_user_agent ~* &quot;qihoobot|Baiduspider|Googlebot|Googlebot-Mobile|Googlebot-Image|Mediapartners-Google|Adsbot-Google|Feedfetcher-Google|Yahoo! Slurp|Yahoo! Slurp China|YoudaoBot|Sosospider|Sogou spider|Sogou web spider|MSNBot|ia_archiver|Tomato Bot|Catall Spider|AcoiRobot|Yisou|bingbot|360Spider&quot;) &#123; return 403;&#125;if ($http_user_agent ~* &quot;WinHttp|WebZIP|FetchURL|node-superagent|FeedDemon|Jullo|JikeSpider|Indy Library|Alexa Toolbar|AskTbFXTV|AhrefsBot|CrawlDaddy|Feedly|UniversalFeedParser|ApacheBench|Microsoft URL Control|Swiftbot|ZmEu|oBot|jaunty|Python-urllib|lightDeckReports Bot|YYSpider|DigExt|MJ12bot|heritrix|EasouSpider|Ezooms|BOT/0.1|YandexBot|FlightDeckReports|Linguee Bot|iaskspider|^$&quot;) &#123; return 403;&#125;if ($request_method !~ ^(GET|POST)$) &#123; return 403;&#125;if ($http_user_agent ~* (Python|Wget|Scrapy|Spider)) &#123; return 403;&#125; 系统参数优化 修改/etc/sysctl.conf 12345678910111213141516171819#每个网络接口接收数据包速度比内核处理速度快的时候，允许发送队列数目数据包的最大数net.core.netdev_max_backlog = 102400#调节系统同时发起的tcp连接数，不应该超过 65535net.core.somaxconn = 65535#该参数用于设定系统中最多允许存在多少TCP套接字不被关联到任何一个用户文件句柄上，主要目的为防止Ddos攻击net.ipv4.tcp_max_orphans = 102400#该参数用于记录尚未收到客户端确认信息的连接请求的最大值net.ipv4.tcp_max_syn_backlog = 102400#nginx服务上建议关闭（既为0）net.ipv4.tcp_timestamps = 0#该参数用于设置内核放弃TCP连接之前向客户端发送SYN+ACK包的数量，为了建立对端的连接服务，服务器和客户端需要进行三次握手，第二次握手期间，内核需要发送SYN并附带一个回应前一个SYN的ACK，这个参数主要影响这个过程，一般赋予值为1，即内核放弃连接之前发送一次SYN＋ACK包。net.ipv4.tcp_synack_retries = 1net.ipv4.tcp_syn_retries = 1 执行生效 1sudo sysctl -p net.core.netdev_max_backlog = 102400net.core.somaxconn = 65535net.ipv4.tcp_max_orphans = 102400net.ipv4.tcp_max_syn_backlog = 102400net.ipv4.tcp_timestamps = 0net.ipv4.tcp_synack_retries = 1net.ipv4.tcp_syn_retries = 1 reload1docker exec ts_nginx nginx -s reload 注意事项 使用nginx -s reload时，不能删除nginx.conf，conf.d，可以删除conf.d下的配置，不然会导致nginx reload异常。由于删除文件后，导致链接失效。]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker-compose</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux rpm 命令]]></title>
    <url>%2Fposts%2Fae3631a6.html</url>
    <content type="text"><![CDATA[先检测是否这些软件包是否已经安装1rpm -qa | grep telnet 卸载rpm包 如果已经安装了，又不清楚顺序，可以都卸载后统一安装 1rpm -e telnet-0.17-64.el7.x86_64 安装rpm包1rpm -ivh telnet-0.17-64.el7.x86_64.rpm]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>rpm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 安装 Oracle]]></title>
    <url>%2Fposts%2Fee8ba7d4.html</url>
    <content type="text"><![CDATA[安装 https://hub.docker.com/r/loliconneko/oracle-ee-11g 1docker pull loliconneko/oracle-ee-11g 启动docker run 命令1docker run -h "oracle" --name "oracle" -d -p 1521:1521 loliconneko/oracle-ee-11g docker-compose 启动 oracle.yml 12345678910version: '3.1'services: oracle-ee-11g: image: loliconneko/oracle-ee-11g ports: # - 1522:8080 - 1521:1521 volumes: - /var/docker/oracle:/u01/app/oracle 启动 1docker-compose -f oracle.yml up 进入容器1docker exec -it &lt;container_id&gt; /bin/bash 登录oracle1sqlplus sysdba/oracle 查看用户1select username,password from dba_users; 创建用户1create user &lt;user_name&gt; identified by &lt;password&gt;; 给用户授权1grant connect,resource to &lt;user_name&gt;; connect 是保证该用户能连接数据库resource 是该用户可以使用数据库资源 所有权限 grant all privileges to &lt;user_name&gt;; 删除用户1drop user deque 链接123jdbc:oracle:thin:@&lt;ip&gt;:&lt;port&gt;:EE.oracle.docker或者jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=&lt;ip&gt;)(PORT=&lt;port&gt;))(CONNECT_DATA=(SERVER=DEDICATED)(SERVICE_NAME=EE.oracle.docker)))]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[监控 Java 应用信息]]></title>
    <url>%2Fposts%2F8d68f4e0.html</url>
    <content type="text"><![CDATA[信息输出 主要输出CPU、内存、线程、链接等使用情况 123456789101112131415#[yl@yl-test ~]$ curl http://localhost:8080/moniter-java.sh -s | sh[yl@yl-test ~]$ sh moniter-java.sh==================== 2020-06-01 10:57:09 ====================(Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) USER STIME | %CPU %MEM thrd | conn dbLn | lsnPorts:conn:wait | PID | path root Apr30 | 0.0 1.5 21 | | | 1394 | imhtp May28 | 0.0 5.1 38 | | | 14510 | /opt/timer/data-job.jar imhtp May08 | 0.0 5.5 36 | 10 3 | 20880:5:0 | 1484 | /opt/ds-service/project/ds-service.jar imhtp May18 | 0.0 11.4 37 | 1 0 | 8021 | 1171 | /opt/xmt/tomcat/ imhtp Apr30 | 0.0 5.4 17 | 19 0 | 2080:19:0 40540 | 2613 | /opt/zookeeper/zookeeper-3.4.10.jar==================== 2020-06-01 10:57:09 ==================== 查询脚本 moniter-java.sh 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141#!/bin/bash# to moniter the java applicationsechoecho "==================== $(date "+%F %T") ===================="#declare -A aPid aUser aCpu aMem aStime aThrd aDbln aConn aPort aJarmarkTHR()&#123; if [ -n "$2" ] &amp;&amp; [ "$&#123;2%.*&#125;" -ge "$1" ]; then echo -n "\033[1;31m%$&#123;3&#125;s\033[0m" else echo -n "%$&#123;3&#125;s" fi&#125;markConn()&#123; awk '&#123; len=(20&gt;length($0)) ? 20-length($0) : 0; if(!length($0)) $1=""; for(i=1;i&lt;=NF;i++)&#123; if($i~/^u/) printf "\033[1;32m%s\033[0m",$i; else if($i~/:/) printf "\033[1;34m%s\033[0m",$i; else printf "%s",$i; printf "%s"," "; &#125; printf "%"len"s",""; &#125;' &lt;&lt;&lt; "$*"&#125;myPrtf()&#123; printf "%9s " "$1" # process username printf "%5s |" "$2" # process start time printf "$(markTHR 10 "$3" 5) " "$3" # process cpu usage printf "$(markTHR 10 "$4" 5) " "$4" # process memory usage printf "$(markTHR 100 "$5" 4) | " "$5" # process threads count printf "$(markTHR 100 "$6" 4) " "$6" # network connections count printf "$(markTHR 30 "$7" 4) | " "$7" # database connections count printf "$(markConn $8)| " # listen ports printf "%5s | " "$&#123;9&#125;" # process id printf "%s\n" "$&#123;10&#125;" # jar file/path&#125;getBasicCmd=$(/bin/ps -eo pid,user,pcpu,pmem,stime,nlwp,args 2&gt;/dev/null | grep [j]ava | awk '&#123; print "aPid["NR"]="$1";"; print "aUser["$1"]="$2";"; print "aCpu["$1"]="$3";"; print "aMem["$1"]="$4";"; print "aStime["$1"]="$5";"; print "aThrd["$1"]="$6";"; &#125;' 2&gt;/dev/null)eval $getBasicCmdgetPortCmd=$(/bin/netstat -natup | grep -E 'java|-' | awk ' $1~/^tcp/&#123; gsub(/[^:]*:/,"",$4); gsub(/[^:]*:/,"",$5); gsub(/\/.*$/,"",$7); &#125; $1~/^udp/&#123; gsub(/[^:]*:/,"",$4); $4=($1~/^udp/)?"u"$4:$4; gsub(/[^:]*:/,"",$5); $7=($5=="*")?$6:$7; gsub(/\/.*$/,"",$7); &#125; $5=="*" &amp;&amp; $7~/[0-9]+/&#123; lsnArr[$7,$4]++; conn[$7]=0; dblink[$7]=0; &#125; $5!="*" &amp;&amp; $7~/[0-9]+/&#123; conn[$7]++; if(!dblink[$7]) dblink[$7]=0; if($5==1521) dblink[$7]++; if(lsnArr[$7,$4]) workArr[$7,$4]++; &#125; $7=="-"&#123; tw[$4]++; &#125; END&#123; for(i in lsnArr)&#123; split(i,lsn,SUBSEP); if(lsnArr[i])&#123; workCount = (workArr[i]) ? ":"workArr[i] : ":"0; waitCount = (tw[lsn[2]]) ? ":"tw[lsn[2]] : ":"0; if(workCount==":0" &amp;&amp; waitCount==":0")&#123; workCount=""; waitCount=""; &#125; workStr[lsn[1]]=workStr[lsn[1]]" "lsn[2] workCount waitCount; twCount[lsn[1]] += tw[lsn[2]]; &#125; &#125; for(i in conn)&#123; print "aConn["i"]="conn[i]";"; print "aWait["i"]="twCount[i]";"; print "aDbln["i"]="dblink[i]";"; print "aPort["i"]=\""workStr[i]"\";"; &#125; &#125;' 2&gt;/dev/null)eval $getPortCmdgetJarCmd=$(/usr/sbin/lsof -nc java | grep '.jar$' | grep -v '/jre/lib/' | awk ' /bootstrap.jar/&#123; gsub(/bin\/bootstrap.jar/,"",$9); jar[$2]=$9; &#125; /jetty/ &amp;&amp; /start/&#123; jar[$2]=$9; &#125; /knity/&#123; jar[$2]=$9; &#125; !/bootstrap.jar/ &amp;&amp; !jar[$2]&#123; jar[$2]=$9; &#125; END&#123; for(i in jar)&#123; print "aJar["i"]="jar[i]";"; &#125; &#125;' 2&gt;/dev/null)eval $getJarCmdprintf "\033[1m%9s %5s |%5s %5s %4s | %4s %4s | %-20s | %5s | %s\033[0m\n" \ "USER" "STIME" "%CPU" "%MEM" "thrd" "conn" "dbLn" "lsnPorts:conn:wait" "PID" "path"unset PIDdeclare -i PIDfor PID in $&#123;aPid[*]&#125;do myPrtf "$&#123;aUser[$PID]&#125;" "$&#123;aStime[$PID]&#125;" "$&#123;aCpu[$PID]&#125;" "$&#123;aMem[$PID]&#125;" "$&#123;aThrd[$PID]&#125;" "$&#123;aConn[$PID]&#125;" "$&#123;aDbln[$PID]&#125;" "$&#123;aPort[$PID]&#125;" "$PID" "$&#123;aJar[$PID]&#125;"done | sort -t'|' -k6 | sed 'n;n;n;n;G'echo "==================== $(date "+%F %T") ===================="echo]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle 按分区同步数据到另一个库]]></title>
    <url>%2Fposts%2F4d2ee75e.html</url>
    <content type="text"><![CDATA[需求A库中某些大表（1年数据量10+亿条）数据只保留最近3个月数据，超过3个月的数据，都迁移到B库中保存，然后删除A库中已经迁移的数据。 A库123-- 创建视图，指定分区条件CREATE OR REPLACE VIEW V_IM_WX_LOG AS SELECT * FROM IM_WX_LOG PARTITION(P2019Y03); B库12345-- 为A库视图创建同义词CREATE SYNONYM V_IM_WX_LOG FOR V_IM_WX_LOG@DBLN_WEIXINDB_KBT;-- 同步数据CREATE TABLE IM_WX_LOG_P2019Y03 AS SELECT * FROM V_IM_WX_LOG; A库123456ALTER TABLE IM_WX_LOG DROP PARTITION P2019Y03;-- 如果索引不是nologging local类型，则需要重建索引alter index PK_ID rebuild online;-- 或者直接使用以下语句ALTER TABLE IM_WX_LOG DROP PARTITION P2019Y03 UPDATE IDEXES;]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo 优雅停机 restart 脚本]]></title>
    <url>%2Fposts%2Fa6adaf74.html</url>
    <content type="text"><![CDATA[优雅停机 使用 kill -9 pid 不能优雅停机 使用 kill pid 可以优雅停机 停机脚本 restart.sh 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273#!/usr/bin/env bashexport LANG=en_US.UTF-8export JAVA_HOME=/usr/java/jdk1.8.0_144export PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$CLASSPATHcd `dirname $0`CURRENT_DIR=`pwd`LOGS_DIR=$CURRENT_DIR/logsSTDOUT_FILE=$CURRENT_DIR/logs/stdout.logPROJECT_HOME=$CURRENT_DIR/projectJAR_FILE=$PROJECT_HOME/dubbo-provider.jar# pidPIDS=`ps -ef | grep java | grep -v grep | grep "$JAR_FILE" | awk '&#123;print $2&#125;'`# Graceful shutdownfunction gracefulShutdown()&#123; if [ -z "$PIDS" ]; then echo "[$(date '+%Y-%m-%d %H:%M:%S')] $JAR_FILE does not started!" | tee -a $STDOUT_FILE else echo "[$(date '+%Y-%m-%d %H:%M:%S')] $JAR_FILE kill $PIDS begining" | tee -a $STDOUT_FILE for PID in $PIDS ; do kill $PID &gt; /dev/null 2&gt;&amp;1 echo "[$(date '+%Y-%m-%d %H:%M:%S')] $JAR_FILE kill $PID success" | tee -a $STDOUT_FILE done # check for graceful shutdown COUNT=0 while [ $COUNT -lt 1 ]; do sleep 1 COUNT=1 for PID in $PIDS ; do PID_EXIST=`ps -f -p $PID | grep java` if [ -n "$PID_EXIST" ]; then COUNT=0 break fi done done fi&#125;function operate()&#123; if [[ "$1" = "kill" ]]; then gracefulShutdown elif [[ "$1" = "start" ]] ; then cd $PROJECT_HOME # starting nohup $JAVA_HOME/bin/java -server -Xms1g -Xmx1g -Xss256k -Dloader.path=$PROJECT_HOME/lib/ -Djava.io.tmpdir=$LOGS_DIR -XX:+DisableExplicitGC -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:LargePageSizeInBytes=128m -XX:+UseFastAccessorMethods -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=70 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=$LOGS_DIR/$PIDS.hprof -Ddubbo.protocol.port=20882 -Dspring.profiles.active=pro -jar $JAR_FILE &gt;&gt; $STDOUT_FILE 2&gt;&amp;1 &amp; PIDS=`ps -ef | grep java | grep -v grep | grep "$JAR_FILE" | awk '&#123;print $2&#125;'` echo "[$(date '+%Y-%m-%d %H:%M:%S')] $JAR_FILE started OK! pid: $PIDS" | tee -a $STDOUT_FILE else echo "[$(date '+%Y-%m-%d %H:%M:%S')] $JAR_FILE is not support $1" | tee -a $STDOUT_FILE fi&#125;if [[ "$1" = "start" || "$1" = "check" ]]; then if [ -n "$PIDS" ]; then echo "[$(date '+%Y-%m-%d %H:%M:%S')] $JAR_FILE already started! pid: $PIDS" &gt;&gt; $STDOUT_FILE exit 1 fi operate startelif [[ "$1" = "" || "$1" = "restart" ]]; then operate kill echo "[$(date '+%Y-%m-%d %H:%M:%S')] $JAR_FILE starting" | tee -a $STDOUT_FILE operate startelif [[ "$1" = "kill" ]]; then operate killelse echo "[$(date '+%Y-%m-%d %H:%M:%S')] $JAR_FILE is not support $1" | tee -a $STDOUT_FILEfi 使用说明12345sh restart.sh start # 启动sh restart.sh # 重启sh restart.sh restart # 重启sh restart.sh check # 检测服务是否启动，没有启动，则启动之，否则不做其他操作sh restart.sh kill # kill 掉已启动的服务进程]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Apache</tag>
        <tag>shell</tag>
        <tag>alibaba</tag>
        <tag>Dubbo</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac Kettle 安装]]></title>
    <url>%2Fposts%2F9fd2e395.html</url>
    <content type="text"><![CDATA[下载https://sourceforge.net/projects/pentaho/files/ 版本：9.1 安装下载 zip 包后，解压到相应目录即可 启动执行spoon.command启动 kettle 启动异常12345678910111213141516171819202122232425262728293031323334java.lang.NullPointerExceptionat org.eclipse.swt.widgets.Control.internal_new_GC(Unknown Source)at org.eclipse.swt.graphics.GC.&lt;init&gt;(Unknown Source)at org.eclipse.swt.graphics.GC.&lt;init&gt;(Unknown Source)at org.eclipse.swt.custom.CTabFolder.updateTabHeight(Unknown Source)at org.eclipse.swt.custom.CTabFolder.runUpdate(Unknown Source)at org.eclipse.swt.custom.CTabItem.getBounds(Unknown Source)at org.eclipse.swt.custom.CTabFolder.onPaint(Unknown Source)at org.eclipse.swt.custom.CTabFolder$1.handleEvent(Unknown Source)at org.eclipse.swt.widgets.EventTable.sendEvent(Unknown Source)at org.eclipse.swt.widgets.Display.sendEvent(Unknown Source)at org.eclipse.swt.widgets.Widget.sendEvent(Unknown Source)at org.eclipse.swt.widgets.Widget.sendEvent(Unknown Source)at org.eclipse.swt.widgets.Widget.sendEvent(Unknown Source)at org.eclipse.swt.widgets.Control.drawWidget(Unknown Source)at org.eclipse.swt.widgets.Widget.drawRect(Unknown Source)at org.eclipse.swt.widgets.Display.windowProc(Unknown Source)at org.eclipse.swt.internal.cocoa.OS.objc_msgSendSuper(Native Method)at org.eclipse.swt.widgets.Display.applicationNextEventMatchingMask(Unknown Source)at org.eclipse.swt.widgets.Display.applicationProc(Unknown Source)at org.eclipse.swt.internal.cocoa.OS.objc_msgSend(Native Method)at org.eclipse.swt.internal.cocoa.NSApplication.nextEventMatchingMask(Unknown Source)at org.eclipse.swt.widgets.Display.readAndDispatch(Unknown Source)at org.pentaho.di.ui.spoon.Spoon.readAndDispatch(Spoon.java:1385)at org.pentaho.di.ui.spoon.Spoon.waitForDispose(Spoon.java:7968)at org.pentaho.di.ui.spoon.Spoon.start(Spoon.java:9350)at org.pentaho.di.ui.spoon.Spoon.main(Spoon.java:711)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:498)at org.pentaho.commons.launcher.Launcher.main(Launcher.java:92)2019-12-23 12:31:23 - Spoon - Spoon 已经结束.stopping 问题原因由于 jdk 版本不兼容导致，不能高于 JAVA 8 242 版本 解决方案方案一：卸载高版本 jdk，重新下载 jdk 1.8 242或以下版本安装 方案二：从https://www.azul.com/downloads/zulu-community/?version=java-8-lts&amp;os=macos&amp;architecture=x86-64-bit&amp;package=jdk&amp;show-old-builds=true下载 JAVA 8 242 版本，解压 zip 后，将解压后的文件放到$KETTLE_HOME/java下。参考：https://jira.pentaho.com/browse/PDI-18866]]></content>
      <categories>
        <category>kettle</category>
      </categories>
      <tags>
        <tag>kettle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kettle 配置及问题汇总]]></title>
    <url>%2Fposts%2Fa426a84b.html</url>
    <content type="text"><![CDATA[共享配置默认共享数据保存在用户目录的share.xml文件。可以通过修改kettle.properties来修改保存位置 123# Custom Setting# 会在kettle安装目录生成一个share.cache文件，并把共享数据保存到该文件KETTLE_SHARED_OBJECTS=share.cache 共享 step 后出现异常共享DB连接无此问题。 share.xml默认utf-8是编码，当共享step后编码变了ANSI，导致读取共享数据出错。将share.xml手动utf-8编码可以解决问题。]]></content>
      <categories>
        <category>kettle</category>
      </categories>
      <tags>
        <tag>kettle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式锁]]></title>
    <url>%2Fposts%2F4eb3381c.html</url>
    <content type="text"><![CDATA[spring-integration-redis 初始化 RedisLockRegistry 12345@Beanpublic RedisLockRegistry redisLockRegistry (RedisConnectionFactory factory) &#123; // 60s过期，单位：ms return RedisLockRegistry(factory, "ts-template", 60000L);&#125; 使用 123456789101112131415161718192021@Resourceprivate RedisLockRegistry redisLockRegistry;public void send(String message) &#123; // 获取锁 Lock lock = redisLockRegistry.obtain(message); try &#123; // 上锁 if (lock.tryLock()) &#123; // 业务逻辑 // ... &#125; &#125; catch() &#123; // 异常处理 &#125; finally &#123; // 删除当前未锁定的旧锁：要手动调用一下这个函数，否则 RedisLockRegistry 中的 locks 对象会越来越大，因为调用 unlock 之后，不会自动删除 locks 中保存的当前锁的对象。但是调用这个删除逻辑最好是通过定时器去调用，因为如果 locks 对象中数据量很大，每次都要迭代一次会很耗时 redisLockRegistry.expireUnusedOlderThan(10*60*1000L); // 释放锁 lock.unlock(); &#125;&#125; 通过定时器调用 expireUnusedOlderThan 12345678@Resourceprivate RedisLockRegistry redisLockRegistry;@Scheduled(fixedDelay=10*60*1000)public void expireUnusedOlderThan() &#123; // 删除当前未锁定的旧锁 redisLockRegistry.expireUnusedOlderThan(10*60*1000L);&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kettle-Java代码：分布式Id生成器]]></title>
    <url>%2Fposts%2F4f2ec68b.html</url>
    <content type="text"><![CDATA[当使用Kettle导入数据到数据表时，由于使用的是Oracle，所以自然而然想到使用增加序列对象去获取一个Id，但是经过测试这种方式非常慢。 以下对比2种不同方式的导入速度： 序列生成Id 分布式Id生成器 速度比较序列 转换 执行结果 从图片可以看出来，使用序列生成Id的方式，导入数据是会非常慢。10分钟才导入2w多条记录。 分布式Id生成器请参考：分布式Id生成器 使用 将以上 分布式Id生成器 文章的代码打包成jar包，放到kettle/lib文件夹下。假设包名、类名：top.ylonline.common.keygen.SnowflakeKeyGenerator.java 转换 Java代码对象 12345678910111213141516171819202122232425262728293031323334import java.lang.*;// 一定要在这里初始化，不能在函数体里面，否则导致每处理一行记录，都会初始化一次生成器，从而导致会出现重复Idtop.ylonline.common.keygen.SnowflakeKeyGenerator snowflake = new top.ylonline.common.keygen.SnowflakeKeyGenerator();String snowFlowIdFeild;public boolean processRow(StepMetaInterface smi, StepDataInterface sdi) throws KettleException&#123; // First, get a row from the default input hop Object[] r = getRow(); // If the row object is null, we are done processing. if (r == null) &#123; setOutputDone(); return false; &#125; // Let's look up parameters only once for performance reason. if (first) &#123; snowFlowIdFeild = getParameter("SNOWFLOW_ID_FEILD"); first=false; &#125; // It is always safest to call createOutputRow() to ensure that your output row's Object[] is large // enough to handle any new fields you are creating in this step. Object[] outputRow = createOutputRow(r, data.outputRowMeta.size()); // 获取分布式 Id String id = String.valueOf(snowflake.generateKey()); // logBasic("id: " + id); get(Fields.Out, snowFlowIdFeild).setValue(outputRow, id); // putRow will send the row on to the default output hop. putRow(data.outputRowMeta, outputRow); return true;&#125; 字段配置 字段名：snowflake_id 类型：String 参数配置 标签：SNOWFLOW_ID_FEILD 值：snowflake_id 执行结果]]></content>
      <categories>
        <category>kettle</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Snowflake</tag>
        <tag>kettle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring cache 动态配置缓存过期时间]]></title>
    <url>%2Fposts%2F23adfb31.html</url>
    <content type="text"><![CDATA[思路 第 1 步 自定义 CacheResolver 通过 CacheOperationInvocationContext 获取到方法的参数名和参数值 重写一个 cacheName（原始cacheName + 过期时间拼接在一起） 第 2 步 重写 CacheManger 的 getMissingCache 方法 在 getMissingCache 方法中读取到第 1 步 cacheName 中过期时间 初始化一个 cache 实例 问题由于该实现是重新构建一个cacheName，这样会导致配合CachePut、CacheEvict等使用时会有问题。 关键代码 Expired.java 123456789101112131415161718192021222324252627282930313233import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Inherited;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;/** * 自定义缓存过期时间配置注解，过期时间单位：s（秒） * &lt;p&gt; * 如果要使用 &amp;#64;&#123;@link Expired&#125;注解，需要启用 &amp;#64;&#123;@link EnableTRedisConfiguration&#125; * * @author YL */@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Inherited@Documentedpublic @interface Expired &#123; /** * expire time, default 60s. */ long value() default 60; /** * Spring Expression Language (SpEL) expression for computing the expire time dynamically. * * &lt;p&gt; * 与 &#123;@link #value()&#125; 属性互斥. 使用该属性配置的过期时间优先级比 &#123;@link #value()&#125; 属性高。由于该实现是重新构建一个cacheName，这样会导致配合CachePut、CacheEvict等使用时会有问题。 * &lt;/p&gt; */ String spEl() default "";&#125; TSimpleCacheResolver.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485import top.ylonline.common.redis.anno.Expired;import top.ylonline.common.util.StrUtils;import lombok.extern.slf4j.Slf4j;import org.springframework.cache.CacheManager;import org.springframework.cache.interceptor.AbstractCacheResolver;import org.springframework.cache.interceptor.CacheOperationInvocationContext;import org.springframework.context.expression.MethodBasedEvaluationContext;import org.springframework.core.LocalVariableTableParameterNameDiscoverer;import org.springframework.core.annotation.AnnotationUtils;import org.springframework.expression.EvaluationContext;import org.springframework.expression.Expression;import org.springframework.expression.ExpressionParser;import org.springframework.expression.spel.standard.SpelExpressionParser;import org.springframework.expression.spel.support.StandardEvaluationContext;import org.springframework.util.ObjectUtils;import java.lang.reflect.Method;import java.util.Arrays;import java.util.Collection;import java.util.HashSet;import java.util.Set;/** * 自定义 &#123;@link org.springframework.cache.interceptor.CacheResolver&#125; 以实现动态过期时间配置 * * @author YL */@Slf4jpublic class TSimpleCacheResolver extends AbstractCacheResolver &#123; public TSimpleCacheResolver(CacheManager cacheManager) &#123; super(cacheManager); &#125; private ExpressionParser parser = new SpelExpressionParser(); private LocalVariableTableParameterNameDiscoverer discoverer = new LocalVariableTableParameterNameDiscoverer(); @Override protected Collection&lt;String&gt; getCacheNames(CacheOperationInvocationContext&lt;?&gt; context) &#123; Method method = context.getMethod(); Object[] args = context.getArgs(); Set&lt;String&gt; cacheNames = context.getOperation().getCacheNames(); Expired expired = AnnotationUtils.findAnnotation(method, Expired.class); if (expired == null || StrUtils.isBlank(expired.spEl())) &#123; return cacheNames; &#125; // Shortcut if no args need to be loaded if (ObjectUtils.isEmpty(args)) &#123; return cacheNames; &#125; // Expose indexed variables as well as parameter names (if discoverable) String[] paramNames = this.discoverer.getParameterNames(method); int paramCount = (paramNames != null ? paramNames.length : method.getParameterCount()); int argsCount = args.length; EvaluationContext eval = new StandardEvaluationContext(); for (int i = 0; i &lt; paramCount; i++) &#123; Object value = null; if (argsCount &gt; paramCount &amp;&amp; i == paramCount - 1) &#123; // Expose remaining arguments as vararg array for last parameter value = Arrays.copyOfRange(args, i, argsCount); &#125; else if (argsCount &gt; i) &#123; // Actual argument found - otherwise left as null value = args[i]; &#125; /** * see &#123;@link MethodBasedEvaluationContext#lazyLoadArguments()&#125; */ eval.setVariable("a" + i, value); eval.setVariable("p" + i, value); if (paramNames != null) &#123; eval.setVariable(paramNames[i], value); &#125; &#125; Expression expression = parser.parseExpression(expired.spEl()); Long ttl = expression.getValue(eval, Long.class); if (ttl != null &amp;&amp; ttl &lt;= 0) &#123; return cacheNames; &#125; Set&lt;String&gt; names = new HashSet&lt;&gt;(); for (String cacheName : cacheNames) &#123; names.add(cacheName + ".exp_" + ttl); &#125; return names; &#125;&#125; TRedisCacheManager.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181package top.ylonline.common.redis.cache;import top.ylonline.common.redis.anno.Expired;import top.ylonline.common.redis.util.CacheUtils;import top.ylonline.common.util.StrUtils;import com.alibaba.fastjson.support.spring.GenericFastJsonRedisSerializer;import lombok.Getter;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.BeansException;import org.springframework.beans.factory.InitializingBean;import org.springframework.cache.Cache;import org.springframework.cache.annotation.CacheConfig;import org.springframework.cache.annotation.Cacheable;import org.springframework.cache.annotation.Caching;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import org.springframework.core.annotation.AnnotationUtils;import org.springframework.data.redis.cache.RedisCache;import org.springframework.data.redis.cache.RedisCacheConfiguration;import org.springframework.data.redis.cache.RedisCacheManager;import org.springframework.data.redis.cache.RedisCacheWriter;import org.springframework.data.redis.serializer.RedisSerializationContext;import org.springframework.data.redis.serializer.StringRedisSerializer;import org.springframework.util.ReflectionUtils;import java.time.Duration;import java.util.Collection;import java.util.LinkedHashMap;import java.util.LinkedList;import java.util.List;import java.util.Map;import java.util.regex.Matcher;import java.util.regex.Pattern;/** * 自定义 RedisCacheManager 缓存管理器 * &lt;pre&gt; * support spring-data-redis 1.8.10.RELEASE * not support spring-data-redis 2.0.0.RELEASE + * &lt;/pre&gt; * * @author YL */@Slf4jpublic class TRedisCacheManager extends RedisCacheManager implements ApplicationContextAware, InitializingBean &#123; private ApplicationContext applicationContext; private Map&lt;String, RedisCacheConfiguration&gt; initialCacheConfiguration = new LinkedHashMap&lt;&gt;(); /** * key serializer */ public static final StringRedisSerializer STRING_SERIALIZER = new StringRedisSerializer(); /** * value serializer * &lt;pre&gt; * 使用 FastJsonRedisSerializer 会报错：java.lang.ClassCastException * FastJsonRedisSerializer&lt;Object&gt; fastSerializer = new FastJsonRedisSerializer&lt;&gt;(Object.class); * &lt;/pre&gt; */ public static final GenericFastJsonRedisSerializer FASTJSON_SERIALIZER = new GenericFastJsonRedisSerializer(); /** * key serializer pair */ public static final RedisSerializationContext.SerializationPair&lt;String&gt; STRING_PAIR = RedisSerializationContext .SerializationPair.fromSerializer(STRING_SERIALIZER); /** * value serializer pair */ public static final RedisSerializationContext.SerializationPair&lt;Object&gt; FASTJSON_PAIR = RedisSerializationContext .SerializationPair.fromSerializer(FASTJSON_SERIALIZER); @Getter private RedisCacheConfiguration defaultCacheConfig; public TRedisCacheManager(RedisCacheWriter cacheWriter, RedisCacheConfiguration defaultCacheConfig) &#123; super(cacheWriter, defaultCacheConfig); this.defaultCacheConfig = defaultCacheConfig; &#125; // public TedisCacheManager(RedisCacheWriter cacheWriter, RedisCacheConfiguration defaultCacheConfiguration, // Map&lt;String, RedisCacheConfiguration&gt; initialCacheConfigurations) &#123; // super(cacheWriter, defaultCacheConfiguration, initialCacheConfigurations); // &#125; @Override public Cache getCache(String name) &#123; Cache cache = super.getCache(name); return new TRedisCacheWrapper(cache); &#125; @Override protected RedisCache getMissingCache(String name) &#123; RedisCacheConfiguration config = getRedisCacheConfiguration(name, computeTtl(name)); return super.createRedisCache(name, config); &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; &#125; @Override public void afterPropertiesSet() &#123; String[] beanNames = applicationContext.getBeanNamesForType(Object.class); for (String beanName : beanNames) &#123; final Class&lt;?&gt; clazz = applicationContext.getType(beanName); doWith(clazz); &#125; super.afterPropertiesSet(); &#125; @Override protected Collection&lt;RedisCache&gt; loadCaches() &#123; List&lt;RedisCache&gt; caches = new LinkedList&lt;&gt;(); for (Map.Entry&lt;String, RedisCacheConfiguration&gt; entry : initialCacheConfiguration.entrySet()) &#123; caches.add(super.createRedisCache(entry.getKey(), entry.getValue())); &#125; return caches; &#125; private void doWith(final Class&lt;?&gt; clazz) &#123; ReflectionUtils.doWithMethods(clazz, method -&gt; &#123; ReflectionUtils.makeAccessible(method); Expired expired = AnnotationUtils.findAnnotation(method, Expired.class); Cacheable cacheable = AnnotationUtils.findAnnotation(method, Cacheable.class); Caching caching = AnnotationUtils.findAnnotation(method, Caching.class); CacheConfig cacheConfig = AnnotationUtils.findAnnotation(clazz, CacheConfig.class); List&lt;String&gt; cacheNames = CacheUtils.getCacheNames(cacheable, caching, cacheConfig); add(cacheNames, expired); &#125;, method -&gt; null != AnnotationUtils.findAnnotation(method, Expired.class)); &#125; private void add(List&lt;String&gt; cacheNames, Expired expired) &#123; for (String cacheName : cacheNames) &#123; if (cacheName == null || "".equals(cacheName.trim())) &#123; continue; &#125; long expire = expired.value(); if (log.isDebugEnabled()) &#123; log.debug("cacheNames: &#123;&#125;, expire: &#123;&#125;s", cacheNames, expire); &#125; if (expire &gt;= 0) &#123; RedisCacheConfiguration config = getRedisCacheConfiguration(cacheName, Duration.ofSeconds(expire)); initialCacheConfiguration.put(cacheName, config); &#125; else &#123; log.warn("&#123;&#125; use default expiration.", cacheName); &#125; &#125; &#125; private RedisCacheConfiguration getRedisCacheConfiguration(String cacheName, Duration ttl) &#123; boolean allowCacheNullValues = defaultCacheConfig.getAllowCacheNullValues(); boolean useKeyPrefix = defaultCacheConfig.usePrefix(); String keyPrefix = defaultCacheConfig.getKeyPrefixFor(cacheName); RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig() .entryTtl(ttl) .serializeKeysWith(TRedisCacheManager.STRING_PAIR) .serializeValuesWith(TRedisCacheManager.FASTJSON_PAIR); if (useKeyPrefix &amp;&amp; StrUtils.isNotBlank(keyPrefix)) &#123; config = config.prefixKeysWith(keyPrefix); &#125; if (!allowCacheNullValues) &#123; config = config.disableCachingNullValues(); &#125; return config; &#125; Pattern pattern = Pattern.compile("\\.exp_(\\d+)"); private Duration computeTtl(String cacheName) &#123; Matcher matcher = pattern.matcher(cacheName); if (matcher.find()) &#123; return Duration.ofSeconds(Long.parseLong(matcher.group(1))); &#125; return defaultCacheConfig.getTtl(); &#125;&#125; 测试123456789101112131415161718192021222324// RedisService.java@Cacheable( value = "redis.v1.service", condition = "#cache eq true", unless = "#result == null or #result.empty")@Expired(spEl = "#id")// @Expired(spEl = "#p1")// @Expired(spEl = "#a1")public Map&lt;String, Object&gt; get(boolean cache, Long id) &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("id", id); map.put("name", "name-" + id); log.info("map: &#123;&#125;", map); return map;&#125;// RedisServiceTest.java@Testpublic void testGet() &#123; Map&lt;String, Object&gt; map = redisService.get(true, 1234L); log.info("map ---&gt; &#123;&#125;", map);&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OkHttp 动态超时时间配置]]></title>
    <url>%2Fposts%2Feb373e45.html</url>
    <content type="text"><![CDATA[思路 自定义一个拦截器 在拦截器中重置超时时间等配置 关键代码 HeadersEx.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107import lombok.Getter;import okhttp3.Headers;/** * @author YL */public class HeadersEx &#123; private static final String NAME = HeadersEx.class.getSimpleName(); public static final String CONNECT_TIMEOUT = NAME + ".connectTimeout"; public static final String WRITE_TIMEOUT = NAME + ".writeTimeout"; public static final String READ_TIMEOUT = NAME + ".readTimeout"; public static final String PRINT_LOG = NAME + ".printLog"; @Getter private final Integer connectTimeout; @Getter private final Integer writeTimeout; @Getter private final Integer readTimeout; @Getter private final boolean printLog; private HeadersEx(Integer connectTimeout, Integer writeTimeout, Integer readTimeout, boolean printLog) &#123; super(); this.connectTimeout = connectTimeout; this.writeTimeout = writeTimeout; this.readTimeout = readTimeout; this.printLog = printLog; &#125; public static HeadersEx.Builder defaultConfig() &#123; return new Builder(); &#125; public static final class Builder &#123; private Integer connectTimeout; private Integer writeTimeout; private Integer readTimeout; private boolean printLog = true; Builder() &#123; &#125; /** * 配置 connectTimeout，单位：ms * * @param connectTimeout 链接超时时间 */ public Builder connectTimeout(Integer connectTimeout) &#123; this.connectTimeout = connectTimeout; return this; &#125; /** * 配置 writeTimeout，单位：ms * * @param writeTimeout 请求超时时间 */ public Builder writeTimeout(Integer writeTimeout) &#123; this.writeTimeout = writeTimeout; return this; &#125; /** * 配置 readTimeout，单位：ms * * @param readTimeout 响应超时时间 */ public Builder readTimeout(Integer readTimeout) &#123; this.readTimeout = readTimeout; return this; &#125; /** * 配置日志打印开关 * * @param printLog 是否打印request body、response body等日志 */ public Builder printLog(boolean printLog) &#123; this.printLog = printLog; return this; &#125; HeadersEx build() &#123; return new HeadersEx(this.connectTimeout, this.writeTimeout, this.readTimeout, this.printLog); &#125; &#125; /** * 配置读取超时时间 * * @param builder 响应超时时间：s */ public static Headers of(HeadersEx.Builder builder) &#123; HeadersEx build = builder.build(); Integer connectTimeout = build.getConnectTimeout(); Integer writeTimeout = build.getWriteTimeout(); Integer readTimeout = build.getReadTimeout(); boolean printLog = build.isPrintLog(); return Headers.of( CONNECT_TIMEOUT, connectTimeout == null ? "" : String.valueOf(connectTimeout.intValue()), WRITE_TIMEOUT, writeTimeout == null ? "" : String.valueOf(writeTimeout.intValue()), READ_TIMEOUT, readTimeout == null ? "" : String.valueOf(readTimeout.intValue()), PRINT_LOG, String.valueOf(printLog) ); &#125;&#125; TimeoutInterceptor.java 12345678910111213141516171819202122232425262728293031323334353637383940414243import top.ylonline.common.okhttp.util.HeadersEx;import top.ylonline.common.util.StrUtils;import lombok.extern.slf4j.Slf4j;import okhttp3.Interceptor;import okhttp3.Request;import okhttp3.Response;import java.io.IOException;import java.util.concurrent.TimeUnit;/** * 动态配置 connectTimeout、writeTimeout、readTimeout 超时时间拦截器 * * @author YL */@Slf4jpublic class TimeoutInterceptor implements Interceptor &#123; @Override public Response intercept(Chain chain) throws IOException &#123; Request request = chain.request(); String connectTimeout = request.header(HeadersEx.CONNECT_TIMEOUT); if (StrUtils.isNotBlank(connectTimeout)) &#123; // 动态修改：连接超时时间 chain = chain.withConnectTimeout(Integer.parseInt(connectTimeout), TimeUnit.MILLISECONDS); &#125; String writeTimeout = request.header(HeadersEx.WRITE_TIMEOUT); if (StrUtils.isNotBlank(writeTimeout)) &#123; // 动态修改：请求超时时间 chain = chain.withWriteTimeout(Integer.parseInt(writeTimeout), TimeUnit.MILLISECONDS); &#125; String readTimeout = request.header(HeadersEx.READ_TIMEOUT); if (StrUtils.isNotBlank(readTimeout)) &#123; // 动态修改：响应超时时间 chain = chain.withReadTimeout(Integer.parseInt(readTimeout), TimeUnit.MILLISECONDS); &#125; // log.info("connectTimeoutMillis: &#123;&#125;", chain.connectTimeoutMillis()); // log.info("writeTimeoutMillis: &#123;&#125;", chain.writeTimeoutMillis()); // log.info("readTimeoutMillis: &#123;&#125;", chain.readTimeoutMillis()); return chain.proceed(request); &#125;&#125; OkHttpTest.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667private OkHttpClient okHttpClient() &#123; OkHttpCommonProperties props = properties.getCommon(); long connectTimeout = props.getConnectTimeout().toMillis(); long readTimeout = props.getReadTimeout().toMillis(); long writeTimeout = props.getWriteTimeout().toMillis(); int maxIdleConnections = props.getPool().getMaxIdleConnections(); long keepAliveDuration = props.getPool().getKeepAliveDuration().toMillis(); OkHttpClient.Builder builder = new OkHttpClient.Builder(); builder.connectTimeout(connectTimeout, TimeUnit.MILLISECONDS); builder.readTimeout(readTimeout, TimeUnit.MILLISECONDS); builder.writeTimeout(writeTimeout, TimeUnit.MILLISECONDS); builder.retryOnConnectionFailure(false); // 配置连接池 ConnectionPool pool = new ConnectionPool(maxIdleConnections, keepAliveDuration, TimeUnit.MILLISECONDS); builder.connectionPool(pool); // 添加动态超时时间配置拦截器 builder.addInterceptor(new TimeoutInterceptor()); // 添加日志拦截器 // builder.addInterceptor(new LoggingInterceptor()); try &#123; // 添加 https 支持 SSLContext sc = SSLContext.getInstance("SSL"); // SSLContext sc = SSLContext.getInstance("TLS"); DisabledValidationTrustManager trustManager = new DisabledValidationTrustManager(); sc.init(null, new TrustManager[]&#123;trustManager&#125;, new java.security.SecureRandom()); builder.sslSocketFactory(sc.getSocketFactory(), trustManager); builder.hostnameVerifier(NoopHostnameVerifier.INSTANCE); &#125; catch (NoSuchAlgorithmException | KeyManagementException e) &#123; log.error("okhttp init TLS failed."); &#125; return builder.build();&#125;@Testpublic void okHttpClient() throws OkHttpException &#123; OkHttpClient client = okHttpClient(); HeadersEx.Builder builder = HeadersEx.defaultConfig() .connectTimeout(4000) .readTimeout(10000); Request.Builder requestBuilder = new Request.Builder() .url(url) .headers(HeadersEx.of(builder)); Request request = requestBuilder.build(); try (Response response = client.newCall(request).execute()) &#123; if (response == null) &#123; throw new OkHttpException("return response is null"); &#125; ResponseBody body = response.body(); // 如果使用 string()，当数据大于 1MB 时，容易造成内存溢出。推荐使用 byteStream()，记得关闭操作流 // String str = body.string(); String str = body == null ? null : IOUtils.toString(body.byteStream(), charset); System.out.println(str); &#125; catch (SocketTimeoutException e) &#123; throw new OkHttpException("连接超时", e); &#125; catch (Exception e) &#123; throw new OkHttpException(e); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>OkHttp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[druid 开启监控]]></title>
    <url>%2Fposts%2Fe95a2fe2.html</url>
    <content type="text"><![CDATA[依赖包 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.21&lt;/version&gt;&lt;/dependency&gt; 在 application.yml 中配置 StatFilter 相关 123456789101112131415161718192021222324252627282930313233343536373839404142spring: aop: proxy-target-class: true datasource: url: jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=127.0.0.1)(PORT=1521))(CONNECT_DATA=(SERVER=DEDICATED)(SERVICE_NAME=bkimDB))) username: test password: f5AOzZUQ/nGxSSc0iYT0yRlq9+21dzQNHkdv+IKlkIf/I99NZdiAh/3vzUCjRg005FSb0T/LjqwoWuvqzPrv5g== druid: initial-size: 1 min-idle: 1 max-active: 3 max-wait: 60000 keep-alive: true time-between-eviction-runs-millis: 60000 min-evictable-idle-time-millis: 300000 validation-query: SELECT 'x' FROM DUAL test-while-idle: true test-on-borrow: false test-on-return: false pool-prepared-statements: true max-pool-prepared-statement-per-connection-size: 20 filter: wall: enabled: true stat: enabled: true config: enabled: true stat-view-servlet: enabled: true connection-properties: config.decrypt=true;config.decrypt.key=MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAJqw3NwlMJmXvcUbhlOn7VttbKPegs99ToSlKhlvDf4YD04OaD86/csdIVHgKcaCkYWfY3XIh/vJtUOf/QEwG+0CAwEAAQ== stat-view-servlet: enabled: true url-pattern: /druid/* # 1.1.13版本及以上，还需要配置allow、deny allow: deny: jpa: database: oracle properties: hibernate: dialect: org.hibernate.dialect.Oracle10gDialect 关键配置是 123456789101112spring: datasource: druid: filter: stat: enabled: true stat-view-servlet: enabled: true url-pattern: /druid/* # 1.1.13版本及以上，还需要配置allow、deny allow: deny: 访问监控页面 http(s)://host:port/project-name/druid/index.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
        <tag>alibaba</tag>
        <tag>druid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring JCL 的坑]]></title>
    <url>%2Fposts%2F6c1c14ff.html</url>
    <content type="text"><![CDATA[关于Spring-JCL日志的坑 Spring 5.x版本后，Spring-Core中加入了 Spring-JCL 库直接依赖。 目前很多三方库都会依赖 commons-logging 来输出日志，而 Spring-JCL 是对 commons-logging 拷贝复制。 所以 2 个库同时依赖进入项目，会导致冲突。 解决 由于当前项目使用的 slf4j api 来打印日志，所以 exclusion 掉 commons-logging 和 Spring-JCL，引入 slf4j-jcl 库： 12345&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt; &lt;version&gt;$&#123;version&#125;&lt;/version&gt;&lt;/dependency&gt;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云仓库 + 自建私库配置]]></title>
    <url>%2Fposts%2F746cc841.html</url>
    <content type="text"><![CDATA[项目 pom.xml 123456789101112131415&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;maven2-weixin-public&lt;/id&gt; &lt;name&gt;maven2-weixin-public&lt;/name&gt; &lt;url&gt;http://maven.ctim:8081/repository/maven2-weixin-public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;checksumPolicy&gt;fail&lt;/checksumPolicy&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; maven setting.xml 12345678910111213141516171819202122232425262728293031323334353637383940&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;settings xmlns="http://maven.apache.org/SETTINGS/1.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd"&gt; &lt;localRepository&gt;D:/Workspace/Maven/repository&lt;/localRepository&gt; &lt;pluginGroups&gt; &lt;/pluginGroups&gt; &lt;proxies&gt; &lt;/proxies&gt; &lt;servers&gt; &lt;server&gt; &lt;id&gt;maven2-weixin-public&lt;/id&gt; &lt;username&gt;***&lt;/username&gt; &lt;password&gt;***&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;maven2-weixin-release&lt;/id&gt; &lt;username&gt;***&lt;/username&gt; &lt;password&gt;***&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;maven2-weixin-snapshots&lt;/id&gt; &lt;username&gt;***&lt;/username&gt; &lt;password&gt;***&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; &lt;mirrors&gt; &lt;!-- 阿里云仓库 --&gt; &lt;mirror&gt; &lt;id&gt;aliyun-nexus&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;url&gt;https://maven.aliyun.com/repository/public&lt;/url&gt; &lt;/mirror&gt; &lt;!-- 自建私有库 --&gt; &lt;mirror&gt; &lt;id&gt;maven2-weixin-public&lt;/id&gt; &lt;!-- mirrorOf 不能配置成 * --&gt; &lt;mirrorOf&gt;maven2-weixin-public&lt;/mirrorOf&gt; &lt;url&gt;http://maven.ctim:8081/repository/maven2-weixin-public/&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt;&lt;/settings&gt;]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jquery.form.js 使用]]></title>
    <url>%2Fposts%2Fe1e0747e.html</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031var options = &#123; // 把服务器返回的内容放入id为output的元素中 target : '#output', // 提交前的回调函数 beforeSubmit : showRequest, // 提交后的回调函数 success : showResponse, // 默认是form的action， 如果申明，则会覆盖 url : url, // 默认是form的method（get or post），如果申明，则会覆盖 type : type, // json...接受服务端返回的类型 dataType : null, // html(默认), xml, script, // 成功提交后，清除所有表单元素的值 clearForm : true, // 成功提交后，重置所有表单元素的值 resetForm : true, // 限制请求的时间，当请求大于3秒后，跳出请求 timeout : 3000&#125;;jqform.ajaxSubmit(&#123; resetForm : true, beforeSubmit : function() &#123; if ($.trim(vue.dxno) == '') &#123; alert('请您输入的手机号码、固话或者宽带帐号'); &#125; if ($.trim(vue.dxpw) == '') &#123; alert(vue.isrd == 'N' ? '请您输入客户密码' : '请您输入随机码'); &#125; &#125;&#125;);]]></content>
      <categories>
        <category>Javascript</category>
      </categories>
      <tags>
        <tag>jQuery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows 默认软件不可用的问题]]></title>
    <url>%2Fposts%2Fd6d2f549.html</url>
    <content type="text"><![CDATA[在命令行中执行以下命名 1Get-AppXPackage -AllUsers | Foreach &#123;Add-AppxPackage -DisableDevelopmentMode -Register "$($_.InstallLocation)\AppXManifest.xml"&#125; 要关闭360等软件，开启Windows Defender、防火墙]]></content>
      <categories>
        <category>软件</category>
      </categories>
      <tags>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jQuery 扩展新函数，增强ajax、post等方法]]></title>
    <url>%2Fposts%2F66aefafa.html</url>
    <content type="text"><![CDATA[实现$.ajax、$.post的拦截器方法来统一操作一些加解密逻辑 重写$.ajax、$.post 扩展新函数$.ajaxEx、$.postEx 明显这里扩展新函数更加合理。$.get、$.load等扩展也是一样 扩展新函数$.ajaxEx、$.postEx 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129!(function ($, json, Ts) &#123; // 构建 AES 密钥 var aesKey = Ts.AES.randomKey(); // 使用 RSA 公钥加密 AES 密钥 var ak = Ts.RSA.encrypt(publicExponent, modulus, aesKey); // 为 jQuery 添加新函数 $.extend(&#123; ajaxEx: function (url, options) &#123; // If url is an object, simulate pre-1.5 signature if ( typeof url === "object" ) &#123; options = url; url = undefined; &#125; // Force options to be an object options = options || &#123;&#125;; var data = options['data']; if(typeof data === 'string') &#123; throw new Error('opt.data parameter can not be a string!'); &#125; // Force options to be an object data = data || &#123;&#125;; // 使用 AES 加密数据 var enc = Ts.AES.encrypt(aesKey, json.stringify(data)); var fn = &#123; success: null, complete: null &#125;; if (options.success) &#123; fn.success = options.success; &#125; if (options.complete) &#123; fn.complete = options.complete; &#125; var opts = &#123;&#125;; opts['data'] = &#123;&#125;; opts['data']['ak'] = ak; opts['data']['encrypt'] = enc; if (fn.success !== null) &#123; opts['success'] = function (data, ts, xhr) &#123; if (data['errcode'] === '0' &amp;&amp; data &amp;&amp; data['data'] &amp;&amp; data['data']['encrypt']) &#123; var _encrypt = data['data']['encrypt']; // 使用 RSA 解密 AES 密钥，再使用解密出来的密钥解密数据 var _decrypt = Ts.AES.decrypt(Ts.AES.getKey(), _encrypt); var _data = $.extend(&#123;&#125;, data); _data['data'] = eval('(' + _decrypt + ')'); var _xhr = $.extend(&#123;&#125;, xhr); _xhr['responseJSON'] = _data; _xhr['responseText'] = json.stringify(_data); fn.success(_data, ts, _xhr); &#125; else &#123; fn.success(data, ts, xhr); &#125; &#125;; &#125; if (fn.complete !== null) &#123; opts['complete'] = function (xhr, ts) &#123; var data = json.parse(xhr.responseText); if (data['errcode'] === '0' &amp;&amp; data &amp;&amp; data['data'] &amp;&amp; data['data']['encrypt']) &#123; var _encrypt = data['data']['encrypt']; // 使用 RSA 解密 AES 密钥，再使用解密出来的密钥解密数据 data['data'] = json.parse(Ts.AES.decrypt(Ts.AES.getKey(), _encrypt)); var _xhr = $.extend(&#123;&#125;, xhr); _xhr['responseJSON'] = data; _xhr['responseText'] = json.stringify(data); fn.complete(_xhr, ts); &#125; else &#123; fn.complete(xhr, ts); &#125; &#125;; &#125; var _opt = $.extend(options, opts); return $.ajax(url, _opt); &#125;, postEx: function (url, data, callback, type) &#123; // Shift arguments if data argument was omitted if (typeof data === 'function') &#123; type = type || callback; callback = data; data = undefined; &#125; if(typeof data === 'string') &#123; throw new Error('opt.data parameter can not be a string!'); &#125; // Force options to be an object data = data || &#123;&#125;; // 使用 AES 加密数据 var enc = Ts.AES.encrypt(aesKey, json.stringify(data)); var fn = &#123; callback: null &#125;; fn.callback = callback; var _data = &#123;&#125;; _data['ak'] = ak; _data['encrypt'] = enc; if (fn.callback !== null) &#123; callback = function (data, ts, xhr) &#123; if (data['errcode'] === '0' &amp;&amp; data &amp;&amp; data['data'] &amp;&amp; data['data']['encrypt']) &#123; var _encrypt = data['data']['encrypt']; // 使用 RSA 解密 AES 密钥，再使用解密出来的密钥解密数据 var _decrypt = Ts.AES.decrypt(Ts.AES.getKey(), _encrypt); var _data = $.extend(&#123;&#125;, data); _data['data'] = eval('(' + _decrypt + ')'); var _xhr = $.extend(&#123;&#125;, xhr); _xhr['responseJSON'] = _data; _xhr['responseText'] = json.stringify(_data); fn.callback(_data, ts, _xhr); &#125; else &#123; fn.callback(data, ts, xhr); &#125; &#125;; &#125; return $.post(url, _data, callback, type); &#125; &#125;);&#125;)(jQuery, JSON, Ts); 测试 1234567891011121314151617181920212223242526272829303132333435363738$.ajaxEx(&#123; url: 'http://localhost:8080/test', type: 'post', dataType: 'json', data: &#123; 'id': '123', 'name': 'test' &#125;, success: function(data, ts, xhr) &#123; console.log('data: %o', data); console.log('ts: %o', ts); console.log('xhr: %o', xhr); &#125;&#125;);$.ajaxEx(&#123; url: 'http://localhost:8080/test', type: 'post', dataType: 'json', data: &#123; 'id': '123', 'name': 'test' &#125;, complete: function(xhr, ts) &#123; console.log('xhr: %o', xhr); console.log('ts: %o', ts); &#125;&#125;);$.postEx('http://localhost:8080/test', &#123; 'id': '123', 'name': 'test'&#125;, function (data, ts, xhr) &#123; console.log('data: %o', data); console.log('ts: %o', ts); console.log('xhr: %o', xhr);&#125;, 'json');]]></content>
      <categories>
        <category>Javascript</category>
      </categories>
      <tags>
        <tag>jQuery</tag>
        <tag>ajax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XML 使用]]></title>
    <url>%2Fposts%2F9605cdb8.html</url>
    <content type="text"><![CDATA[XML 报文换行 正常换行 123456789&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;soapenv:Envelope xmlns:soapenv="http://schemas.xmlsoap.org/soap/envelope/"&gt; &lt;soapenv:Body&gt; &lt;ns1:message xmlns:ns1="MessageServer"&gt; &lt;ns1:arg0&gt;191&lt;/ns1:arg0&gt; &lt;ns1:arg1&gt;标题：My alert title&amp;#x000A;状态：alerting&amp;#x000A;信息：webfronts&lt;/ns1:arg1&gt; &lt;/ns1:message&gt; &lt;/soapenv:Body&gt;&lt;/soapenv:Envelope&gt; 前提，不能用&lt;![CDATA[]]&gt;把内容包起来，也不能使用\r\n等 12&lt;!-- 这样是不能换行的，会原样显示&amp;#x000A;字符出来 --&gt;&lt;ns1:arg1&gt;&lt;![CDATA[标题：My alert title&amp;#x000A;状态：alerting&amp;#x000A;信息：webfronts]]&gt;&lt;/ns1:arg1&gt;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>XML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 应用 JAR 包部署启动脚本]]></title>
    <url>%2Fposts%2F42919bde.html</url>
    <content type="text"><![CDATA[restart.sh 脚本 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#!/usr/bin/env bash# @Author: YL# @Date: 2019-05-08 15:52:30# @Last Modified by: YL# @Last Modified time: 2019-11-01 09:36:19export LANG=en_US.UTF-8cd `dirname $0`CURRENT_DIR=`pwd`LOGS_DIR=$CURRENT_DIR/logsSTDOUT_FILE=$CURRENT_DIR/logs/stdout.logPROJECT_HOME=$CURRENT_DIR/projectJAR_FILE=$PROJECT_HOME/ts-asig-service.jar# date patternDATE_PATTERN="[$(date '+%Y-%m-%d %H:%M:%S')] $JAR_FILE"# pidPIDS=`ps -ef | grep java | grep -v grep | grep "$JAR_FILE" | awk '&#123;print $2&#125;'`# JVM optionsJAVA_OPT="-server -Xms1g -Xmx1g -Xss256k"JAVA_OPT="$&#123;JAVA_OPT&#125; -Dloader.path=$&#123;PROJECT_HOME&#125;/lib/ -Djava.io.tmpdir=$&#123;LOGS_DIR&#125;"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:+DisableExplicitGC -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:LargePageSizeInBytes=128m -XX:+UseFastAccessorMethods -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=70"JAVA_OPT="$&#123;JAVA_OPT&#125; -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=$&#123;LOGS_DIR&#125;/dump-`date +"%Y-%m-%d"`.hprof"JAVA_OPT="$&#123;JAVA_OPT&#125; -Ddubbo.protocol.port=20886"JAVA_OPT="$&#123;JAVA_OPT&#125; -Dspring.profiles.active=pro -Dfile.encoding=UTF-8"JAVA_OPT="$&#123;JAVA_OPT&#125; -jar $&#123;JAR_FILE&#125;"# Graceful shutdownfunction gracefulShutdown()&#123; if [ -z "$PIDS" ]; then echo "[$(date '+%Y-%m-%d %H:%M:%S')] $JAR_FILE does not started!" | tee -a $STDOUT_FILE else echo "[$(date '+%Y-%m-%d %H:%M:%S')] $JAR_FILE kill $PIDS begining" | tee -a $STDOUT_FILE for PID in $PIDS ; do kill $PID &gt; /dev/null 2&gt;&amp;1 done # check for graceful shutdown COUNT=0 while [ $COUNT -lt 1 ]; do sleep 1 COUNT=1 for PID in $PIDS ; do PID_EXIST=`ps -f -p $PID | grep java` if [ -n "$PID_EXIST" ]; then COUNT=0 break fi done done echo "[$(date '+%Y-%m-%d %H:%M:%S')] $JAR_FILE kill $PID success" | tee -a $STDOUT_FILE fi&#125;function operate()&#123; if [[ "$1" = "kill" ]]; then gracefulShutdown elif [[ "$1" = "start" ]] ; then cd $PROJECT_HOME # starting nohup $JAVA_HOME/bin/java $JAVA_OPT &gt;&gt; $STDOUT_FILE 2&gt;&amp;1 &amp; PIDS=`ps -ef | grep java | grep -v grep | grep "$JAR_FILE" | awk '&#123;print $2&#125;'` echo "[$(date '+%Y-%m-%d %H:%M:%S')] $JAR_FILE started OK! pid: $PIDS" | tee -a $STDOUT_FILE else echo "[$(date '+%Y-%m-%d %H:%M:%S')] $JAR_FILE is not support $1" | tee -a $STDOUT_FILE fi&#125;if [[ "$1" = "start" || "$1" = "check" ]]; then if [ -n "$PIDS" ]; then echo "[$(date '+%Y-%m-%d %H:%M:%S')] $JAR_FILE already started! pid: $PIDS" &gt;&gt; $STDOUT_FILE exit 1 fi operate startelif [[ "$1" = "" || "$1" = "restart" ]]; then operate kill echo "[$(date '+%Y-%m-%d %H:%M:%S')] $JAR_FILE starting" | tee -a $STDOUT_FILE ls -d -t $LOGS_DIR/undertow* | tail -n +3 | xargs rm -rf operate startelif [[ "$1" = "kill" ]]; then operate killelse echo "[$(date '+%Y-%m-%d %H:%M:%S')] $JAR_FILE is not support $1" | tee -a $STDOUT_FILEfi]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JAR</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CommonsRequestLoggingFilter]]></title>
    <url>%2Fposts%2F233e0cfa.html</url>
    <content type="text"><![CDATA[注册 bean12345678910@Bean@ConditionalOnMissingBeanpublic CommonsRequestLoggingFilter commonsRequestLoggingFilter()&#123; CommonsRequestLoggingFilter filter = new CommonsRequestLoggingFilter(); filter.setIncludeClientInfo(true); filter.setIncludeQueryString(true); filter.setIncludePayload(true); filter.setIncludeHeaders(true); return filter;&#125; 在logback.xml配置1&lt;logger name="org.springframework.web.filter.CommonsRequestLoggingFilter" level="DEBUG"/&gt; 日志打印1219-05-06 14:37:23 DEBUG o.s.w.f.CommonsRequestLoggingFilter.beforeRequest(47) | Before request [uri=/szim/triple.do?action=getJsonUserFeeInfo&amp;encrypt=TJ943tVLlkJmwouCRnJgj6aDOGqm5VBxeLiNqpcIOdUHaByb%2FJ0RK%2FFQvzJcK3TL0aPmKvSdKhNL%2FUl6ZvHznEFR2ohRKF8HTxwaqss9KCZ66AQ4Dx60ZBWrXdju2nlIohMo9O2d0Ia5Bvl6HEpmhQ%3D%3D&amp;ak=0f882bab896ca50e10ef389f12c279c195d7c1810dc3e9e55db6a0057335f148b61761ab383957431d94d5e9982cff0d389021fdf17e25a5843f96cd0a448ef22e47d6abae9bacb5cc7e1cb2ba30a7c0b08d423a5fcb644e2e9392d0a685d0f73a416470d9a074eff6582ad7d05fb2eadb925d798093519c6f1351455dc84296;client=0:0:0:0:0:0:0:1;session=B6FBF9F2B61AA8F5C715A90C2FB1D328;headers=&#123;host=[localhost:8080], connection=[keep-alive], pragma=[no-cache], cache-control=[no-cache], accept=[application/json, text/javascript, */*; q=0.01], dnt=[1], x-requested-with=[XMLHttpRequest], user-agent=[Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/11.0 Mobile/15A372 Safari/604.1], referer=[http://localhost:8080/szim/triple.do?U=ybFlMQgKMvBjGbYIUs+dhtVOInHIaCqdM3ZmiOQn/r0GvzWE2sMZdzaCSHhclamx56V86dWa+JB3unGmNOwvKQ==&amp;t=1557124281371], accept-encoding=[gzip, deflate, br], accept-language=[zh-CN,zh;q=0.9,en;q=0.8], cookie=[JSESSIONID=B6FBF9F2B61AA8F5C715A90C2FB1D328]&#125;]19-05-06 14:37:23 DEBUG o.s.w.f.CommonsRequestLoggingFilter.afterRequest(55) | After request [uri=/szim/triple.do?action=getJsonUserFeeInfo&amp;encrypt=TJ943tVLlkJmwouCRnJgj6aDOGqm5VBxeLiNqpcIOdUHaByb%2FJ0RK%2FFQvzJcK3TL0aPmKvSdKhNL%2FUl6ZvHznEFR2ohRKF8HTxwaqss9KCZ66AQ4Dx60ZBWrXdju2nlIohMo9O2d0Ia5Bvl6HEpmhQ%3D%3D&amp;ak=0f882bab896ca50e10ef389f12c279c195d7c1810dc3e9e55db6a0057335f148b61761ab383957431d94d5e9982cff0d389021fdf17e25a5843f96cd0a448ef22e47d6abae9bacb5cc7e1cb2ba30a7c0b08d423a5fcb644e2e9392d0a685d0f73a416470d9a074eff6582ad7d05fb2eadb925d798093519c6f1351455dc84296;client=0:0:0:0:0:0:0:1;session=B6FBF9F2B61AA8F5C715A90C2FB1D328;headers=&#123;host=[localhost:8080], connection=[keep-alive], pragma=[no-cache], cache-control=[no-cache], accept=[application/json, text/javascript, */*; q=0.01], dnt=[1], x-requested-with=[XMLHttpRequest], user-agent=[Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/11.0 Mobile/15A372 Safari/604.1], referer=[http://localhost:8080/szim/triple.do?U=ybFlMQgKMvBjGbYIUs+dhtVOInHIaCqdM3ZmiOQn/r0GvzWE2sMZdzaCSHhclamx56V86dWa+JB3unGmNOwvKQ==&amp;t=1557124281371], accept-encoding=[gzip, deflate, br], accept-language=[zh-CN,zh;q=0.9,en;q=0.8], cookie=[JSESSIONID=B6FBF9F2B61AA8F5C715A90C2FB1D328]&#125;]]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-cloud-sleuth]]></title>
    <url>%2Fposts%2Fccd87ced.html</url>
    <content type="text"><![CDATA[sleuth输出的日志格式12019-04-29 16:37:54.849 INFO [sleuth,fd6f9ebb8f69ab75,fd6f9ebb8f69ab75,false] 1616 --- [ctor-http-nio-2] t.y.sc.sleuth.service.UserServiceImpl : list: [&#123;id=1, name=test_1&#125;, &#123;id=2, name=test_2&#125;, &#123;id=3, name=test_3&#125;, &#123;id=4, name=test_4&#125;, &#123;id=5, name=test_5&#125;, &#123;id=6, name=test_6&#125;, &#123;id=7, name=test_7&#125;, &#123;id=8, name=test_8&#125;, &#123;id=9, name=test_9&#125;, &#123;id=10, name=test_10&#125;] 可以看到内容是由[appname,traceId,spanId,exportable]组成的, 具体含义如下： appname：服务的名称，也就是spring.application.name的值 traceId：整个请求的唯一ID，它标识整个整个请求的链路 spanId：基本的工作单元，发起一起远程调用就是一个span exportable：是否导入数据到Zipkin中 sleuth的数据推送到logstash 将跟踪的信息导入到ES中，可以将跟踪的信息以JSON格式的数据输出到 logstash，再输出到ES中 123456789101112131415161718192021222324252627282930313233&lt;springProperty scope="context" name="appName" source="spring.application.name"/&gt;&lt;!-- Appender to log to file in a JSON format --&gt;&lt;appender name="logstash" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;$&#123;LOG_FILE&#125;.json&lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;$&#123;LOG_FILE&#125;.json.%d&#123;yyyy-MM-dd&#125;.gz&lt;/fileNamePattern&gt; &lt;maxHistory&gt;7&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder"&gt; &lt;providers&gt; &lt;timestamp&gt; &lt;timeZone&gt;UTC&lt;/timeZone&gt; &lt;/timestamp&gt; &lt;pattern&gt; &lt;pattern&gt; &#123; "level": "%level", "appName": "$&#123;appName:-&#125;", "traceId": "%X&#123;X-B3-TraceId:-&#125;", "spanId": "%X&#123;X-B3-SpanId:-&#125;", "parentId": "%X&#123;X-B3-ParentSpanId:-&#125;", "exportable": "%X&#123;X-Span-Export:-&#125;", "pid": "$&#123;PID:-&#125;", "thread": "%thread", "class": "%logger&#123;40&#125;", "msg": "%message" &#125; &lt;/pattern&gt; &lt;/pattern&gt; &lt;/providers&gt; &lt;/encoder&gt;&lt;/appender&gt;]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>spring-cloud</tag>
        <tag>sleuth</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[druid 打印慢 sql 日志]]></title>
    <url>%2Fposts%2Fc236a064.html</url>
    <content type="text"><![CDATA[依赖包 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt;&lt;/dependency&gt; 在 application.yml 中配置 StatFilter 相关 1234567891011121314151617181920212223242526272829303132333435363738394041debug: falsespring: aop: proxy-target-class: true datasource: url: jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=127.0.0.1)(PORT=1521))(CONNECT_DATA=(SERVER=DEDICATED)(SERVICE_NAME=bkimDB))) username: test password: f5AOzZUQ/nGxSSc0iYT0yRlq9+21dzQNHkdv+IKlkIf/I99NZdiAh/3vzUCjRg005FSb0T/LjqwoWuvqzPrv5g== druid: initial-size: 1 min-idle: 1 max-active: 3 max-wait: 60000 keep-alive: true time-between-eviction-runs-millis: 60000 min-evictable-idle-time-millis: 300000 validation-query: SELECT 'x' FROM DUAL test-while-idle: true test-on-borrow: false test-on-return: false pool-prepared-statements: true max-pool-prepared-statement-per-connection-size: 20 filter: wall: enabled: true stat: enabled: true log-slow-sql: true slow-sql-millis: 10 config: enabled: true stat-view-servlet: enabled: false web-stat-filter: enabled: false connection-properties: config.decrypt=true;config.decrypt.key=MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAJqw3NwlMJmXvcUbhlOn7VttbKPegs99ToSlKhlvDf4YD04OaD86/csdIVHgKcaCkYWfY3XIh/vJtUOf/QEwG+0CAwEAAQ== jpa: database: oracle properties: hibernate: dialect: org.hibernate.dialect.Oracle10gDialect 关键配置是 12345678spring: datasource: druid: filter: stat: enabled: true log-slow-sql: true slow-sql-millis: 10 慢 sql 日志 1219-04-18 15:09:46 ERROR pool-2-thread-1 com.alibaba.druid.filter.stat.StatFilter.internalAfterStatementExecute(478) | slow sql 20 millis. select * from ( select token0_.id as id1_0_, token0_.curr as curr2_0_, token0_.ip as ip3_0_, token0_.serviceno as serviceno4_0_, token0_.ticket as ticket5_0_, token0_.token as token6_0_, token0_.vtime as vtime7_0_ from im_wx_token token0_ where token0_.curr=? and token0_.serviceno=? ) where rownum &lt;= ?["1","gh_de5f1fdc39ec",1]19-04-18 15:09:46 ERROR pool-2-thread-1 com.alibaba.druid.filter.stat.StatFilter.internalAfterStatementExecute(478) | slow sql 11 millis. select token0_.id as id1_0_0_, token0_.curr as curr2_0_0_, token0_.ip as ip3_0_0_, token0_.serviceno as serviceno4_0_0_, token0_.ticket as ticket5_0_0_, token0_.token as token6_0_0_, token0_.vtime as vtime7_0_0_ from im_wx_token token0_ where token0_.id=?[303547228245069824]]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
        <tag>alibaba</tag>
        <tag>druid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux traceroute 命令]]></title>
    <url>%2Fposts%2F683fa9b1.html</url>
    <content type="text"><![CDATA[traceroute1traceroute &lt;ip&gt; -nT -p &lt;port&gt; windows使用 12tracert &lt;ip&gt;tracert baidu.com]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>traceroute</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux telnet 命令]]></title>
    <url>%2Fposts%2F683fa9b1.html</url>
    <content type="text"><![CDATA[telnet1telnet &lt;ip&gt; &lt;port&gt; ctrl+c 不退出问题解决1234# 先输入$ ctrl+]# 在输入$ quit]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>telnet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[logback 踩坑]]></title>
    <url>%2Fposts%2F15985cf3.html</url>
    <content type="text"><![CDATA[totalSizeCap 配置大于 2GB 时，不生效的问题 logbakc.xml 配置 1234567891011121314151617181920&lt;appender name="info_rolling" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;File&gt;$&#123;logger.path&#125;/info.log&lt;/File&gt; &lt;encoder charset="$&#123;logger.charset&#125;"&gt; &lt;pattern&gt;$&#123;logger.pattern&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt; $&#123;logger.path&#125;/info.%d&#123;yy-MM-dd&#125;.%i.log &lt;/fileNamePattern&gt; &lt;maxHistory&gt;$&#123;logger.maxHistory&#125;&lt;/maxHistory&gt; &lt;maxFileSize&gt;512MB&lt;/maxFileSize&gt; &lt;totalSizeCap&gt;5GB&lt;/totalSizeCap&gt; &lt;/rollingPolicy&gt;&lt;/appender&gt; logback-core-1.1.11.jar 及之前版本的 TimeBasedArchiveRemover 12345678910111213141516171819void capTotalSize(Date now) &#123; int totalSize = 0; int totalRemoved = 0; for (int offset = 0; offset &lt; maxHistory; offset++) &#123; Date date = rc.getEndOfNextNthPeriod(now, -offset); File[] matchingFileArray = getFilesInPeriod(date); descendingSortByLastModified(matchingFileArray); for (File f : matchingFileArray) &#123; long size = f.length(); if (totalSize + size &gt; totalSizeCap) &#123; addInfo("Deleting [" + f + "]" + " of size " + new FileSize(size)); totalRemoved += size; f.delete(); &#125; totalSize += size; &#125; &#125; addInfo("Removed " + new FileSize(totalRemoved) + " of files");&#125; 这里的totalSize使用的是int类型，Interger.MAX_VALUE最大只能表示2GB的数据，修改成使用long类型可以解决这个问题。 logback-core 1.2.0 之后的版本已经修复这个问题 12345678910111213141516171819void capTotalSize(Date now) &#123; long totalSize = 0; long totalRemoved = 0; for (int offset = 0; offset &lt; maxHistory; offset++) &#123; Date date = rc.getEndOfNextNthPeriod(now, -offset); File[] matchingFileArray = getFilesInPeriod(date); descendingSortByLastModified(matchingFileArray); for (File f : matchingFileArray) &#123; long size = f.length(); if (totalSize + size &gt; totalSizeCap) &#123; addInfo("Deleting [" + f + "]" + " of size " + new FileSize(size)); totalRemoved += size; f.delete(); &#125; totalSize += size; &#125; &#125; addInfo("Removed " + new FileSize(totalRemoved) + " of files");&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>logback</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jstack]]></title>
    <url>%2Fposts%2F9f2701e8.html</url>
    <content type="text"><![CDATA[jstack导出线程信息到文件 1$ jstack &lt;pid&gt; &gt; pid.txt]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>jstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo 配置相关说明]]></title>
    <url>%2Fposts%2F1432ba6.html</url>
    <content type="text"><![CDATA[线程池类型dubbo 提供了4中线程池类型 fixed 固定大小线程池，启动时建立线程，不关闭，一直持有(缺省) core-size 默认值：200，可配置 max-size 默认值：200，可配置 queue-size 默认值：0，可配置 等于 0 时：SynchronousQueue 不等于 0 时：LinkedBlockingQueue keep-alive 默认值：0 cached 缓存线程池，空闲一分钟自动删除，需要时重建 core-size 默认值：0，可配置 max-size 默认值：Integer.MAX_VALUE，可配置 queue-size 默认值：0，可配置 等于 0 时：SynchronousQueue 不等于 0 时：LinkedBlockingQueue keep-alive 默认值：60 * 1000(ms)，可配置 limited 可伸缩线程池，但池中的线程数只会增长不会收缩。 可能只增长不收缩的目的是为了避免收缩时突然来了大流量引起的性能问题 core-size 默认值：0，可配置 max-size 默认值：200，可配置 queue-size 默认值：0，可配置 等于 0 时：SynchronousQueue 不等于 0 时：LinkedBlockingQueue keep-alive 默认值：Long.MAX_VALUE eager 优先创建Worker线程。在任务数量大于core-size但是小于max-size时，优先创建Worker来处理任务。当任务数量大于max-size时，将任务放入阻塞队列中 core-size 默认值：0，可配置 max-size 默认值：Integer.MAX_VALUE，可配置 queue-size 默认值：1，可配置 等于 0 时：SynchronousQueue 不等于 0 时：LinkedBlockingQueue keep-alive 默认值：60 * 1000(ms)，可配置 ThreadPoolExecutor参数 对应Dubbo URL参数 对应Dubbo配置项 core-size corethreads fixed：dubbo.provider.threadsdubbo.protocol.threads其他（没有在配置类中暴露出来）：dubbo.provider.corethreadsdubbo.protocol.corethreads（2.6.6及以前的版本ProtocolConfig中没有这个参数，2.7.0后的版本已经添加上去） max-size threads dubbo.provider.threadsdubbo.protocol.threads queue-size queues dubbo.provider.queuesdubbo.protocol.queues keep-alive alive 没有在配置类中暴露出来dubbo.provider.alivedubbo.protocol.alive 队列类型 SynchronousQueue 它的同步原理是，当生成者线程准备将元素放入这个队列时，如果这时没有消费者线程来，它就一直wait，等到有消费者线程来了，消费者线程把元素取走，他就可以返回true了。 同样的，当消费者准备从这个队列取元素时，如果这时正好有生产者线程来时，他就把元素取走返回true，否则就一直在那等生产者线程来。 LinkedBlockingQueue add：方法在添加元素的时候，若超出了度列的长度会直接抛出异常 put：若向队尾添加元素的时候发现队列已经满了会发生阻塞一直等待空间，以加入元素 offer：在添加元素时，如果发现队列已满无法添加的话，会直接返回false 其他函数： poll：若队列为空，返回null remove：若队列为空，抛出NoSuchElementException异常 take：若队列为空，发生阻塞，等待有元素]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Apache</tag>
        <tag>alibaba</tag>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式Id生成器]]></title>
    <url>%2Fposts%2Ff9490f40.html</url>
    <content type="text"><![CDATA[Id生成的几种方式 数据库自增 优势 简单，无需额外操作 保持定长自增 保持单表唯一性 劣势 主键生成依赖数据库，高并发下会造成数据库服务器压力较大 水平扩展困难，在分布式数据库环境下，无法保证唯一性 UUID（GUID） 优势 本地生成，无需远程调用（无需网络通信） 全局唯一 水平扩展好 劣势 ID 128 bits，占用空间大 字符串类型，索引效率低 无法保证趋势递增 时间戳 略 Twitter Snowflake 雪花算法 优势 本地生产，无需远程调用（无需网络通信） 单机每秒可生成400w个ID ID 64 bits，占用空间小 long类型，对索引效率有提升 趋势递增 劣势 时间回拨问题 集群部署时，集群内机器时间同步问题 基于雪花算法的分布式Id生成器实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147import java.util.Calendar;/** * 该生成器采用 Twitter Snowflake 算法实现，生成 64 Bits 的 Long 型编号 * &lt;pre&gt; * 1 bit 41 bits 10 bits 12 bits * sign bit 时间戳 工作ID 序列号ID * &lt;/pre&gt; * * @author YL */public final class SnowflakeKeyGenerator implements KeyGenerator &#123; /** * 基准时间：时间偏移量 */ private static final long EPOCH; static &#123; // 从2017年01月01日零点开始 Calendar calendar = Calendar.getInstance(); calendar.set(2017, Calendar.JANUARY, 1); calendar.set(Calendar.HOUR_OF_DAY, 0); calendar.set(Calendar.MINUTE, 0); calendar.set(Calendar.SECOND, 0); calendar.set(Calendar.MILLISECOND, 0); EPOCH = calendar.getTimeInMillis(); &#125; /** * 序列号ID位数 */ private static final long SEQUENCE_BITS = 12L; /** * 工作ID位数 */ private static final long WORKER_ID_BITS = 10L; /** * 序列号ID最大值 */ private static final long SEQUENCE_MASK = (1 &lt;&lt; SEQUENCE_BITS) - 1; /** * 工作ID最大值 */ private static final long WORKER_ID_MAX_VALUE = 1L &lt;&lt; WORKER_ID_BITS; /** * 工作ID左移12位 */ private static final long WORKER_ID_LEFT_SHIFT_BITS = SEQUENCE_BITS; /** * 时间戳左移22数 */ private static final long TIMESTAMP_LEFT_SHIFT_BITS = WORKER_ID_LEFT_SHIFT_BITS + WORKER_ID_BITS; /** * 序列号ID */ private long sequence; /** * 序列号ID偏移量 */ private byte sequenceOffset; /** * 最后生成编号时间戳，单位：毫秒 */ private long lastTime; /** * 工作ID */ private long workerId; public SnowflakeKeyGenerator(long workerId) &#123; if (workerId &gt;= WORKER_ID_MAX_VALUE || workerId &lt; 0) &#123; throw new IllegalArgumentException(String.format("worker Id can't be greater than %d or less than 0", WORKER_ID_MAX_VALUE)); &#125; this.workerId = workerId; &#125; /** * 生成 ID * * @return 返回@&#123;@link Long&#125;类型的Id */ @Override public synchronized long nextId() &#123; // 保证当前时间大于最后时间。时间回退会导致产生重复id long currentMillis = System.currentTimeMillis(); if (currentMillis &lt; this.lastTime) &#123; throw new IllegalArgumentException(String.format("clock moved backwards.Refusing to generate id for %d " + "milliseconds", (this.lastTime - currentMillis))); &#125; // 获取序列号 if (this.lastTime == currentMillis) &#123; // 当获得序号超过最大值时，归0，并去获得新的时间 if (0L == (this.sequence = ++this.sequence &amp; SEQUENCE_MASK)) &#123; currentMillis = tailNextMillis(currentMillis); &#125; &#125; else &#123; // 1、在跨毫秒时，序列号总是归0，导致序列号为0的ID较多，导致生成的ID取模后不均匀 // this.sequence = 0; // 2、序列号取[0-9]之间的随机数，可以初步解决【1】中的问题，也会导致ID取模不均匀 // this.sequence = new SecureRandom().nextInt(10); // 3、交替使用[0-1] this.sequence = vibrateSequenceOffset(); &#125; // 设置最后时间戳 this.lastTime = currentMillis; // 生成编号 return ((currentMillis - EPOCH) &lt;&lt; TIMESTAMP_LEFT_SHIFT_BITS) | (this.workerId &lt;&lt; WORKER_ID_LEFT_SHIFT_BITS) | this.sequence; &#125; /** * 不停获得时间，直到大于最后时间 * &lt;p&gt; * 从 Snowflake 的官方文档 (https://github.com/twitter/snowflake/#system-clock-dependency) 中也可以看到, 它明确要求 "You should * use NTP to keep your system clock accurate". 而且最好把 NTP 配置成不会向后调整的模式. 也就是说, NTP 纠正时间时, 不会向后回拨机器时钟. * ntpd 和 ntpdate 的区别，使用 ntpd 影响不大 * todo 如果时间回拨，会导致这个逻辑等待，等待时间可能会很长 * &lt;/p&gt; * * @param lastTime 最后时间 * * @return 时间 */ private long tailNextMillis(final long lastTime) &#123; long time = System.currentTimeMillis(); while (time &lt;= lastTime) &#123; time = System.currentTimeMillis(); &#125; return time; &#125; /** * 只会交替返回0和1 */ private byte vibrateSequenceOffset() &#123; this.sequenceOffset = (byte) (~this.sequenceOffset &amp; 1); return this.sequenceOffset; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Twitter</tag>
        <tag>Snowflake</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle SYSDATE]]></title>
    <url>%2Fposts%2Fb9e67bce.html</url>
    <content type="text"><![CDATA[sysdate12345678910111213141516171819202122SELECT '当前时间' AS 描述, TO_CHAR(SYSDATE, 'yyyy-mm-dd hh24:mi:ss') AS 时间 FROM DUALUNION ALLSELECT '1天前' AS 描述, TO_CHAR(SYSDATE - 1, 'yyyy-mm-dd hh24:mi:ss') AS 时间 FROM DUALUNION ALLSELECT '1小时前' AS 描述, TO_CHAR(SYSDATE - 1 / 24, 'yyyy-mm-dd hh24:mi:ss') AS 时间 FROM DUALUNION ALLSELECT '1分钟前' AS 描述, TO_CHAR(SYSDATE - 1 / (24 * 60), 'yyyy-mm-dd hh24:mi:ss') AS 时间 FROM DUALUNION ALLSELECT '1秒钟前' AS 描述, TO_CHAR(SYSDATE - 1 / (24 * 60 * 60), 'yyyy-mm-dd hh24:mi:ss') AS 时间 FROM DUAL-- 2019-11-29号执行以下 sql-- SELECT TRUNC(SYSDATE - 1) + 1, TRUNC(SYSDATE + 1) FROM dual-- 2019/11/29 2019/11/30 打印结果 123456描述 时间当前时间 2019-03-10 10:53:361天前 2019-03-09 10:53:361小时前 2019-03-10 09:53:361分钟前 2019-03-10 10:52:361秒钟前 2019-03-10 10:53:35]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>SYSDATE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[logstash 使用]]></title>
    <url>%2Fposts%2F1e58019c.html</url>
    <content type="text"><![CDATA[启动logstash1$ bin/logstash -f /opt/logstash/conf.d/ -r true start.sh 启动脚本 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#!/bin/sh# @Author: YL# @Date: 2019-03-07 17:19:33# @Last Modified by: YL# @Last Modified time: 2019-03-08 10:31:06cd `dirname $0`LS_HOME=`pwd`LS_CONF="$LS_HOME/conf.d/"LS_HOME_CORE_LIB="$LS_HOME/logstash-core/lib"# 检测Tomcat是否启动（进程ID）LS_PID=`ps -ef | grep $LS_HOME_CORE_LIB | grep -v grep | awk '&#123;print $2&#125;'`#==================================================================================# JVM Configuration#==================================================================================export LANG=en_US.UTF-8export JAVA_HOME=/usr/java/jdk1.8.0_144function operate()&#123; if [[ "$1" = "kill" ]] ; then if [[ "$LS_PID" = "" ]] ; then echo "logstash not alive" else kill -9 $LS_PID fi elif [[ "$1" = "start" ]]; then nohup $LS_HOME/bin/logstash -f $LS_CONF -r true &gt;/dev/null 2&gt;&amp;1 &amp; else echo "not support: $1" fi&#125;if [[ "$1" = "" || "$1" = "restart" || "$1" = "start" ]] ; then operate kill operate startelif [[ "$1" = "kill" ]] ; then operate killelif [[ "$1" = "check" ]] ; then if [[ "$LS_PID" = "" ]] ; then operate start fielse echo "not support: $1"fi crontab 1* * * * * /opt/logstash/start.sh check logstash config 命名 思考：如果logstash配置了多个config(多个input或多个filter)，怎样来控制它们被执行的顺序呢？ 答案是logstash是按照config file的文件名，按照字母顺序合并了所有的config file，然后才处理的。 最佳命名实践 1234567800_input.conf10_filter_global.conf20_filter_nginx.conf21_filter_vsftpd.conf999_output.conf 条件判断12345678910111213output &#123; if [index_prefix] &#123; elasticsearch &#123; hosts =&gt; [ &quot;elasticsearch:9200&quot; ] index =&gt; &quot;%&#123;index_prefix&#125;-%&#123;+YYYY.MM.dd&#125;&quot; &#125; &#125; else &#123; elasticsearch &#123; hosts =&gt; [ &quot;elasticsearch:9200&quot; ] index =&gt; &quot;logstash-%&#123;+YYYY.MM.dd&#125;&quot; &#125; &#125;&#125; 比较操作有： 相等: ==, !=, &lt;, &gt;, &lt;=, &gt;= 正则: =~(匹配正则), !~(不匹配正则) 包含: in(包含), not in(不包含) 布尔操作： and(与), or(或), nand(非与), xor(非或) 一元运算符： !(取反) ()(复合表达式), !()(对复合表达式结果取反) remove _field 删除字段 123mutate &#123; remove_field =&gt; [ &quot;source&quot; ]&#125; 删除嵌套字段（Nested fields） 123mutate &#123; remove_field =&gt; [ &quot;[host][name]&quot; ]&#125; 注意：如果没有host字段，[host][name]引用会创建一个空的host字典，为了避免这种情况，可以按以下方式去做： 12345if [host] and [host][name] == &quot;null&quot; &#123; mutate &#123; remove_field =&gt; [ &quot;[host][name]&quot; ] &#125;&#125; logstash-logback-encoderlogback发送日志到logstash 解决logstash到elasticsearch时区差8小时的问题 123&lt;timestamp&gt; &lt;timeZone&gt;GMT+8&lt;/timeZone&gt;&lt;/timestamp&gt; 配置过滤器，过滤掉不需要的日志 1234567&lt;filter class="ch.qos.logback.core.filter.EvaluatorFilter"&gt; &lt;evaluator class="ch.qos.logback.classic.boolex.JaninoEventEvaluator"&gt; &lt;expression&gt;return message.contains("api_monitor");&lt;/expression&gt; &lt;/evaluator&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt;&lt;/filter&gt; pom.xml 12345678910&lt;dependency&gt; &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt; &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt; &lt;version&gt;5.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.codehaus.janino&lt;/groupId&gt; &lt;artifactId&gt;janino&lt;/artifactId&gt; &lt;version&gt;3.0.12&lt;/version&gt;&lt;/dependency&gt; logback-spring.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;springProfile name="pro"&gt; &lt;appender name="logstash" class="net.logstash.logback.appender.LogstashTcpSocketAppender"&gt; &lt;destination&gt;192.168.56.101:5044&lt;/destination&gt; &lt;keepAliveDuration&gt;5 minutes&lt;/keepAliveDuration&gt; &lt;reconnectionDelay&gt;1 second&lt;/reconnectionDelay&gt; &lt;filter class="ch.qos.logback.core.filter.EvaluatorFilter"&gt; &lt;evaluator class="ch.qos.logback.classic.boolex.JaninoEventEvaluator"&gt; &lt;expression&gt; return message.contains("api_monitor"); &lt;/expression&gt; &lt;/evaluator&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;encoder charset="$&#123;logger.charset&#125;" class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder"&gt; &lt;providers&gt; &lt;timestamp&gt; &lt;timeZone&gt;GMT+8&lt;/timeZone&gt; &lt;/timestamp&gt; &lt;pattern&gt; &lt;pattern&gt; &#123; "time": "%d&#123;yy-MM-dd HH:mm:ss&#125;", "level": "%p", "thread": "%t", "class": "%c&#123;2&#125;.%M\\(%L\\)", "message": "%m" &#125; &lt;/pattern&gt; &lt;/pattern&gt; &lt;stackTrace&gt; &lt;throwableConverter class="net.logstash.logback.stacktrace.ShortenedThrowableConverter"&gt; &lt;maxDepthPerThrowable&gt;full&lt;/maxDepthPerThrowable&gt; &lt;maxLength&gt;full&lt;/maxLength&gt; &lt;shortenedClassNameLength&gt;20&lt;/shortenedClassNameLength&gt; &lt;rootCauseFirst&gt;true&lt;/rootCauseFirst&gt; &lt;inlineHash&gt;true&lt;/inlineHash&gt; &lt;!-- generated class names --&gt; &lt;exclude&gt;\$\$FastClassByCGLIB\$\$&lt;/exclude&gt; &lt;exclude&gt;\$\$EnhancerBySpringCGLIB\$\$&lt;/exclude&gt; &lt;exclude&gt;^sun\.reflect\..*\.invoke&lt;/exclude&gt; &lt;!-- JDK internals --&gt; &lt;exclude&gt;^com\.sun\.&lt;/exclude&gt; &lt;exclude&gt;^sun\.net\.&lt;/exclude&gt; &lt;!-- dynamic invocation --&gt; &lt;exclude&gt;^net\.sf\.cglib\.proxy\.MethodProxy\.invoke&lt;/exclude&gt; &lt;exclude&gt;^org\.springframework\.cglib\.&lt;/exclude&gt; &lt;exclude&gt;^org\.springframework\.transaction\.&lt;/exclude&gt; &lt;exclude&gt;^org\.springframework\.validation\.&lt;/exclude&gt; &lt;exclude&gt;^org\.springframework\.app\.&lt;/exclude&gt; &lt;exclude&gt;^org\.springframework\.aop\.&lt;/exclude&gt; &lt;exclude&gt;^java\.lang\.reflect\.Method\.invoke&lt;/exclude&gt; &lt;!-- Spring plumbing --&gt; &lt;exclude&gt;^org\.springframework\.ws\..*\.invoke&lt;/exclude&gt; &lt;exclude&gt;^org\.springframework\.ws\.transport\.&lt;/exclude&gt; &lt;exclude&gt;^org\.springframework\.ws\.soap\.saaj\.SaajSoapMessage\.&lt;/exclude&gt; &lt;exclude&gt;^org\.springframework\.ws\.client\.core\.WebServiceTemplate\.&lt;/exclude&gt; &lt;exclude&gt;^org\.springframework\.web\.filter\.&lt;/exclude&gt; &lt;!-- Tomcat internals --&gt; &lt;exclude&gt;^org\.apache\.tomcat\.&lt;/exclude&gt; &lt;exclude&gt;^org\.apache\.catalina\.&lt;/exclude&gt; &lt;exclude&gt;^org\.apache\.coyote\.&lt;/exclude&gt; &lt;exclude&gt;^java\.util\.concurrent\.ThreadPoolExecutor\.runWorker&lt;/exclude&gt; &lt;exclude&gt;^java\.lang\.Thread\.run$&lt;/exclude&gt; &lt;/throwableConverter&gt; &lt;/stackTrace&gt; &lt;/providers&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level="info"&gt; &lt;appender-ref ref="logstash"/&gt; &lt;/root&gt;&lt;/springProfile&gt; 使用中遇到的问题gsub 有问题 12345678910mutate &#123; gsub =&gt; [ &quot;city&quot;, &quot;5&quot;, &quot;深圳&quot;, &quot;city&quot;, &quot;50&quot;, &quot;东莞&quot;, &quot;city&quot;, &quot;51&quot;, &quot;江门&quot; ]&#125;# 5进来，替换成“深圳”# 50进来，会被替换成“深圳0”# 51进来，会被替换成“深圳1” 正常 12345678910mutate &#123; gsub =&gt; [ &quot;city&quot;, &quot;^5$&quot;, &quot;深圳&quot;, &quot;city&quot;, &quot;^50$&quot;, &quot;东莞&quot;, &quot;city&quot;, &quot;^51$&quot;, &quot;江门&quot; ]&#125;# 5进来，替换成“深圳”# 50进来，会被替换成“东莞”# 51进来，会被替换成“江门” 12345678910mutate &#123; gsub =&gt; [ &quot;city&quot;, &quot;50&quot;, &quot;东莞&quot;, &quot;city&quot;, &quot;51&quot;, &quot;江门&quot;, &quot;city&quot;, &quot;5&quot;, &quot;深圳&quot; ]&#125;# 5进来，替换成“深圳”# 50进来，会被替换成“东莞”# 51进来，会被替换成“江门”]]></content>
      <categories>
        <category>elk</category>
      </categories>
      <tags>
        <tag>logback</tag>
        <tag>logstash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[grok patterns]]></title>
    <url>%2Fposts%2Fa8d0988c.html</url>
    <content type="text"><![CDATA[官方Grok Pattern源码 Custom Grok Pattern 自定义的正则格式 1(?&lt;field_name&gt;the pattern here) General Grok Patterns USER 1%&#123;USERNAME&#125; USERNAME 1[a-zA-Z0-9._-]+ BASE10NUM1(?&lt;![0-9.+-])(?&gt;[+-]?(?:(?:[0-9]+(?:\.[0-9]+)?)|(?:\.[0-9]+))) BASE16FLOAT1\b(?&lt;![0-9A-Fa-f.])(?:[+-]?(?:0x)?(?:(?:[0-9A-Fa-f]+(?:\.[0-9A-Fa-f]*)?)|(?:\.[0-9A-Fa-f]+)))\b INT1(?:[+-]?(?:[0-9]+)) NONNEGINT1\b(?:[0-9]+)\b NUMBER1(?:%&#123;BASE10NUM&#125;) BASE16NUM (?&lt;![0-9A-Fa-f])(?:[+-]?(?:0x)?(?:[0-9A-Fa-f]+)) POSINT1\b(?:[1-9][0-9]*)\b WORD1\b\w+\b NOTSPACE1\S+ SPACE1\s* DATA1.*? GREEDYDATA1.* QUOTEDSTRING1(?&gt;(?&lt;!\\)(?&gt;"(?&gt;\\.|[^\\"]+)+"|""|(?&gt;'(?&gt;\\.|[^\\']+)+')|''|(?&gt;`(?&gt;\\.|[^\\`]+)+`)|``)) UUID1[A-Fa-f0-9]&#123;8&#125;-(?:[A-Fa-f0-9]&#123;4&#125;-)&#123;3&#125;[A-Fa-f0-9]&#123;12&#125; Date and Time Grok Patterns MONTH1\b(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\b MONTHNUM1(?:0?[1-9]|1[0-2]) MONTHNUM21(?:0[1-9]|1[0-2]) MONTHDAY1(?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9]) DAY1(?:Mon(?:day)?|Tue(?:sday)?|Wed(?:nesday)?|Thu(?:rsday)?|Fri(?:day)?|Sat(?:urday)?|Sun(?:day)?) YEAR1(?&gt;\d\d)&#123;1,2&#125; HOUR (?:2[0123]|[01]?[0-9]) MINUTE (?:[0-5][0-9]) SECOND1(?:(?:[0-5]?[0-9]|60)(?:[:.,][0-9]+)?) TIME (?!&lt;[0-9])%&#123;HOUR&#125;:%&#123;MINUTE&#125;(?::%&#123;SECOND&#125;)(?![0-9]) Note: 60 is a leap second in most time standards. DATE_US1%&#123;MONTHNUM&#125;[/-]%&#123;MONTHDAY&#125;[/-]%&#123;YEAR&#125; DATE_EU1%&#123;MONTHDAY&#125;[./-]%&#123;MONTHNUM&#125;[./-]%&#123;YEAR&#125; ISO8601_TIMEZONE1(?:Z|[+-]%&#123;HOUR&#125;(?::?%&#123;MINUTE&#125;)) ISO8601_SECOND1(?:%&#123;SECOND&#125;|60) TIMESTAMP_ISO86011%&#123;YEAR&#125;-%&#123;MONTHNUM&#125;-%&#123;MONTHDAY&#125;[T ]%&#123;HOUR&#125;:?%&#123;MINUTE&#125;(?::?%&#123;SECOND&#125;)?%&#123;ISO8601_TIMEZONE&#125;? DATE1%&#123;DATE_US&#125;|%&#123;DATE_EU&#125; DATESTAMP1%&#123;DATE&#125;[- ]%&#123;TIME&#125; TZ1(?:[PMCE][SD]T|UTC) DATESTAMP_RFC8221%&#123;DAY&#125; %&#123;MONTH&#125; %&#123;MONTHDAY&#125; %&#123;YEAR&#125; %&#123;TIME&#125; %&#123;TZ&#125; DATESTAMP_RFC28221%&#123;DAY&#125;, %&#123;MONTHDAY&#125; %&#123;MONTH&#125; %&#123;YEAR&#125; %&#123;TIME&#125; %&#123;ISO8601_TIMEZONE&#125; DATESTAMP_OTHER1%&#123;DAY&#125; %&#123;MONTH&#125; %&#123;MONTHDAY&#125; %&#123;TIME&#125; %&#123;TZ&#125; %&#123;YEAR&#125; DATESTAMP_EVENTLOG1%&#123;YEAR&#125;%&#123;MONTHNUM2&#125;%&#123;MONTHDAY&#125;%&#123;HOUR&#125;%&#123;MINUTE&#125;%&#123;SECOND&#125; Java Grok Patterns JAVACLASS1(?:[a-zA-Z$_][a-zA-Z$_0-9]*\.)*[a-zA-Z$_][a-zA-Z$_0-9]* JAVAFILE1(?:[A-Za-z0-9_. -]+) A space character is allowed to match special cases, such as Native Method or Unknown Source. JAVAMETHOD1(?:(&lt;init&gt;)|[a-zA-Z$_][a-zA-Z$_0-9]*) JAVASTACKTRACEPART1%&#123;SPACE&#125;at %&#123;JAVACLASS:class&#125;\.%&#123;JAVAMETHOD:method&#125;\(%&#123;JAVAFILE:file&#125;(?::%&#123;NUMBER:line&#125;)?\) The line number is optional in special cases, such as Native Method or Unknown Source. Log Grok Patterns SYSLOGTIMESTAMP1%&#123;MONTH&#125; +%&#123;MONTHDAY&#125; %&#123;TIME&#125; PROG (?:[\w._/%-]+) SYSLOGPROG1%&#123;PROG:program&#125;(?:\[%&#123;POSINT:pid&#125;\])? SYSLOGHOST1%&#123;IPORHOST&#125; SYSLOGFACILITY1&lt;%&#123;NONNEGINT:facility&#125;.%&#123;NONNEGINT:priority&#125;&gt; SYSLOGBASE1%&#123;SYSLOGTIMESTAMP:timestamp&#125; (?:%&#123;SYSLOGFACILITY&#125; )?%&#123;SYSLOGHOST:logsource&#125; %&#123;SYSLOGPROG&#125;: HTTPDATE1%&#123;MONTHDAY&#125;/%&#123;MONTH&#125;/%&#123;YEAR&#125;:%&#123;TIME&#125; %&#123;INT&#125; QS1%&#123;QUOTEDSTRING&#125; COMMONAPACHELOG1%&#123;IPORHOST:clientip&#125; %&#123;USER:ident&#125; %&#123;USER:auth&#125; \[%&#123;HTTPDATE:timestamp&#125;\] "(?:%&#123;WORD:verb&#125; %&#123;NOTSPACE:request&#125;(?: HTTP/%&#123;NUMBER:httpversion&#125;)?|%&#123;DATA:rawrequest&#125;)" %&#123;NUMBER:response&#125; (?:%&#123;NUMBER:bytes&#125;|-) COMBINEDAPACHELOG1%&#123;COMMONAPACHELOG&#125; %&#123;QS:referrer&#125; %&#123;QS:agent&#125; LOGLEVEL1([Aa]lert|ALERT|[Tt]race|TRACE|[Dd]ebug|DEBUG|[Nn]otice|NOTICE|[Ii]nfo|INFO|[Ww]arn?(?:ing)?|WARN?(?:ING)?|[Ee]rr?(?:or)?|ERR?(?:OR)?|[Cc]rit?(?:ical)?|CRIT?(?:ICAL)?|[Ff]atal|FATAL|[Ss]evere|SEVERE|EMERG(?:ENCY)?|[Ee]merg(?:ency)?) Networking Grok Patterns MAC1(?:%&#123;CISCOMAC&#125;|%&#123;WINDOWSMAC&#125;|%&#123;COMMONMAC&#125;) CISCOMAC1(?:(?:[A-Fa-f0-9]&#123;4&#125;\.)&#123;2&#125;[A-Fa-f0-9]&#123;4&#125;) COMMONMAC1(?:(?:[A-Fa-f0-9]&#123;2&#125;:)&#123;5&#125;[A-Fa-f0-9]&#123;2&#125;) WINDOWSMAC1(?:(?:[A-Fa-f0-9]&#123;2&#125;-)&#123;5&#125;[A-Fa-f0-9]&#123;2&#125;) HOST1%&#123;HOSTNAME&#125; HOSTNAME1\b(?:[0-9A-Za-z][0-9A-Za-z-]&#123;0,62&#125;)(?:\.(?:[0-9A-Za-z][0-9A-Za-z-]&#123;0,62&#125;))*(\.?|\b) HOSTPORT1%&#123;IPORHOST&#125;:%&#123;POSINT&#125; IPORHOST1(?:%&#123;HOSTNAME&#125;|%&#123;IP&#125;) IP1(?:%&#123;IPV6&#125;|%&#123;IPV4&#125;) IPV61((([0-9A-Fa-f]&#123;1,4&#125;:)&#123;7&#125;([0-9A-Fa-f]&#123;1,4&#125;|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;6&#125;(:[0-9A-Fa-f]&#123;1,4&#125;|((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;)|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;5&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,2&#125;)|:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;)|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;4&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,3&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)?:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;3&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,4&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,2&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;2&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,5&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,3&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;1&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,6&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,4&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(:(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,7&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,5&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:)))(%.+)? IPV4 (?&lt;![0-9])(?:(?:25[0-5]|2[0-4][0-9]|[0-1]?[0-9]&#123;1,2&#125;)[.](?:25[0-5]|2[0-4][0-9]|[0-1]?[0-9]&#123;1,2&#125;)[.](?:25[0-5]|2[0-4][0-9]|[0-1]?[0-9]&#123;1,2&#125;)[.](?:25[0-5]|2[0-4][0-9]|[0-1]?[0-9]&#123;1,2&#125;))(?![0-9]) Path Grok Patterns PATH1(?:%&#123;UNIXPATH&#125;|%&#123;WINPATH&#125;) UNIXPATH1(?&gt;/(?&gt;[\w_%!$@:.,~-]+|\\.)*)+ TTY (?:/dev/(pts|tty([pq])?)(\w+)?/?(?:[0-9]+)) WINPATH1(?&gt;[A-Za-z]+:|\\)(?:\\[^\\?*]*)+ URIPROTO [A-Za-z]+(\+[A-Za-z+]+)? URIHOST1%&#123;IPORHOST&#125;(?::%&#123;POSINT:port&#125;)? URIPATH1(?:/[A-Za-z0-9$.+!*'()&#123;&#125;,~:;=@#%_\-]*)+ #URIPARAM \?(?:[A-Za-z0-9]+(?:=(?:[^&amp;]*))?(?:&amp;(?:[A-Za-z0-9]+(?:=(?:[^&amp;]*))?)?)*)? URIPARAM1\?[A-Za-z0-9$.+!*'|()&#123;&#125;,~@#%&amp;/=:;_?\-\[\]]* URIPATHPARAM1%&#123;URIPATH&#125;(?:%&#123;URIPARAM&#125;)? URI1%&#123;URIPROTO&#125;://(?:%&#123;USER&#125;(?::[^@]*)?@)?(?:%&#123;URIHOST&#125;)?(?:%&#123;URIPATHPARAM&#125;)?]]></content>
      <categories>
        <category>elk</category>
      </categories>
      <tags>
        <tag>grok</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo 2.7.x使用]]></title>
    <url>%2Fposts%2Fed805d7d.html</url>
    <content type="text"><![CDATA[环境代码地址dubbo-v2.7.x dubbo 2.7.0duboo-spring-boot-starter 2.7.0 启动 provider访问以下地址来判断provider端使用多协议是否正常 [http://localhost:9090/top.ylonline.dubbo27x.api.RestService/single/echo?message=rest-protocol](http://localhost:9090/top.ylonline.dubbo27x.api.RestService/single/echo?message=rest-protocol) [http://localhost:9090/top.ylonline.dubbo27x.api.MultipleService/multiple/echo?message=dubbo-or-rest-protocol](http://localhost:9090/top.ylonline.dubbo27x.api.MultipleService/multiple/echo?message=dubbo-or-rest-protocol) 使用接口的全限类名作为contextpath是dubbo-2.7.0的bug，请看issue，此PR修复了这个问题 启动 consumer分别访问以下地址来判断consumer端使用多协议是否正常 http://localhost:8080/demo/dubbo?message=dubbo-protocol http://localhost:8080/demo/rest?message=rest-protocol http://localhost:8080/demo/multiple?message=dubbo-or-rest-protocol 异常问题java.lang.NoClassDefFoundError: org/jboss/resteasy/client/jaxrs/engines/ApacheHttpClient4Engine 需要添加以下依赖包，该依赖 provider 端无需依赖，consumer 端需要依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.jboss.resteasy&lt;/groupId&gt; &lt;artifactId&gt;resteasy-client&lt;/artifactId&gt; &lt;version&gt;$&#123;resteasy-client.version&#125;&lt;/version&gt;&lt;/dependency&gt; java.lang.RuntimeException: You must use at least one, but no more than one http method annotation on: top.ylonline.dubbo.spring.boot.example.api.EchoService.echo.. 出现这个异常，说明要在使用的接口标注：@Path、@POST、@Get等javax.ws.rs.*这个路径下相关注解，不应该在实现类标注 12345678910111213141516171819202122package top.ylonline.dubbo.spring.boot.api;import javax.ws.rs.GET;import javax.ws.rs.Path;import javax.ws.rs.QueryParam;/** * @author YL */@Path("/single")public interface RestService &#123; /** * echo * * @param message msg * * @return 信息 */ @GET @Path("/echo") String echo(@QueryParam("message") String message);&#125; Duplicate application configs本人提了一个issue 当使用org.apache.dubbo:dubbo-spring-boot-starter 2.7.0，同时使用xml作为dubbo的配置时，会出现以下异常：1Caused by: java.lang.IllegalStateException: Duplicate application configs: &lt;dubbo:application name=&quot;dubbo-consumer-2.7.x&quot; valid=&quot;true&quot; id=&quot;dubbo-consumer-2.7.x&quot; prefix=&quot;dubbo.application&quot; /&gt; and &lt;dubbo:application valid=&quot;false&quot; prefix=&quot;dubbo.application&quot; /&gt; main 类123456789101112131415@SpringBootApplication( exclude = &#123; DataSourceAutoConfiguration.class, WebSocketServletAutoConfiguration.class, JmxAutoConfiguration.class &#125;)@ImportResource(locations = &#123;"classpath:dubbo.xml"&#125;)@Slf4jpublic class DubboConsumer270 &#123; public static void main(String[] args) &#123; SpringApplication.run(DubboConsumer270.class, args); &#125;&#125; dubbo.xml1234567891011121314151617181920&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://dubbo.apache.org/schema/dubbo" xmlns="http://www.springframework.org/schema/beans" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd http://dubbo.apache.org/schema/dubbo http://dubbo.apache.org/schema/dubbo/dubbo.xsd"&gt; &lt;dubbo:application name="dubbo-consumer-2.7.x"&gt; &lt;dubbo:parameter key="qos.enable" value="false"/&gt; &lt;/dubbo:application&gt; &lt;dubbo:registry address="zookeeper://192.168.56.101:2181" client="curator"/&gt; &lt;dubbo:consumer check="false" client="netty"/&gt; &lt;dubbo:reference id="dubboService" interface="top.ylonline.dubbo27x.api.DubboService"/&gt;&lt;/beans&gt; pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114&lt;properties&gt; &lt;dubbo.version&gt;2.7.0&lt;/dubbo.version&gt; &lt;spring-boot.version&gt;2.0.6.RELEASE&lt;/spring-boot.version&gt;&lt;/properties&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-boot.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;$&#123;dubbo.version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;dubbo.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Dubbo zookeeper registry dependency --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.9&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;2.12.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;2.12.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.29.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;21.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!-- dubbo --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- zk registry dependency --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt;&lt;/dependency&gt; 解决方法： 去掉dubbo-spring-boot-starter依赖，使用xml方式配置dubbo 不使用xml方式配置dubbo，单单使用dubbo-spring-boot-starter方式 No such extension org.apache.dubbo.metadata.store.MetadataReportFactory by name redis问题描述请看：issue 本人提交了一个PR修复了此问题 同时，也可以添加以下依赖来解决这个问题1234567891011&lt;dependency&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-metadata-report-redis&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-metadata-report-api&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Apache</tag>
        <tag>spring-boot</tag>
        <tag>alibaba</tag>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo 2.6.x使用]]></title>
    <url>%2Fposts%2F61ed87a1.html</url>
    <content type="text"><![CDATA[环境代码地址dubbo-v2.6.x dubbo 2.6.5 dubbo-spring-boot-starter 0.2.0 由于 dubbo-2.6.5 及以下版本的 Reference 还不支持 protocol 属性（dubbo-2.7.0支持了），注解暂时无法指定协议，但是可以使用xml配置指定协议 启动 provider 端访问以下地址来判断provider端使用多协议是否正常 http://localhost:9090/demo/echo?message=rest协议 启动 consumer 端分别访问以下地址来判断consumer端使用多协议是否正常 http://localhost:8080/demo/dubbo?message=使用dubbo协议 http://localhost:8080/demo/rest?message=使用rest协议 提示 AnnotationInjectedBeanPostProcessor 异常issue1Caused by: java.lang.ClassNotFoundException: com.alibaba.spring.beans.factory.annotation.AnnotationInjectedBeanPostProcessor 解决，添加以下依赖12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.spring&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt;&lt;/dependency&gt; 异常问题 java.lang.NoClassDefFoundError: org/jboss/resteasy/client/jaxrs/engines/ApacheHttpClient4Engine 需要添加以下依赖包，该依赖 provider 端无需依赖，consumer 端需要依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.jboss.resteasy&lt;/groupId&gt; &lt;artifactId&gt;resteasy-client&lt;/artifactId&gt; &lt;version&gt;$&#123;resteasy-client.version&#125;&lt;/version&gt;&lt;/dependency&gt; java.lang.RuntimeException: You must use at least one, but no more than one http method annotation on: top.ylonline.dubbo.spring.boot.example.api.EchoService.echo.. 出现这个异常，说明要在使用的接口标注：@Path、@POST、@Get等javax.ws.rs.*这个路径下相关注解，不应该在实现类标注 12345678910111213141516171819202122package top.ylonline.dubbo.spring.boot.example.api;import javax.ws.rs.GET;import javax.ws.rs.Path;import javax.ws.rs.QueryParam;/** * @author YL */@Path("/demo")public interface EchoService &#123; /** * echo * * @param message msg * * @return 信息 */ @GET @Path("/echo") String echo(@QueryParam("message") String message);&#125; dubbo-spring-boot-starter 中 spring-boot-starter scope 传递问题1234567891011&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.2.0&lt;/version&gt;&lt;/dependency&gt; 由于dubbo-spring-boot-starter中依赖了spring-boot-starter的scope是true，会导致其继承spring-boot-starter-test的scope，使其变成test123456&lt;!-- Spring Boot dependencies --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;scope&gt;true&lt;/scope&gt;&lt;/dependency&gt; spring 版本不一致问题 项目中 pom.xml 12345678910111213141516171819202122&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.6.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt;&lt;properties&gt; &lt;dubbo.version&gt;2.6.5&lt;/dubbo.version&gt;&lt;/properties&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo-dependencies-bom&lt;/artifactId&gt; &lt;version&gt;$&#123;dubbo.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; dubbo-dependencies-bom pom.xml 1234567891011121314151617&lt;properties&gt; &lt;!-- Common libs --&gt; &lt;spring_version&gt;4.3.16.RELEASE&lt;/spring_version&gt;&lt;/properties&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- Common libs --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-framework-bom&lt;/artifactId&gt; &lt;version&gt;$&#123;spring_version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 由于spring-boot-starter-parent中的依赖的spring版本是5.0.10 .RELEASE，dubbo-dependencies-bom中依赖了spring-framework-bom，版本是4.3.16 .RELEASE，会导致spring的版本不一致问题 解决方法：将dubbo-dependencies-bom作为parent，spring-boot-starter-parent放到dependencyManagement中，但是如果这样的话，有可能引发其他依赖问题]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Apache</tag>
        <tag>spring-boot</tag>
        <tag>alibaba</tag>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读取 js 链接后面的参数]]></title>
    <url>%2Fposts%2Fe053978f.html</url>
    <content type="text"><![CDATA[读取 js 链接后面参数的逻辑 js/log.js 1234567891011121314151617181920// 当前 script src 中的 js urlvar jsUrl = document.scripts[document.scripts.length - 1].src;console.log("url: %o", jsUrl);var paramArr = jsUrl.split('\?');console.log('paramArr: %o', paramArr);if (paramArr.length === 1) &#123; return;&#125;// 所有参数放到这个变量中var map = &#123;&#125;;var keyValueStrArr = paramArr[1].split('\&amp;');console.log('keyValueStrArr: %o', keyValueStrArr);for (var i = 0; i &lt; keyValueStrArr.length; i++) &#123; var keyValueArr = keyValueStrArr[i].split('\='); console.log('keyValueArr: %o', keyValueArr); map[keyValueArr[0]] = keyValueArr[1];&#125;console.log('map: %o', map); 在页面中引入js123456789101112131415&lt;!doctype html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=GBK"/&gt; &lt;meta content="width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=no" name="viewport"&gt; &lt;meta content="yes" name="apple-mobile-web-app-capable"&gt; &lt;meta content="black" name="apple-mobile-web-app-status-bar-style"&gt; &lt;meta content="telephone=no" name="format-detection"&gt; &lt;meta content="email=no" name="format-detection"&gt; &lt;title&gt;在用产品功能&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;测试&lt;/h1&gt;&lt;script src="js/log.js?v=20190124&amp;timestamp=1234567"&gt;&lt;/script&gt;&lt;/html&gt; 控制台打印123456url: js/log.js?v=20190124&amp;timestamp=1234567paramArr: ["js/log.js", "v=20190124&amp;timestamp=1234567"]keyValueStrArr: ["v=20190124", "timestamp=1234567"]keyValueArr: ["v", "20190124"]keyValueArr: ["timestamp", "1234567"]map: &#123;"v": "20190124", "timestamp": "1234567"&#125;]]></content>
      <categories>
        <category>Javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jpipe - A Java implementation of Facebook's bigPipe technology.]]></title>
    <url>%2Fposts%2F97f95e0.html</url>
    <content type="text"><![CDATA[JpipeA Java implementation of Facebook’s bigPipe technology. Jpipe 是通过自定义标签实现的，所以对后端代码零侵入。 HTML 是完成前台页面的功能，而自定义标签可以在后台完成某些操作。 特性 jsp 标签支持 freemarker 指令支持 freemarker 中使用 jsp 标签 为什么使用 BigPipe 解决速度瓶颈 降低延迟时间 BigPipe 适合什么场景主要适用于： 请求时间较长，后端程序需要读取多个API获取数据 页面内容可以划分成多个区块显示，且各个区块之间的关联不大（松耦合） 对SEO需求较弱 多种实现方式的对比 类型 请求数 服务器端压力 用户体验 网页加载速度 模块加载顺序 实现难度 后期维护难度 普通 1 小 差 慢 文档流顺序 简单 一般 Ajax 多 大 好 快 不确定 困难 困难 单线程BigPipe 1 小 好 慢 自定义 一般 一般 多线程BigPipe 1 一般（线程池引起） 好 最快 不确定 最困难 一般 开始线程池配置 属性 类型 是否必填 缺省值 说明 描述 core-size int 否 -1 核心线程数 最小空闲线程数，无论如何都会存活的最小线程数 max-size int 否 1024 最大线程数 Jpipe 能创建用来处理 pagelet 的最大线程数 queue-size int 否 1024 最大等待对列数 请求并发大于 max-size，则被放入队列等待 keep-alive long 否 60000 最大空闲时间(ms) 超过这个空闲时间，且线程数大于 core-size 的，被回收直到线程数等于core-size pre-start-all-core-threads boolean 否 false 预热线程池 是否预先启动 core-size 个线程 pepe 标签、指令 属性 类型 是否必填 缺省值 说明 描述 async boolean 否 true 是否异步执行pagelet任务 pagelet 标签、指令 属性 类型 是否必填 缺省值 说明 描述 domid string 是 html document Id bean string 是 spring bean name var string 是 variable 参数 uri string 否 uri 参数 jsmethod string 否 JP.view 包装数据的js函数 与Spring集成 通过JpipeThreadPoolFactoryBean类 1234567891011121314151617181920212223242526272829303132333435&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean class="top.ylonline.jpipe.spring.JpipeSpringFactoryBean"/&gt; &lt;bean id="pool-1" class="top.ylonline.jpipe.threadpool.common.Pool"&gt; &lt;property name="coreSize" value="-1"/&gt; &lt;property name="maxSize" value="20"/&gt; &lt;property name="preStartAllCoreThreads" value="false"/&gt; &lt;property name="keepAlive" value="12000000"/&gt; &lt;property name="queueSize" value="500"/&gt; &lt;/bean&gt; &lt;!-- 工场模式 --&gt; &lt;bean class="top.ylonline.jpipe.threadpool.util.JpipeThreadPoolFactoryBean"&gt; &lt;property name="pool" ref="pool-1"/&gt; &lt;/bean&gt; &lt;!-- 或者 &lt;bean class="top.ylonline.jpipe.threadpool.util.JpipeThreadPoolFactoryBean"&gt; &lt;property name="pool"&gt; &lt;bean class="top.ylonline.jpipe.threadpool.common.Pool"&gt; &lt;property name="coreSize" value="4"/&gt; &lt;property name="maxSize" value="10"/&gt; &lt;property name="preStartAllCoreThreads" value="true"/&gt; &lt;property name="keepAlive" value="60000"/&gt; &lt;property name="queueSize" value="500"/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; --&gt;&lt;/beans&gt; 通过JpipeThreadPoolBuilder类 12345678910111213141516171819202122&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean class="top.ylonline.jpipe.spring.JpipeSpringFactoryBean"/&gt; &lt;!-- builder 模式 --&gt; &lt;bean id="jpipeThreadPoolBuilder" class="top.ylonline.jpipe.threadpool.util.JpipeThreadPoolBuilder"&gt; &lt;property name="pool"&gt; &lt;bean class="top.ylonline.jpipe.threadpool.common.Pool"&gt; &lt;property name="coreSize" value="1"/&gt; &lt;property name="maxSize" value="1"/&gt; &lt;property name="preStartAllCoreThreads" value="true"/&gt; &lt;property name="keepAlive" value="1"/&gt; &lt;property name="queueSize" value="1"/&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id="jpipeThreadPool-3" factory-bean="jpipeThreadPoolBuilder" factory-method="build"/&gt;&lt;/beans&gt; 通过 JavaBean 方式 12345678910111213141516@Beanpublic JpipeSpringFactoryBean jpipeSpringFactoryBean()&#123; return new JpipeSpringFactoryBean();&#125;@Beanpublic JpipeThreadPoolExecutor jpipeThreadPoolExecutor() &#123; Pool pool = new Pool(); pool.setCoreSize(10); pool.setMaxSize(1024); pool.setPreStartAllCoreThreads(true); pool.getKeepAlive(60000); pool.getQueueSize(512); // return new EagerThreadPool().getExecutor(pool); return new JpipeThreadPoolBuilder(pool).build();&#125; 通过 spring-boot starter pom.xml 依赖 12345&lt;dependency&gt; &lt;groupId&gt;top.ylonline.jpipe&lt;/groupId&gt; &lt;artifactId&gt;jpipe-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;version&#125;&lt;/version&gt;&lt;/dependency&gt; application.yml 配置 12345678jpipe: # enabled: true pool: pre-start-all-core-threads: true core-size: -1 max-size: 20 queue-size: 10 keep-alive: 10000 定义一个 pagelet使用 Spring 的 @Service 定义一个pagelet，实现 PageletBean 接口的 doExec 方法 1234567891011121314@Service("testPagelet1")public class PageletServiceTest implements PageletBean &#123; @Override public Map&lt;String, Object&gt; doExec(final Map&lt;String, String&gt; params) &#123; Map&lt;String, Object&gt; data = new HashMap&lt;&gt;(params); try &#123; TimeUnit.MILLISECONDS.sleep(new Random().nextInt(5000)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return data; &#125;&#125; jpipe js jpipe.core.js12345678910111213141516171819;(function (root, factory) &#123; if (typeof exports === 'object') &#123; module.exports = exports = factory(); &#125; else if (typeof define === 'function' &amp;&amp; define.amd) &#123; define([], factory); &#125; else &#123; root.JP = factory(); &#125;&#125;(this, function () &#123; var JP = JP || (function (window) &#123; return &#123; view: function (json) &#123; var id = json['id']; document.getElementById(id).innerHTML = json['html']; &#125; &#125;; &#125;(window)); return JP;&#125;)); JSP 标签 引入标签 &lt;%@ taglib prefix=&quot;jp&quot; uri=&quot;http://java.yl-online.top/jsp/jpipe&quot; %&gt; 使用自定义标签，最好放到&lt;/body&gt;上面，这样就不会堵塞首屏dom的渲染123456789101112131415161718192021222324252627&lt;%@ page contentType="text/html;charset=UTF-8" trimDirectiveWhitespaces="true" %&gt;&lt;%@ taglib prefix="c" uri="http://java.sun.com/jsp/jstl/core" %&gt;&lt;%@ taglib prefix="jp" uri="http://java.yl-online.top/jsp/jpipe" %&gt;&lt;c:set var="ctx" value="$&#123;pageContext.request.contextPath&#125;"/&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;title&gt;index&lt;/title&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/&gt; &lt;meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=no"&gt; &lt;script type="text/javascript" src="$&#123;ctx&#125;/resources/jpipe.core.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;index&lt;/h1&gt;&lt;div id="pagelet1"&gt;&lt;/div&gt;&lt;div id="pagelet2"&gt;&lt;/div&gt;&lt;jp:pipe&gt; &lt;jp:pagelet domid="pagelet1" bean="testPagelet1" var="item" uri="id=123&amp;name=forever杨"&gt; &lt;h1&gt;jspbody support&lt;/h1&gt; &lt;p&gt;$&#123;item.id&#125;&lt;/p&gt; &lt;/jp:pagelet&gt; &lt;jp:pagelet domid="pagelet2" bean="testPagelet2" var="item2" uri="id=456&amp;name=forever杨2"&gt; &lt;h1&gt;jspbody support&lt;/h1&gt; &lt;p&gt;$&#123;item2.name&#125;&lt;/p&gt; &lt;/jp:pagelet&gt;&lt;/jp:pipe&gt;&lt;/body&gt;&lt;/html&gt; 略：部署到 Tomcat、Jetty 等容器 FTL 指令 通过 freemarker Configuration 配置命名空间123456789101112@Configurationpublic class MvcWevConfig &#123; @Resource private freemarker.template.Configuration configuration; @PostConstruct public void setConfiguration() &#123; Version version = freemarker.template.Configuration.getVersion(); DefaultObjectWrapper wrapper = new DefaultObjectWrapperBuilder(version).build(); this.configuration.setSharedVariable("jp", new FmHashModel(wrapper)); &#125;&#125; 12345678910111213141516171819202122232425&lt;#--&lt;#assign pipe="top.ylonline.jpipe.freemarker.tag.PipeTag"?new() /&gt;--&gt;&lt;#--&lt;#assign pagelet="top.ylonline.jpipe.freemarker.tag.PageletTag"?new() /&gt;--&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;title&gt;index&lt;/title&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/&gt; &lt;meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=no"&gt; &lt;script type="text/javascript" src="jpipe.core.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;index&lt;/h1&gt;&lt;div id="pagelet1"&gt;&lt;/div&gt;&lt;div id="pagelet2"&gt;&lt;/div&gt;&lt;@jp.pipe&gt; &lt;@jp.pagelet domid="pagelet1" bean="testPagelet1" var="item" uri="id=123&amp;name=forever杨"&gt; &lt;h1&gt;testPagelet1 jspbody support&lt;/h1&gt; &lt;p&gt;$&#123;item.id&#125;&lt;/p&gt; &lt;/@jp.pagelet&gt; &lt;@jp.pagelet domid="pagelet2" bean="testPagelet2" var="item2" uri="id=456&amp;name=forever杨2"&gt; &lt;h1&gt;testPagelet2 jspbody support&lt;/h1&gt; &lt;p&gt;$&#123;item2.name&#125;&lt;/p&gt; &lt;/@jp.pagelet&gt;&lt;/@jp.pipe&gt;&lt;/body&gt;&lt;/html&gt; 通过 assign 指令配置 12345678910111213141516171819202122232425&lt;#assign pipe="top.ylonline.jpipe.freemarker.tag.PipeTag"?new() /&gt;&lt;#assign pagelet="top.ylonline.jpipe.freemarker.tag.PageletTag"?new() /&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;title&gt;index&lt;/title&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/&gt; &lt;meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=no"&gt; &lt;script type="text/javascript" src="jpipe.core.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;index&lt;/h1&gt;&lt;div id="pagelet1"&gt;&lt;/div&gt;&lt;div id="pagelet2"&gt;&lt;/div&gt;&lt;@jp.pipe&gt; &lt;@jp.pagelet domid="pagelet1" bean="testPagelet1" var="item" uri="id=123&amp;name=forever杨"&gt; &lt;h1&gt;testPagelet1 jspbody support&lt;/h1&gt; &lt;p&gt;$&#123;item.id&#125;&lt;/p&gt; &lt;/@jp.pagelet&gt; &lt;@jp.pagelet domid="pagelet2" bean="testPagelet2" var="item2" uri="id=456&amp;name=forever杨2"&gt; &lt;h1&gt;testPagelet2 jspbody support&lt;/h1&gt; &lt;p&gt;$&#123;item2.name&#125;&lt;/p&gt; &lt;/@jp.pagelet&gt;&lt;/@jp.pipe&gt;&lt;/body&gt;&lt;/html&gt; 在 FTL 中使用自定义 JSP 标签FTL 是支持使用 JSP 标签的。如果你的项目本来没有使用 JSP 模版，不推荐这种使用做法。因为自定义 JSP 标签是在 JSP 环境中来写作操作的，需要引入 支持 JSP 1.1或者 JSP 1.2的 Servlet 容器（Tomcat、Jetty等Servlet容器部署），而 FTL 可以在非 Servlet 等 Web 环境中使用。 更准确的解释是：尽管 Servlet 容器没有本地的JSP支持，你也可以在 FreeMarker 中使用JSP标签库。 只是确保对JSP 1.2版本(或更新)的 javax.servlet.jsp.* 包在Web应用程序中可用就行。如果你的servlet容器只对JSP 1.1支持， 那么你不得不将下面六个类(比如你可以从Tomcat 5.x或Tomcat 4.x的jar包中提取)复制到Web应用的 WEB-INF/classes/…目录下： javax.servlet.jsp.tagext.IterationTag， javax.servlet.jsp.tagext.TryCatchFinally， javax.servlet.ServletContextListener， javax.servlet.ServletContextAttributeListener， javax.servlet.http.HttpSessionAttributeListener， javax.servlet.http.HttpSessionListener。但是要注意， 因为容器只支持JSP 1.1，通常是使用较早的Servlet 2.3之前的版本，事件监听器可能就不支持，因此JSP 1.2标签库来注册事件监听器会正常工作。 截止发稿：JSP已经发布到 2.3版本 index.ftl 代码使用 &lt;#assign jp=JspTaglibs[&quot;http://java.yl-online.top/jsp/jpipe&quot;] /&gt; 引入自定义 JSP 标签123456789101112131415161718192021222324&lt;#assign jp=JspTaglibs["http://java.yl-online.top/jsp/jpipe"] /&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;title&gt;index&lt;/title&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/&gt; &lt;meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=no"&gt; &lt;script type="text/javascript" src="jpipe.core.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;index&lt;/h1&gt;&lt;div id="pagelet1"&gt;&lt;/div&gt;&lt;div id="pagelet2"&gt;&lt;/div&gt;&lt;@jp.pipe&gt; &lt;@jp.pagelet domid="pagelet1" bean="testPagelet1" var="item" uri="id=123&amp;name=forever杨"&gt; &lt;h1&gt;testPagelet1 support&lt;/h1&gt; &lt;p&gt;$&#123;item.id&#125;&lt;/p&gt; &lt;/@jp.pagelet&gt; &lt;@jp.pagelet domid="pagelet2" bean="testPagelet2" var="item2" uri="id=456&amp;name=forever杨2"&gt; &lt;h1&gt;testPagelet2 support&lt;/h1&gt; &lt;p&gt;$&#123;item2.name&#125;&lt;/p&gt; &lt;/@jp.pagelet&gt;&lt;/@jp.pipe&gt;&lt;/body&gt;&lt;/html&gt; 部署到 undertow maven 依赖 123456789101112&lt;!-- undertow 部署 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-undertow&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- undertow 部署 --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet.jsp-api&lt;/artifactId&gt; &lt;version&gt;2.3.3&lt;/version&gt;&lt;/dependency&gt; 由于 undertow 等容器没有 jsp-api 环境，所以需要依赖 javax.servlet.jsp-api 包，同时要通过 TaglibFactory 配置 freemarker 的 classpathTlds。没有这个配置，会报错：freemarker.ext.jsp.TaglibFactory$TaglibGettingException: No TLD was found for the “http://java.yl-online.top/jsp/jpipe&quot; JSP taglib URI. (TLD-s are searched according the JSP 2.2 specification. In development- and embedded-servlet-container setups you may also need the “MetaInfTldSources” and “ClasspathTlds” freemarker.ext.servlet.FreemarkerServlet init-params or the similar system properites.) Configuration 123456789101112@Configurationpublic class MvcWevConfig &#123; @Resource private FreeMarkerConfigurer freeMarkerConfigurer; @PostConstruct public void loadClassPathTlds() &#123; List&lt;String&gt; classpathTlds = new ArrayList&lt;&gt;(); classpathTlds.add("/META-INF/Jpipe.tld"); freeMarkerConfigurer.getTaglibFactory().setClasspathTlds(classpathTlds); &#125;&#125; 部署到 Tomcat maven 依赖 1234567891011121314151617&lt;!-- 外部 Tomcat 部署 --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;!-- 外部 Tomcat 部署 --&gt; 由于 Tomcat、Jetty中已经有 jsp-api 环境了，这里不需要再依赖 javax.servlet.jsp-api 包]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>BigPipe</tag>
        <tag>Facebook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BigPipe 分块输出遇到的问题]]></title>
    <url>%2Fposts%2Fb0407ea6.html</url>
    <content type="text"><![CDATA[buffer 问题由于“各路”buffer的存在，如果包比较小的话BigPipe的chunked输出很可能会被buffer住。 解决方案 填充空格：将一次flush的数据填充到 buffer_size。 调小buffer，让数据更容易达到 buffer_size。 关闭buffer。 Nginx 负载 buffer对于 Nginx 来说，会有 proxy_buffer 和 fastcgi_buffer。第一种方式，不用调整 buffer，但这种方式很不优雅，而且增加了带宽，并不是很合理。至于调小 buffer，这看起来是一个很好的思路，然而对于 gzip 过的数据来说，最小的 buffer 可能也比较大。 选择了关闭 proxy_buffer 和 fastcgi_buffer 关闭 proxy_buffer 的指令 proxy_buffering off 原生就支持。而关闭 fastcgi_buffer 的 fastcgi_buffering 需要1.5.6版本。 1234Syntax: fastcgi_buffering on | off;Default: fastcgi_buffering on;Context: http, server, locationThis directive appeared in version 1.5.6. 这种方式对所有请求都关闭 buffer 用 http header，用于关闭 buffer Buffering can also be enabled or disabled by passing “yes” or “no” in the “X-Accel-Buffering” response header field. This capability can be disabled using the fastcgi_ignore_headers directive. 因此，配置上完全不用关闭 buffer，只需要在代码中加 header 就好，顺利把 buffer 优雅关闭 1header(&apos;X-Accel-Buffering: no&apos;); 在需要关闭 nginx 的 buffer 的请求响应添加 X-Accel-Buffering 头：response.addHeader(“X-Accel-Buffering”, “no”); 其他问题 123456http &#123; .... fastcgi_buffer_size 1k; fastcgi_buffers 16 1k; ....&#125; 其实读可以这么理解上面的配置，nginx会在攒够一块儿缓冲区的量后，将一块儿数据发出去。上面我们配置了fastcgi_buffers 16 1k; 就是16块儿，大小为1K的缓存。 我们的数据量太小了，连默认的一块儿缓冲区都填不满，没法看到分块儿发送的效果，所以这里我们将缓冲区给调小为1K，这样就能1K为单位分块儿，1K一发，体现出实验效果了。 ios 系统 buffer 问题 经过 nginx 负载 首屏内容最少要 200 个字符（html标签、css样式、js代码不算在内），同时需要配置 X-Accel-Buffering 头才会分块 flush 不经过 nginx 负载 首屏内容最少要 200 个字符（html标签、css样式、js代码不算在内），无需配置 X-Accel-Buffering 头 android 系统 buffer 问题配置 X-Accel-Buffering 头，首屏内容超过 200 字符都不能分块 flush]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>BigPipe</tag>
        <tag>Facebook</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nacos 实现 gateway 路由动态更新]]></title>
    <url>%2Fposts%2Fda547d1d.html</url>
    <content type="text"><![CDATA[通过Nacos配置spring-cloud-gateway的路由规则，实现路由规则的动态更新，代码在托管gateway-nacos 依赖123456789101112131415161718192021222324252627&lt;properties&gt; &lt;spring-cloud.version&gt;Finchley.SR2&lt;/spring-cloud.version&gt;&lt;/properties&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;version&gt;0.2.1.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; spring-cloud-starter-alibaba-nacos-config 的原理是将配置信息注入到Spring的environment中，并在配置更新时自动触发context refresh事件，从而将environment环境中的配置变更为最新配置 application.yml12server: port: 8080 bootstrap.properties12345spring.application.name=nacos-spring-cloud-gateway-examplespring.cloud.nacos.config.server-addr=192.168.56.101:8848spring.cloud.nacos.config.ext-config[0].data-id=gateway.yamlspring.cloud.nacos.config.ext-config[0].refresh=true refresh要配置为true，否则不能动态更新 gateway.yaml 的配置项 App.java12345678910import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class App &#123; public static void main(String[] args) &#123; SpringApplication.run(App.class, args); &#125;&#125; 在 Nacos 控制台新建 gateway.yaml 配置Data ID: gateway.yaml Group: DEFAULT_GROUP123456789101112spring: cloud: gateway: routes: - id: baidu uri: https://www.baidu.com predicates: - Path=/s - id: taobao uri: https://www.taobao.com/ predicates: - Path=/markets/3c/tbdc 配置完成后，执行 App.java 启动网关项目 浏览器访问分别访问http://localhost:8080/s和http://localhost:8080/markets/3c/tbdc，能正常转发到百度、淘宝网站 修改 gateway.yaml 配置12345678spring: cloud: gateway: routes: - id: baidu uri: https://www.baidu.com predicates: - Path=/s 控制台打印以下日志，说明配置修改已经被监听到12org.springframework.cloud.endpoint.event.RefreshEventListener.handle(37) | Refresh keys changed: [spring.cloud.gateway.routes.xxx] 再次访问http://localhost:8080/markets/3c/tbdc，会返回404页面 说明修改的配置已经动态更新了 动态更新原理 Nacos 配置更新的时候，spring-cloud-starter-alibaba-nacos-config会 publish 一个 RefreshEvent 事件，从而使 spring-cloud-commons 的 RefreshEventListener 监听到并触发 ContextRefresher.refresh() 方法。 spring-cloud-gateway 的 RouteRefreshListener 监听了 ApplicationEvent 事件，当 Nacos 触发 ContextRefresher.refresh()后，会监听到 RefreshScopeRefreshedEvent事件并调用RouteRefreshListener.reset() 方法 publish 一个 RefreshRoutesEvent 路由更新事件，达到路由动态更新的目的。 spring-cloud-alibaba-nacos-config在spring-cloud-alibaba-nacos-config中，会默认监听配置的更新，并publish refresh事件 NacosRefreshProperties.java 1234567891011121314@Componentpublic class NacosRefreshProperties &#123; @Value("$&#123;spring.cloud.nacos.config.refresh.enabled:true&#125;") private boolean enabled = true; public boolean isEnabled() &#123; return enabled; &#125; public void setEnabled(boolean enabled) &#123; this.enabled = enabled; &#125;&#125; ...refresh.enabled:true默认开启配置更新事件推送 NacosContextRefresher.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495public class NacosContextRefresher implements ApplicationListener&lt;ApplicationReadyEvent&gt;, ApplicationContextAware &#123; private final static Logger LOGGER = LoggerFactory .getLogger(NacosContextRefresher.class); public static final AtomicLong loadCount = new AtomicLong(0); private final NacosRefreshProperties refreshProperties; private final NacosRefreshHistory refreshHistory; private final ConfigService configService; private ApplicationContext applicationContext; private AtomicBoolean ready = new AtomicBoolean(false); private Map&lt;String, Listener&gt; listenerMap = new ConcurrentHashMap&lt;&gt;(16); public NacosContextRefresher(NacosRefreshProperties refreshProperties, NacosRefreshHistory refreshHistory, ConfigService configService) &#123; this.refreshProperties = refreshProperties; this.refreshHistory = refreshHistory; this.configService = configService; &#125; @Override public void onApplicationEvent(ApplicationReadyEvent event) &#123; // many Spring context if (this.ready.compareAndSet(false, true)) &#123; this.registerNacosListenersForApplications(); &#125; &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) &#123; this.applicationContext = applicationContext; &#125; private void registerNacosListenersForApplications() &#123; if (refreshProperties.isEnabled()) &#123; for (NacosPropertySource nacosPropertySource : NacosPropertySourceRepository .getAll()) &#123; if (!nacosPropertySource.isRefreshable()) &#123; continue; &#125; String dataId = nacosPropertySource.getDataId(); registerNacosListener(nacosPropertySource.getGroup(), dataId); &#125; &#125; &#125; private void registerNacosListener(final String group, final String dataId) &#123; Listener listener = listenerMap.computeIfAbsent(dataId, i -&gt; new Listener() &#123; @Override public void receiveConfigInfo(String configInfo) &#123; loadCount.incrementAndGet(); String md5 = ""; if (!StringUtils.isEmpty(configInfo)) &#123; try &#123; MessageDigest md = MessageDigest.getInstance("MD5"); md5 = new BigInteger(1, md.digest(configInfo.getBytes("UTF-8"))) .toString(16); &#125; catch (NoSuchAlgorithmException | UnsupportedEncodingException e) &#123; LOGGER.warn("[Nacos] unable to get md5 for dataId: " + dataId, e); &#125; &#125; refreshHistory.add(dataId, md5); applicationContext.publishEvent( new RefreshEvent(this, null, "Refresh Nacos config")); if (LOGGER.isDebugEnabled()) &#123; LOGGER.debug("Refresh Nacos config group&#123;&#125;,dataId&#123;&#125;", group, dataId); &#125; &#125; @Override public Executor getExecutor() &#123; return null; &#125; &#125;); try &#123; configService.addListener(dataId, group, listener); &#125; catch (NacosException e) &#123; e.printStackTrace(); &#125; &#125;&#125; spring-cloud-gateway RefreshEventListener.java 1234567891011121314151617181920212223public class RefreshEventListener &#123; private static Log log = LogFactory.getLog(RefreshEventListener.class); private ContextRefresher refresh; private AtomicBoolean ready = new AtomicBoolean(false); public RefreshEventListener(ContextRefresher refresh) &#123; this.refresh = refresh; &#125; @EventListener public void handle(ApplicationReadyEvent event) &#123; this.ready.compareAndSet(false, true); &#125; @EventListener public void handle(RefreshEvent event) &#123; if (this.ready.get()) &#123; // don't handle events before app is ready log.debug("Event received " + event.getEventDesc()); Set&lt;String&gt; keys = this.refresh.refresh(); log.info("Refresh keys changed: " + keys); &#125; &#125;&#125; RouteRefreshListener.java 123456789101112131415161718192021222324252627282930313233343536373839public class RouteRefreshListener implements ApplicationListener&lt;ApplicationEvent&gt; &#123; private HeartbeatMonitor monitor = new HeartbeatMonitor(); private final ApplicationEventPublisher publisher; public RouteRefreshListener(ApplicationEventPublisher publisher) &#123; Assert.notNull(publisher, "publisher may not be null"); this.publisher = publisher; &#125; @Override public void onApplicationEvent(ApplicationEvent event) &#123; if (event instanceof ContextRefreshedEvent || event instanceof RefreshScopeRefreshedEvent || event instanceof InstanceRegisteredEvent) &#123; reset(); &#125; else if (event instanceof ParentHeartbeatEvent) &#123; ParentHeartbeatEvent e = (ParentHeartbeatEvent) event; resetIfNeeded(e.getValue()); &#125; else if (event instanceof HeartbeatEvent) &#123; HeartbeatEvent e = (HeartbeatEvent) event; resetIfNeeded(e.getValue()); &#125; &#125; private void resetIfNeeded(Object value) &#123; if (this.monitor.update(value)) &#123; reset(); &#125; &#125; private void reset() &#123; this.publisher.publishEvent(new RefreshRoutesEvent(this)); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
        <tag>Nacos</tag>
        <tag>spring-cloud-gateway</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nacos 初探]]></title>
    <url>%2Fposts%2Fc706fd60.html</url>
    <content type="text"><![CDATA[Nacos 是一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 以下内容都是基于spring-boot + nacos 依赖管理项目：nacos-spring-boot-example 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;nacos-config-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.2.1&lt;/version&gt;&lt;/dependency&gt; application.yml1234nacos: config: server-addr: 192.168.56.101:8848# namespace: '0278390f-21e8-40ae-b46d-fac0ebb7af97' namespace是命名空间 ID，不能配置命名空间名称。如果不配置namespace，默认使用public 在 Nacos 控制台新建配置Data ID：szim.properties Group：DEFAULT_GROUP 配置内容： 12id=1name=forever杨 App.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import com.alibaba.nacos.api.config.annotation.NacosConfigListener;import com.alibaba.nacos.api.config.annotation.NacosValue;import com.alibaba.nacos.spring.context.annotation.config.EnableNacosConfig;import com.alibaba.nacos.spring.context.annotation.config.NacosPropertySource;import org.springframework.boot.CommandLineRunner;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import org.springframework.core.Ordered;import org.springframework.core.annotation.Order;import lombok.extern.slf4j.Slf4j;@SpringBootApplication@EnableNacosConfig@NacosPropertySource(dataId = App.DATA_ID)@Slf4jpublic class App &#123; static final String DATA_ID = "szim.properties"; public static void main(String[] args) &#123; SpringApplication.run(App.class, args); &#125; @NacosConfigListener( dataId = App.DATA_ID, timeout = 500 ) public void onChange(String newContent) throws Exception &#123; log.info("onChange: &#123;&#125;", newContent); &#125; @Bean @Order(Ordered.LOWEST_PRECEDENCE - 1) public CommandLineRunner secondCommandLineRunner() &#123; return new SecondCommandLineRunner(); &#125; public static class SecondCommandLineRunner implements CommandLineRunner &#123; @NacosValue("$&#123;id:unknown&#125;") private String id; @NacosValue("$&#123;name:unknown&#125;") private String name; @Override public void run(String... args) throws Exception &#123; log.info("id: &#123;&#125;, name: &#123;&#125;", id, name); &#125; &#125;&#125; 支持的配置方式yaml文件 支持的格式 12spring.redis.host: 192.168.199.101spring.redis.port: 6379 不支持的格式 1234spring: redis: host: 192.168.199.101 port: 6379 据说后续版本会支持这种格式 properties文件12spring.redis.host = 192.168.199.101spring.redis.port = 6379 读取配置12345@Value("$&#123;spring.redis.port&#125;")private String host;@NacosValue(value = "$&#123;spring.redis.port&#125;", autoRefreshed = true)private String port; Spring @Value注解和 Nacos @NacosValue 注解 注解 是否支持动态更新 补充 @Value 否 @NacosValue 是 前提需配置autoRefreshed=true 1.3.0+ 版本使用分布式存储启动命令：sh bin/startup.sh -p embedded]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
        <tag>alibaba</tag>
        <tag>Nacos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hibernate 配置字段加解密]]></title>
    <url>%2Fposts%2F996dbf54.html</url>
    <content type="text"><![CDATA[使用 Hibernate 配置数据库字段的加密、解密函数。 可以使用@ColumnTransformer注解的read、write属性，或者使用 xml 配置的column标签的read、write属性 本例子基于 spring-boot-starter-data-jpa、druid-spring-boot-starter、spring-boot-starter-test User 实体类配置 wx_crypto.des_decrypt、wx_crypto.des_encrypt自定义的加解密函数，可以使用 Oracle 内置的 to_char、nvl 等函数代替，效果是一样的 实体类注解配置 12345678910111213141516171819202122232425262728293031323334353637383940import lombok.Data;import lombok.NoArgsConstructor;import org.hibernate.annotations.ColumnTransformer;import org.hibernate.annotations.DynamicInsert;import org.hibernate.annotations.DynamicUpdate;import javax.persistence.Column;import javax.persistence.Entity;import javax.persistence.GeneratedValue;import javax.persistence.Id;import javax.persistence.SequenceGenerator;import javax.persistence.Table;/** * 用户信息 */@Entity@Table(name = "t_user")@DynamicInsert@DynamicUpdate@Data@NoArgsConstructorpublic class User implements java.io.Serializable &#123; private static final long serialVersionUID = 1L; @Id @SequenceGenerator(name = "sq_name", sequenceName = "sq_user") @GeneratedValue(generator = "sq_name") private Long id; private String userName; @ColumnTransformer( // 注意这里的 cert_no 使用的是数据库字段名，不是使用实体类的字段名 read = "wx_crypto.des_decrypt(cert_no)", write = "wx_crypto.des_encrypt(?)" ) @Column(name = "cert_no") private String certNo; // 身份证号&#125; read 配置要使用数据库字段名，否则会报错：ORA-00904: “USER0_”.”CERTNO”: 标识符无效 实体类 User.hbm.xml 配置 注意：xml 配置 read、write 需要 hibernate 3.5.x 以上版本才支持 1234567891011121314151617181920212223&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC "-//Hibernate/Hibernate Mapping DTD 4.0//EN" "http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd"&gt;&lt;hibernate-mapping&gt; &lt;class name="top.ylonline.domain.User" table="t_user" dynamic-insert="true" dynamic-update="true"&gt; &lt;id name="id" type="java.lang.Long"&gt; &lt;column name="ID" precision="22" scale="0"/&gt; &lt;generator class="sequence"&gt; &lt;param name="sequence"&gt;sq_user&lt;/param&gt; &lt;/generator&gt; &lt;/id&gt; &lt;property name="userName" type="java.lang.String"&gt; &lt;column name="user_name" length="20"/&gt; &lt;/property&gt; &lt;property name="certNo" type="java.lang.String"&gt; &lt;column name="cert_no" length="18" read="wx_crypto.des_decrypt(cert_no)" write="wx_crypto.des_encrypt(?)"/&gt; &lt;/property&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt; read 配置要使用数据库字段名，否则会报错：ORA-00904: “USER0_”.”CERTNO”: 标识符无效 测试 UserRepository.java 12345678910import top.ylonline.domain.User;import org.springframework.data.jpa.repository.JpaRepository;import org.springframework.data.jpa.repository.JpaSpecificationExecutor;/** * @author Created by YL on 2017/8/21 */public interface UserRepository extends JpaRepository&lt;User, Long&gt;, JpaSpecificationExecutor&lt;User&gt; &#123; User findFirstByUserName(String userName);&#125; 数据库配置 1234567891011121314151617181920212223242526272829303132333435363738spring: datasource: url: jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=127.0.0.1)(PORT=1521))(CONNECT_DATA=(SERVER=DEDICATED)(SERVICE_NAME=bkimDB))) username: test password: Uf+4C5nKZ9gLxZbvG+pPl4Wb6xDM5/xiPzPLM4PZ/MRESrucR1z9FQUJXnuTiXM+6bdAmJzYRcchhHM+ENmt6g== druid: initial-size: 3 min-idle: 3 max-active: 10 max-wait: 60000 keep-alive: true time-between-eviction-runs-millis: 60000 min-evictable-idle-time-millis: 300000 validation-query: SELECT 'x' FROM DUAL test-while-idle: true test-on-borrow: false test-on-return: false pool-prepared-statements: true max-pool-prepared-statement-per-connection-size: 20 filter: wall: enabled: true stat: enabled: false stat-view-servlet: enabled: false config: enabled: true web-stat-filter: enabled: false connection-properties: config.decrypt=true;config.decrypt.key=MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAMcX0mcr65fnwkYTEyxlfiQHxyDGHGzp3hH37na7cmN20y7hd5JjlwXq91xbRzpI/LCu/ZJs5TPhwmHwf46VPy8CAwEAAQ== jpa: show-sql: true database: oracle properties: hibernate: format_sql: true dialect: org.hibernate.dialect.Oracle10gDialect Test 类 123456789101112131415161718192021222324252627282930313233343536373839import top.ylonline.domain.User;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.autoconfigure.jdbc.AutoConfigureTestDatabase;import org.springframework.boot.test.autoconfigure.orm.jpa.DataJpaTest;import org.springframework.test.context.junit4.SpringRunner;import org.springframework.transaction.annotation.Propagation;import org.springframework.transaction.annotation.Transactional;/** * @author Created by YL on 2018/12/7 */@RunWith(SpringRunner.class)@DataJpaTest// 测试环境默认是会回滚数据，操作的数据是不会插入、更新到数据库的。如果要插入、更新到数据库，要配置一下事物@Transactional(propagation = Propagation.NOT_SUPPORTED)// 使用真实环境测试，否则使用的是内嵌的内存数据库@AutoConfigureTestDatabase(replace = AutoConfigureTestDatabase.Replace.NONE)// 使用 druid 连接池@Import(&#123;DruidDataSourceAutoConfigure.class&#125;)public class UserRepositoryTest &#123; @Autowired private UserRepository userRepository; @Test public void save() &#123; User user = new User(); oauth.setUserName("forever杨"); oauth.setCertNo("sldfjlsj"); userRepository.save(user); &#125; @Test public void findOne() &#123; User user = userRepository.findFirstByUserName("forever杨"); System.out.println(user); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
        <tag>Hibernate</tag>
        <tag>spring-boot</tag>
        <tag>DataJpaTest</tag>
        <tag>jpa</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle Package 包说明和包体]]></title>
    <url>%2Fposts%2F6b176628.html</url>
    <content type="text"><![CDATA[在包中定义的函数，包体中实现的时候，函数名、参数名、类型都要一致，否则报错 定义包说明1234567891011CREATE OR REPLACE PACKAGE WX_CRYPTO IS -- 定义 DES encrypt 函数 FUNCTION DES_ENCRYPT(INPUT_STRING IN VARCHAR2) RETURN VARCHAR2; FUNCTION DES_ENCRYPT(INPUT_STRING IN VARCHAR2, KEY_STRING IN VARCHAR2) RETURN VARCHAR2; -- 定义 DES decrypt 函数 FUNCTION DES_DECRYPT(INPUT_STRING IN VARCHAR2) RETURN VARCHAR2 DETERMINISTIC; FUNCTION DES_DECRYPT(INPUT_STRING IN VARCHAR2, KEY_STRING IN VARCHAR2) RETURN VARCHAR2 DETERMINISTIC;END WX_CRYPTO; 在创建基于自定义函数时, 指定 deterministic 参数，在创建函数索引，就没有问题了 比如： 123456789/* * 如果函数不加 deterministic，以下创建索引 SQL 语句会报错： * ORA-30553: The function is not deterministic */create index i_user_decrypt_user_no on USER (wx_crypto.des_decrypt(user_no));-- 以下查询是会走索引的select * from user where wx_crypto.des_decrypt(user_no) = '123'; 定义包体123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869CREATE OR REPLACE PACKAGE BODY WX_CRYPTO IS -- 实现 DES encrypt 函数（一个参数） FUNCTION DES_ENCRYPT(INPUT_STRING IN VARCHAR2 -- 明文 ) RETURN VARCHAR2 AS BEGIN RETURN WX_CRYPTO.DES_ENCRYPT(INPUT_STRING =&gt; INPUT_STRING, KEY_STRING =&gt; 'eda93763'); END; -- 实现 DES encrypt 函数（两个参数） FUNCTION DES_ENCRYPT(INPUT_STRING IN VARCHAR2, -- 明文 KEY_STRING IN VARCHAR2 -- 密钥 ) RETURN VARCHAR2 AS V_TEXT VARCHAR2(4000); -- 明文。长度要是 8 的倍数，若不足 8 的倍数，则用隐藏字符串 chr(0) 补足 V_TEXT_RAW RAW(2048); -- 明文 V_KEY_RAW RAW(128); -- 密钥 V_ENCRYPT_RAW RAW(2048); -- 加密后的字符串 BEGIN IF INPUT_STRING IS NULL THEN RETURN NULL; END IF; IF INSTR(INPUT_STRING, '&#123;DES&#125;') = 1 THEN RETURN INPUT_STRING; END IF; -- 向右补足。CHR(0) 隐藏字符串 V_TEXT := RPAD(INPUT_STRING, (TRUNC(LENGTHB(INPUT_STRING) / 8) + 1) * 8, CHR(0)); -- 转换成 16 进制 V_TEXT_RAW := UTL_I18N.STRING_TO_RAW(V_TEXT, 'ZHS16GBK'); V_KEY_RAW := UTL_I18N.STRING_TO_RAW(KEY_STRING, 'ZHS16GBK'); V_ENCRYPT_RAW := DBMS_OBFUSCATION_TOOLKIT.DESENCRYPT(INPUT =&gt; V_TEXT_RAW, KEY =&gt; V_KEY_RAW); RETURN '&#123;DES&#125;' || RAWTOHEX(V_ENCRYPT_RAW); END; -- 实现 DES decrypt 函数（一个参数） FUNCTION DES_DECRYPT(INPUT_STRING IN VARCHAR2 -- 明文 ) RETURN VARCHAR2 DETERMINISTIC AS BEGIN RETURN WX_CRYPTO.DES_DECRYPT(INPUT_STRING =&gt; INPUT_STRING, KEY_STRING =&gt; 'eda93763'); END; -- 实现 DES decrypt 函数（两个参数） FUNCTION DES_DECRYPT(INPUT_STRING IN VARCHAR2, -- 密文 KEY_STRING IN VARCHAR2 -- 密钥 ) RETURN VARCHAR2 DETERMINISTIC AS V_TEXT_RAW RAW(2048); -- 密文 V_KEY_RAW RAW(128); -- 密钥 V_DECRYPT_RAW RAW(2048); -- 解密后的明文 V_DECRYPT_STRING VARCHAR2(4000); -- 解密后的明文 BEGIN IF INPUT_STRING IS NULL THEN RETURN NULL; END IF; IF INSTR(INPUT_STRING, '&#123;DES&#125;') = 1 THEN V_TEXT_RAW := HEXTORAW(SUBSTR(INPUT_STRING, 6)); -- 转换成 16 进制 V_KEY_RAW := UTL_I18N.STRING_TO_RAW(KEY_STRING, 'ZHS16GBK'); -- 解密 V_DECRYPT_RAW := DBMS_OBFUSCATION_TOOLKIT.DESDECRYPT(INPUT =&gt; V_TEXT_RAW, KEY =&gt; V_KEY_RAW); -- RAW_TO_CHAR 转换成字符串 V_DECRYPT_STRING := UTL_I18N.RAW_TO_CHAR(V_DECRYPT_RAW, 'ZHS16GBK'); -- RTRIM 去除字符串右侧的隐藏字符串 CHR(0) RETURN RTRIM(V_DECRYPT_STRING, CHR(0)); END IF; RETURN INPUT_STRING; END;END WX_CRYPTO; 如果调用多次函数，最多也只进行一次加密、或者解密操作 使用12345678910111213141516171819202122-- 使用默认密钥-- 使用默认密钥SELECT WX_CRYPTO.DES_ENCRYPT('1234中文abc') ENC, WX_CRYPTO.DES_ENCRYPT(WX_CRYPTO.DES_ENCRYPT('1234中文abc')) ENC2, WX_CRYPTO.DES_DECRYPT(WX_CRYPTO.DES_ENCRYPT('1234中文abc')) DEC, WX_CRYPTO.DES_DECRYPT(WX_CRYPTO.DES_DECRYPT(WX_CRYPTO.DES_ENCRYPT('1234中文abc'))) DEC2 FROM DUAL;-- 使用指定密钥SELECT WX_CRYPTO.DES_ENCRYPT('1234中文abc', '12345678') ENC, WX_CRYPTO.DES_ENCRYPT(WX_CRYPTO.DES_ENCRYPT('1234中文abc', '12345678'), '12345678') ENC2, WX_CRYPTO.DES_DECRYPT(WX_CRYPTO.DES_ENCRYPT('1234中文abc', '12345678'), '12345678') DEC, WX_CRYPTO.DES_DECRYPT(WX_CRYPTO.DES_DECRYPT(WX_CRYPTO.DES_ENCRYPT('1234中文abc', '12345678'), '12345678'), '12345678') DEC2 FROM DUAL;]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>Package</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-session + redis 保存会话 session]]></title>
    <url>%2Fposts%2F74b23c9e.html</url>
    <content type="text"><![CDATA[基于spring-boot + spring-session + redis 实现 session 共享 依赖12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-boot-starter-data-redis.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-session-data-redis.version&#125;&lt;/version&gt;&lt;/dependency&gt; spring-boot 1.x123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293import com.alibaba.fastjson.support.spring.GenericFastJsonRedisSerializer;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.annotation.Bean;import org.springframework.data.redis.serializer.RedisSerializer;import org.springframework.session.config.annotation.web.http.SpringHttpSessionConfiguration;import org.springframework.session.data.redis.config.ConfigureRedisAction;import org.springframework.session.data.redis.config.annotation.web.http.EnableRedisHttpSession;import org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration;import org.springframework.session.web.http.CookieHttpSessionStrategy;import org.springframework.session.web.http.CookieSerializer;import org.springframework.session.web.http.DefaultCookieSerializer;import org.springframework.session.web.http.HttpSessionStrategy;/** * 使用 redis 存储 HttpSession * &lt;pre&gt; * spring-boot 两种方式启用 spring-session + redis * 1、使用 @EnableRedisHttpSession 注解 * 2、在application.properties 配置 spring.session.store-type: redis * 优先级：@EnableRedisHttpSession &gt; application.properties * &lt;/pre&gt; * * @author Created by YL on 2018/11/7 */@EnableRedisHttpSessionpublic class RedisHttpSessionConfig &#123; /** * disable sessions expire event notifications */ @Bean public ConfigureRedisAction configureRedisAction() &#123; return ConfigureRedisAction.NO_OP; &#125; /** * spring-session 使用 fastjson 序列化 * &lt;p&gt;bean name 要配置成 &lt;strong&gt;springSessionDefaultRedisSerializer&lt;/strong&gt;，否则不生效，参考： * &#123;@link RedisHttpSessionConfiguration#setDefaultRedisSerializer(org.springframework.data.redis.serializer.RedisSerializer)&#125;&lt;/p&gt; */ @Bean @Qualifier("springSessionDefaultRedisSerializer") public RedisSerializer&lt;Object&gt; springSessionDefaultRedisSerializer() &#123; return new GenericFastJsonRedisSerializer(); &#125; /** * cookie serializer * &lt;p&gt; * &#123;@link SpringHttpSessionConfiguration#setCookieSerializer(org.springframework.session.web.http.CookieSerializer)&#125; */ @Bean @Qualifier("cookieSerializer") public CookieSerializer cookieSerializer() &#123; DefaultCookieSerializer serializer = new DefaultCookieSerializer(); serializer.setCookieName("x-auth-token"); // serializer.setDomainName("localhost"); // serializer.setDomainNamePattern("(\\w+)");//("^.+?\\.(\\w+\\.[a-z]+)$"); serializer.setCookiePath("/"); serializer.setUseHttpOnlyCookie(true); // 由于spring-boot 1.x和2.x这个默认值不一样，所以统一设置成 false serializer.setUseBase64Encoding(false); // 防止 http、https 混用的情况 serializer.setUseSecureCookie(false); return serializer; &#125; /** * HttpSessionStrategy * &lt;p&gt; * &#123;@link SpringHttpSessionConfiguration#setHttpSessionStrategy(org.springframework.session.web.http.HttpSessionStrategy)&#125; */ @Bean @Qualifier("httpSessionStrategy") public HttpSessionStrategy httpSessionStrategy() &#123; CookieHttpSessionStrategy strategy = new CookieHttpSessionStrategy(); strategy.setCookieSerializer(cookieSerializer()); return strategy; &#125; // /** // * HttpSessionStrategy // * &lt;p&gt; // * &#123;@link SpringHttpSessionConfiguration#setHttpSessionStrategy(org.springframework.session.web.http // .HttpSessionStrategy)&#125; // */ // @Bean // @Qualifier("httpSessionStrategy") // public HttpSessionStrategy httpSessionStrategy() &#123; // HeaderHttpSessionStrategy strategy = new HeaderHttpSessionStrategy(); // strategy.setHeaderName(UTConst.COOKIE_NAME); // return strategy; // &#125;&#125; spring-boot 2.x123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990import com.alibaba.fastjson.support.spring.GenericFastJsonRedisSerializer;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.annotation.Bean;import org.springframework.data.redis.serializer.RedisSerializer;import org.springframework.session.config.annotation.web.http.SpringHttpSessionConfiguration;import org.springframework.session.data.redis.config.ConfigureRedisAction;import org.springframework.session.data.redis.config.annotation.web.http.EnableRedisHttpSession;import org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration;import org.springframework.session.web.http.CookieHttpSessionIdResolver;import org.springframework.session.web.http.CookieSerializer;import org.springframework.session.web.http.DefaultCookieSerializer;import org.springframework.session.web.http.HttpSessionIdResolver;/*** 使用 redis 存储 HttpSession* &lt;pre&gt;* spring-boot 两种方式启用 spring-session + redis* 1、使用 @EnableRedisHttpSession 注解* 2、在application.properties 配置 spring.session.store-type: redis* 优先级：@EnableRedisHttpSession &gt; application.properties* &lt;/pre&gt;** @author Created by YL on 2018/11/7*/@EnableRedisHttpSessionpublic class RedisHttpSessionConfig &#123; /** * disable sessions expire event notifications */ @Bean public ConfigureRedisAction configureRedisAction() &#123; return ConfigureRedisAction.NO_OP; &#125; /** * spring-session 使用 fastjson 序列化 * &lt;p&gt;bean name 要配置成 &lt;strong&gt;springSessionDefaultRedisSerializer&lt;/strong&gt;，否则不生效，参考： * &#123;@link RedisHttpSessionConfiguration#setDefaultRedisSerializer(RedisSerializer)&#125;&lt;/p&gt; */ @Bean @Qualifier("springSessionDefaultRedisSerializer") public RedisSerializer&lt;Object&gt; springSessionDefaultRedisSerializer() &#123; return new GenericFastJsonRedisSerializer(); &#125; /** * cookie serializer * &lt;p&gt; * &#123;@link SpringHttpSessionConfiguration#setCookieSerializer(CookieSerializer)&#125; */ @Bean @Qualifier("cookieSerializer") public CookieSerializer cookieSerializer() &#123; DefaultCookieSerializer serializer = new DefaultCookieSerializer(); serializer.setCookieName("x-auth-token"); // serializer.setDomainName("localhost"); // serializer.setDomainNamePattern("(\\w+)");//("^.+?\\.(\\w+\\.[a-z]+)$"); serializer.setCookiePath("/"); serializer.setUseHttpOnlyCookie(true); // 由于spring-boot 1.x和2.x这个默认值不一样，所以统一设置成 false serializer.setUseBase64Encoding(false); // 防止 http、https 混用的情况 serializer.setUseSecureCookie(false); return serializer; &#125; /** * HttpSessionIdResolver * &lt;p&gt; * &#123;@link SpringHttpSessionConfiguration#setHttpSessionIdResolver(HttpSessionIdResolver)&#125; */ @Bean @Qualifier("httpSessionIdResolver") public HttpSessionIdResolver httpSessionIdResolver() &#123; CookieHttpSessionIdResolver resolver = new CookieHttpSessionIdResolver(); resolver.setCookieSerializer(cookieSerializer()); return resolver; &#125; // /** // * HttpSessionIdResolver // * &lt;p&gt; // * &#123;@link SpringHttpSessionConfiguration#setHttpSessionIdResolver(HttpSessionIdResolver)&#125; // */ // @Bean // @Qualifier("httpSessionIdResolver") // public HttpSessionIdResolver httpSessionIdResolver() &#123; // return new HeaderHttpSessionIdResolver("x-gdwxkf-token"); // &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>spring-boot</tag>
        <tag>spring-session</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle DES 加解密]]></title>
    <url>%2Fposts%2F2b37b6b3.html</url>
    <content type="text"><![CDATA[DES encrypt1234567891011121314CREATE OR REPLACE FUNCTION DES_ENCRYPT(P_TEXT VARCHAR2, -- 明文。长度要是 8 的倍数，若不足 8 的倍数，则用空白补足 P_KEY VARCHAR2) -- 密钥。长度最少要 8 位以上; 不同的 Key，加密结果将会不同 RETURN VARCHAR2 IS V_TEXT VARCHAR2(4000); -- 不足 8 的倍数，补足后的字符串 V_ENCRYPT RAW(2048); -- 加密后的字符串BEGIN -- 补足。CHR(0) 隐藏字符串 V_TEXT := RPAD(P_TEXT, (TRUNC(LENGTHB(P_TEXT) / 8) + 1) * 8, CHR(0)); V_ENCRYPT := DBMS_OBFUSCATION_TOOLKIT.DESENCRYPT(INPUT =&gt; UTL_I18N.STRING_TO_RAW(V_TEXT, 'ZHS16GBK'), -- 转换成 16 进制 KEY =&gt; UTL_I18N.STRING_TO_RAW(P_KEY, 'ZHS16GBK')); -- 转换成 16 进制 RETURN RAWTOHEX(V_ENCRYPT);END; DES decrypt123456789101112131415CREATE OR REPLACE FUNCTION DES_DECRYPT(P_TEXT VARCHAR2, -- 密文 P_KEY VARCHAR2) -- 密钥 RETURN VARCHAR2 IS V_DECRYPT RAW(2048); -- 解密后的明文BEGIN IF (P_TEXT IS NULL OR P_TEXT = '') THEN RETURN ''; END IF; V_DECRYPT := DBMS_OBFUSCATION_TOOLKIT.DESDECRYPT(INPUT =&gt; HEXTORAW(P_TEXT), KEY =&gt; UTL_I18N.STRING_TO_RAW(P_KEY, 'ZHS16GBK')); -- 需转换成 16 进制 -- RTRIM 去除字符串右侧空白：CHR(0) -- RAW_TO_CHAR 转换成字符串 RETURN RTRIM(UTL_I18N.RAW_TO_CHAR(V_DECRYPT, 'ZHS16GBK'), CHR(0));END;]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>DES</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-boot shiro 配置]]></title>
    <url>%2Fposts%2Fae8ab207.html</url>
    <content type="text"><![CDATA[初始化使用@Configuration配置shiro无状态登录时出现的问题，在subject.login之后当前线程重新绑定了一个假定subject，isAuthenticated。 这里自定义的访问拦截器的创建需要放在shiroFilter之后，如下： 123456789101112131415161718192021222324252627282930/** * Shiro 的 Web 过滤器链 */@Bean("shiroFilter")public ShiroFilterFactoryBean shiroFilter() &#123; ShiroFilterFactoryBean filter = new ShiroFilterFactoryBean(); filter.setSecurityManager(securityManager()); Map&lt;String, Filter&gt; filters = new LinkedHashMap&lt;String, Filter&gt;(); // 无状态授权器 filters.put("statelessAuthc", statelessAuthcFilter()); filter.setFilters(filters); /** * 配置shiro拦截器链 */ // filterChainDefinitionMap 必须是 LinkedHashMap 因为它必须保证有序 Map&lt;String, String&gt; chain = new LinkedHashMap&lt;String, String&gt;(); // anon-表示可以匿名访问， authc-表示需要认证才可以访问 // 因为禁用了 Session，所以这里不能使用 authc 了，否则会报 DisabledSessionException 异常 chain.put("/services/*", "statelessAuthc"); chain.put("/**", "anon"); filter.setFilterChainDefinitionMap(chain); return filter;&#125;@Beanpublic AccessControlFilter statelessAuthcFilter() &#123; return new StatelessAccessControlFilter();&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
        <tag>shiro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-boot parent]]></title>
    <url>%2Fposts%2F3ef60930.html</url>
    <content type="text"><![CDATA[End of Lifesee：https://spring.io/projects/platform The Platform will reach the end of its supported life on 9 April 2019. Maintenence releases of both the Brussels and Cairo lines will continue to be published up until that time. Users of the Platform are encourage to start using Spring Boot’s dependency management directory, either by using spring-boot-starter-parent as their Maven project’s parent, or by importing the spring-boot-dependencies bom. spring-boot-starter-parent123456&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt; spring-boot-dependencies12345678910111213141516&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;spring-boot.version&gt;2.0.4.RELEASE&lt;/spring-boot.version&gt;&lt;/properties&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-boot.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt;&lt;/dependency&gt;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo 多协议配置]]></title>
    <url>%2Fposts%2F90506ac1.html</url>
    <content type="text"><![CDATA[本文主要阐述，Dubbo 多协议、单协议多端口实现 环境dubbo 2.6.5、2.7.0 dubbo-spring-boot-starter 0.2.0 多协议实现在 application.yml 中添加如下配置首先要开启多协议的配置开关，再通过 protocols 指定多协议 1234567891011121314dubbo: config: # 开启多个配置绑定 multiple: true # 多协议配置 protocols: dubbo: name: dubbo port: 20885 server: netty4 rest: name: rest port: 8080 server: netty 开启了多协议之后，可以使用@Service(protocol = {&quot;dubbo&quot;, &quot;rest&quot;})指定协议类型 如果不需要多协议，也要明确指定其中一个协议@Service(protocol = {&quot;dubbo&quot;}) rest.server可以是servlet、jetty、tomcat、netty，这里以netty4为例 对比单协议的配置 12345&gt; dubbo:&gt; protocol:&gt; name: dubbo&gt; port: 20885&gt; 如果是单协议配置，不能这样指定协议@Service(protocol = {&quot;dubbo&quot;})，否则会报错找不到dubbo compent 要在pom.xml引入 resteasy 的依赖 12345678910111213141516171819&lt;dependency&gt; &lt;groupId&gt;org.jboss.resteasy&lt;/groupId&gt; &lt;artifactId&gt;resteasy-jaxrs&lt;/artifactId&gt; &lt;version&gt;3.0.26.Final&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.jboss.resteasy&lt;/groupId&gt; &lt;artifactId&gt;resteasy-netty4&lt;/artifactId&gt; &lt;version&gt;3.0.26.Final&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;javax.validation&lt;/groupId&gt; &lt;artifactId&gt;validation-api&lt;/artifactId&gt; &lt;version&gt;1.1.0.Final&lt;/version&gt;&lt;/dependency&gt; Dubbo Service 指定多个协议1234567@javax.ws.rs.Path("/user")public interface UserService &#123; @javax.ws.rs.GET @javax.ws.rs.Path("/say-hello") public String sayHello(@javax.ws.rs.QueryParam("name") String name);&#125; rest相关的Path、GET、POST要在接口上配置 验证 rest 服务12$ curl http://localhost:8080/demo/say-hello?name=foreverHello, forever! 单协议多端口实现在 application.yml 中添加如下配置首先要开启多协议的配置开关，再通过 protocols 指定多协议 1234567891011121314dubbo: config: # 开启多个配置绑定 multiple: true # 多协议配置 protocols: dubbo: name: dubbo port: 20885 server: netty4 dubbo2: name: dubbo port: 20886 server: netty4 Dubbo Service 指定多个协议123456789101112import com.alibaba.dubbo.config.annotation.Service;// @Service(// protocol = &#123;"dubbo", "dubbo2"&#125;// )@Servicepublic class UserServiceImpl implements UserService &#123; public String sayHello(String name) &#123; return "Hello, " + name + "!"; &#125;&#125; @Service 不配置 protocol，默认使用所有协议]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Apache</tag>
        <tag>spring-boot</tag>
        <tag>alibaba</tag>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 安装 redis]]></title>
    <url>%2Fposts%2F6fffbcc4.html</url>
    <content type="text"><![CDATA[拉取镜像 12345# 默认拉取 redis:latest 版本$ docker pull redis# 拉取指定版本镜像$ docker pull redis:4.0.11 运行 redis 容器 12345# 默认运行 redis:latest 版本$ docker run -p 6379:6379 --name redis -d redis# 运行指定版本 redis$ docker run -p 6379:6379 --name redis -d redis:4.0.11 使用 docker-compose 1234567891011# 默认运行 redis:latest 版本redis: image: 'redis' ports: - '6379:6379'# 运行指定版本 redisredis: image: 'redis:4.0.11' ports: - '6379:6379' 1$ docker-compose up -d redis]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>docker-compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 安装 elasticsearch]]></title>
    <url>%2Fposts%2F6a0c4822.html</url>
    <content type="text"><![CDATA[elasticsearchhttps://www.elastic.co/guide/en/elasticsearch/reference/6.6/docker.html#docker-prod-cluster-composefile docker-compose.yml123456789101112131415161718192021222324version: '3.8'services: elasticsearch: image: elasticsearch:6.6.2 container_name: ts_elasticsearch ports: - "9200:9200" restart: always volumes: - "/data/docker/elasticsearch/data:/usr/share/elasticsearch/data" environment: - "bootstrap.memory_lock=true" - "ES_JAVA_OPTS=-Xms1g -Xmx1g" - "discovery.type=single-node" ulimits: memlock: soft: -1 hard: -1 networks: - elknetnetworks: elknet: driver: bridge logstashhttps://www.elastic.co/guide/en/logstash/6.6/docker-config.html docker-compose.yml 123456789101112131415161718192021version: '3.8'services: logstash: image: logstash:6.6.2 container_name: ts_logstash ports: - "5044:5044" restart: always volumes: - "/data/docker/logstash/pipeline:/usr/share/logstash/pipeline" - "/data/docker/logstash/config:/usr/share/logstash/config" environment: LS_JAVA_OPTS: "-Xmx512m -Xms512m" networks: - elknet depends_on: - elasticsearchnetworks: elknet: driver: bridge kibanahttps://www.elastic.co/guide/en/kibana/6.6/docker.html docker-compose.yml 123456789101112131415161718version: '3.8'services: kibana: image: kibana:6.6.2 container_name: ts_kibana ports: - 5601:5601 restart: always volumes: - "/data/docker/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml" networks: - elknet depends_on: - elasticsearchnetworks: elknet: driver: bridge]]></content>
      <categories>
        <category>elk</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>docker-compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 安装 elk 环境]]></title>
    <url>%2Fposts%2F6a0c4822.html</url>
    <content type="text"><![CDATA[安装 从 Docker 仓库中拉取镜像 1docker pull sebp/elk 拉取指定版本镜像 1docker pull sebp/elk:671 启动容器使用docker-compose docker-compose.yml 1234567891011121314151617181920212223242526elk: image: sebp/elk:671 ports: # Elasticsearch - "9200:9200" # Logstash - "5044:5044" # Kibana - "5601:5601" volumes: # elasticsearch # 持久日志数据 - "/data/docker/elk/elasticsearch:/var/lib/elasticsearch" # logstash ## config/logstash.yml, config/jvm.options, config/pipelines.yml ## logstash-plugin：/opt/logstash/bin - "/data/docker/elk/logstash/:/opt/logstash" ## 01-lumberjack-input.conf, 02-beats-input.conf - "/data/docker/elk/logstash/conf.d:/etc/logstash/conf.d" # kibana ## kibana-plugin：/opt/kibana/bin - "/data/docker/elk/kibana/:/opt/kibana" restart: always environment: - "bootstrap.memory_lock=true" - "ES_JAVA_OPTS=-Xss256k" 1docker-compose up -d 启动异常 m.max_map_count [65530] is too low 12342020-08-21T04:04:58,114[o.e.b.BootstrapChecks ] [8pUsAbG] bound or publishing to a non-loopback address, enforcing bootstrap checks2020-08-21T04:04:58,120[o.e.b.Bootstrap ] [8pUsAbG] node validation exception[1] bootstrap checks failed[1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 配置 /etc/sysctl.conf 12$ vi /etc/sysctl.confvm.max_map_count=262144 生效 1$ sysctl -p 验证1$ sysctl -a|grep vm.max_map_count 进入容器命令行 1234# centosdocker exec -it &lt;container-name&gt; /bin/bash# alpinedocker exec -it &lt;container-name&gt; sh Elasticsearch 索引定时清理 elasticsearch-curator 安装 123456789101112131415# 安装 curator 源$ rpm --import https://packages.elastic.co/GPG-KEY-elasticsearch# 编辑 curator yum 源配置$ vim /etc/yum.repos.d/curator.repo[curator-5]name=CentOS/RHEL 7 repository for Elasticsearch Curator 5.x packagesbaseurl=https://packages.elastic.co/curator/5/centos/7gpgcheck=1gpgkey=https://packages.elastic.co/GPG-KEY-elasticsearchenabled=1# 安装 curator$ yum install elasticsearch-curator -y 配置 config.yml 12345678910111213141516171819202122$ mkdir -p /data/ELKStack/curator$ vim /data/ELKStack/curator/config.ymllient: hosts: - 172.16.1.3 port: 9200 url_prefix: use_ssl: False certificate: client_cert: client_key: ssl_no_validate: False http_auth: timeout: 150 master_only: Falselogging: loglevel: INFO logfile: logformat: default blacklist: [&apos;elasticsearch&apos;, &apos;urllib3&apos;] 配置 action.yml 清理规则 /data/ELKStack/curator/action.yml 12345678910111213141516171819actions: 1: action: delete_indices description: &gt;- Delete indices older than 60 days. Ignore the error if the filter does not result in an actionable list of indices (ignore_empty_list) and exit cleanly. options: ignore_empty_list: True disable_action: False filters: - filtertype: pattern kind: regex # 保留 kibana|json|monitoring|metadata 不被清理 value: '^((?!(kibana|json|monitoring|metadata)).)*$' - filtertype: age source: creation_date direction: older #timestring: '%Yi-%m-%d' unit: days unit_count: 60 设置计划任务 1$ crontab -e 0 0 * * * /usr/bin/curator --config /data/ELKStack/curator/config.yml /data/ELKStack/curator/action.yml 1&gt;&gt; /tmp/curator.log 2&gt;&amp;1]]></content>
      <categories>
        <category>elk</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>docker-compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-compose 安装和使用]]></title>
    <url>%2Fposts%2F9bc29391.html</url>
    <content type="text"><![CDATA[安装 1234$ sudo curl -L https://github.com/docker/compose/releases/download/1.22.0/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose$ sudo curl --proxy 192.168.123.1:1234 -L "https://github.com/docker/compose/releases/download/1.26.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose 可执行权限 1$ sudo chmod +x /usr/local/bin/docker-compose 验证安装 12$ docker-compose --versiondocker-compose version 1.22.0, build 1719ceb 使用 1$ docker-compose -f grafana/docker-compose.yml up]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker-compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装 docker 环境 for CentOS]]></title>
    <url>%2Fposts%2F2fff8f5e.html</url>
    <content type="text"><![CDATA[安装 Docker 删除旧版本 123456789101112131415sudo yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-selinux \ docker-engine-selinux \ docker-engine# 或者sudo yum remove flannel docker* -ysudo yum -y remove docker docker-common docker-selinux docker-engine docker-engine-selinux container-selinux docker-cesudo rm -rf /var/lib/docker 配置 repo 1234567891011121314151617sudo yum install -y yum-utils \ device-mapper-persistent-data \ lvm2 sudo yum-config-manager \ --add-repo \ https://download.docker.com/linux/centos/docker-ce.repo# 或者使用阿里云sudo yum-config-manager \ --add-repo \ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# Optionalsudo yum-config-manager --enable docker-ce-edgesudo yum-config-manager --enable docker-ce-testsudo yum-config-manager --disable docker-ce-edge 斯蒂芬森 12345678910111213141516171819202122# 配置yum源阿里云镜像## 备份原来的yum源cd /etc/yum.repos.d/sudo mv CentOS-Base.repo CentOS-Base.repo_bak## 获取阿里云yum源sudo wget -e "http_proxy=192.168.123.1:1234" -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo## 清除原有yum源缓存sudo yum clean all## 生成阿里云yum源缓存sudo yum makecache## 或者sudo rm -f /var/lib/rpm/__*sudo rpm --rebuilddb -v -vsudo yum clean dbcachesudo yum clean metadatasudo yum clean rpmdbsudo yum clean headerssudo yum clean allsudo rm -rf /var/cache/yum/timedhosts.txtsudo rm -rf /var/cache/yum/*sudo yum makecache 安装 docker 在线安装 1234567891011# 安装最新版本sudo yum install docker-ce#安装指定版本 docker# 可以查看所有仓库中所有docker版本，并选择特定版本安装yum list docker-ce --showduplicates | sort -rdocker-ce.x86_64 18.03.0.ce-1.el7.centos docker-ce-stablesudo yum install docker-ce-&lt;VERSION STRING&gt;# 或者sudo curl https://releases.rancher.com/install-docker/19.03.sh | shsudo curl --proxy 192.168.123.1:1234 https://releases.rancher.com/install-docker/19.03.sh | sh 离线安装 123sudo yum install -y docker-ce-cli-19.03.12-3.el7.x86_64.rpmsudo yum install -y containerd.io-1.3.7-3.1.el7.x86_64.rpmsudo yum install -y docker-ce-19.03.12-3.el7.x86_64.rpm 启动并加入开机启动 12345678# 启动 dockersudo systemctl start docker# 停止运行 dockersudo systemctl stop docker# 开机启动sudo systemctl enable docker# 禁止开机启动sudo systemctl disable docker 版本锁定 防止升级、变更版本 123sudo yum install yum-plugin-versionlocksudo yum versionlock add docker-ce docker-ce-clisudo yum versionlock list 将当前用户加入docker组，并重启docker 12sudo gpasswd -a $&#123;USER&#125; dockersudo systemctl restart docker 验证安装 12345678910111213141516171819$ docker versionClient: Version: 18.06.1-ce API version: 1.38 Go version: go1.10.3 Git commit: e68fc7a Built: Tue Aug 21 17:23:03 2018 OS/Arch: linux/amd64 Experimental: falseServer: Engine: Version: 18.06.1-ce API version: 1.38 (minimum version 1.12) Go version: go1.10.3 Git commit: e68fc7a Built: Tue Aug 21 17:25:29 2018 OS/Arch: linux/amd64 Experimental: false Docker 配置 代理1234567891011# 配置 docker pull 代理# sudo rm -rf /etc/systemd/system/docker.service.d# cat /etc/systemd/system/docker.service.d/http-proxy.confsudo mkdir -p /etc/systemd/system/docker.service.dsudo tee /etc/systemd/system/docker.service.d/http-proxy.conf &lt;&lt;-'EOF'[Service]Environment="HTTP_PROXY=http://192.168.123.1:1234" "NO_PROXY=localhost,127.0.0.1,172.16.120.0/24"EOFsudo systemctl daemon-reloadsudo systemctl enable dockersudo systemctl restart docker 其中172.16.120.0/24为宿主机 ip Docker 配置 加速源1234567891011# sudo rm -rf /etc/docker/daemon.jsonsudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'&#123;"registry-mirrors": ["https://docker.mirrors.ustc.edu.cn"],"log-driver":"json-file","log-opts":&#123; "max-size" :"50m","max-file":"10"&#125;&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 进入容器 12345# centosdocker exec -it &lt;container-name&gt; /bin/bash# alpinedocker exec -it &lt;container-name&gt; sh]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker-compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker 命令]]></title>
    <url>%2Fposts%2F71631b3f.html</url>
    <content type="text"><![CDATA[docker container ls 列出所有容器 用法 1docker container ls [options] 选项 | 参数 | 默认值 | 描述 || ————– | —— | ——————————– || -all, -a | false | 显示所有容器(默认只显示运行的) || --filter, -f | | 根据提供的条件过滤输出 || --format | | 使用Go模板打印容器 || -last, -n | -1 | 显示最后创建的容器(包括所有状态) || --latest, -l | false | 显示最新创建的容器(包括所有状态) || -no-trunc | false | 不要截断输出 || --quiet, -q | false | 只显示数字ID || -size, -s | false | 显示文件大小 | docker container rm 删除一个或多个容器 用法 1docker container rm [options] CONTAINER [CONTAINER...] 选项 | 参数 | 默认值 | 描述 || ————— | —— | ———————————– || --force, -f | false | 强制移走正在运行的容器(使用SIGKILL) || --link, -l | false | 删除指定的链接 || --volumes, -v | false | 删除与容器关联的卷 | 相关命令 命令 描述 docker container attach 附加到正在运行的容器 docker container commit 从容器的更改创建一个新的映像 docker container cp 在容器和本地文件系统之间复制文件/文件夹 docker container create 创建一个新的容器 docker container diff 检查容器文件系统上文件或目录的更改 docker container exec 在运行容器中运行命令 docker container export 将容器的文件系统导出为tar存档 docker container inspect 显示一个或多个容器的详细信息 docker container kill 杀死一个或多个运行容器 docker container logs 获取容器的日志 docker container ls 列出容器 docker container pause 暂停一个或多个容器内的所有进程 docker container port 列出端口映射或容器的特定映射 docker container prune 取出所有停止的容器 docker container rename 重命名容器 docker container restart 重新启动一个或多个容器 docker container rm 删除(移除)一个或多个容器 docker container run 在新容器中运行命令 docker container start 启动一个或多个停止的容器 docker container stats 显示容器的实时流资源使用统计信息 docker container stop 停止一个或多个运行容器 docker container top 显示容器的正在运行的进程 docker container unpause 取消暂停一个或多个容器内的所有流程 docker container update 更新一个或多个容器的配置 docker container wait 阻止一个或多个容器停止，然后打印退出代码]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>container</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Indices APIs]]></title>
    <url>%2Fposts%2Fef78ba07.html</url>
    <content type="text"><![CDATA[Defines a Template123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172PUT _template/api-monitor&#123; "order" : 0, "index_patterns": [ "api-monitor-*" ], "settings": &#123; "index": &#123; "number_of_shards": 2, "number_of_replicas": 1, "refresh_interval": "5s" &#125; &#125;, "mappings": &#123; "_default_": &#123; "dynamic_templates": [ &#123; "message_field": &#123; "path_match": "message", "match_mapping_type": "string", "mapping": &#123; "type": "text", "norms": false &#125; &#125; &#125;, &#123; "string_fields": &#123; "match": "*", "match_mapping_type": "string", "mapping": &#123; "type": "text", "norms": false, "fields": &#123; "keyword": &#123; "type": "keyword", "ignore_above": 256 &#125; &#125; &#125; &#125; &#125; ], "properties": &#123; "@timestamp": &#123; "type": "date" &#125;, "@version": &#123; "type": "keyword" &#125;, "geoip": &#123; "dynamic": true, "properties": &#123; "ip": &#123; "type": "ip" &#125;, "location": &#123; "type": "geo_point" &#125;, "latitude": &#123; "type": "half_float" &#125;, "longitude": &#123; "type": "half_float" &#125; &#125; &#125; &#125; &#125; &#125;, "aliases": &#123;&#125;&#125; order 默认 0 Deleting a Template1DELETE _template/logstash Getting templates1234GET _template/logstash# You can also match several templates by using wildcards like:GET _template/logstash, logstash_1 Template exists1HEAD _template/logstash Multiple Templates Matching]]></content>
      <categories>
        <category>elk</category>
      </categories>
      <tags>
        <tag>index</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[filebeat-6.4.0 使用]]></title>
    <url>%2Fposts%2F9cf2c75c.html</url>
    <content type="text"><![CDATA[filebeat 版本 6.6.x 配置输入12345678filebeat.inputs:# 输入类型：[log, stdin, redis, udp, docker, tcp, syslog, netflow]- type: log # Change to true to enable this input configuration. enabled: true # Paths that should be crawled and fetched. Glob based paths. paths: - /var/logs/*.log 动态加载外部配置文件 动态配置 1234567891011121314#============================= Filebeat modules ===============================filebeat.config: modules: path: $&#123;path.config&#125;/modules.d/*.yml reload.enabled: false #reload.period: 10s # 动态加载外部输入配置文件 inputs: enabled: true path: $&#123;path.config&#125;/inputs.d/*.yml reload.enabled: true reload.period: 10s 启动12$ cd /opt/filebeat/$ nohup ./filebeat -e -c filebeat.yml &amp;]]></content>
      <categories>
        <category>elk</category>
      </categories>
      <tags>
        <tag>filebeat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring redirect 导致内存溢出问题核查]]></title>
    <url>%2Fposts%2Fb575301a.html</url>
    <content type="text"><![CDATA[3.x 版本这个类AbstractCachingViewResolver里面的viewCache HashMap没有限制大小 3.x：如果在 controller 返回的 view 是不固定的，如：”redirect:form.html?entityId=” + entityId，由于 entityId 的值会存在 N 个，那么会导致产生 N 个 ViewName 被缓存起来 4.x 版本及以上已经修复这个问题，代码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243public abstract class AbstractCachingViewResolver extends WebApplicationObjectSupport implements ViewResolver &#123; /** Default maximum number of entries for the view cache: 1024 */ public static final int DEFAULT_CACHE_LIMIT = 1024; /** Dummy marker object for unresolved views in the cache Maps */ private static final View UNRESOLVED_VIEW = new View() &#123; @Override public String getContentType() &#123; return null; &#125; @Override public void render(Map&lt;String, ?&gt; model, HttpServletRequest request, HttpServletResponse response) &#123; &#125; &#125;; /** The maximum number of entries in the cache */ private volatile int cacheLimit = DEFAULT_CACHE_LIMIT; /** Whether we should refrain from resolving views again if unresolved once */ private boolean cacheUnresolved = true; /** Fast access cache for Views, returning already cached instances without a global lock */ private final Map&lt;Object, View&gt; viewAccessCache = new ConcurrentHashMap&lt;Object, View&gt;(DEFAULT_CACHE_LIMIT); /** Map from view key to View instance, synchronized for View creation */ @SuppressWarnings("serial") private final Map&lt;Object, View&gt; viewCreationCache = new LinkedHashMap&lt;Object, View&gt;(DEFAULT_CACHE_LIMIT, 0.75f, true) &#123; @Override protected boolean removeEldestEntry(Map.Entry&lt;Object, View&gt; eldest) &#123; if (size() &gt; getCacheLimit()) &#123; // 超过限制大小，删除老数据 viewAccessCache.remove(eldest.getKey()); return true; &#125; else &#123; return false; &#125; &#125; &#125;; ...... 4.x 版本4.x 版本是这个AbstractAutoProxyCreator这个类里面的advisedBeans ConcurrentHashMap没有限制大小 问题描述：https://github.com/spring-projects/spring-boot/issues/13771 The problem is that InternalResourceViewResolver calls AutowireCapableBeanFactory.initializeBean(Object existingBean, String beanName) using the complete URL as the beanName. The bean name is then used by AbstractAutoProxyCreator.wrapIfNecessary(Object, String, Object) as the key when it caches the fact that no advice applies to it. 截止发稿：最新的 spring 5.0.8.RELEASE 还存在这个问题]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>redirect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 线程池]]></title>
    <url>%2Fposts%2Fbc557e1a.html</url>
    <content type="text"><![CDATA[线程池作用 CPU资源隔离 减少上下文切换 减少线程创建/关闭的资源开销 更好并发控制 更好生命周期控制 设计时注意事项 任务混杂 任务依赖 饥饿死锁 慢操作 使用时注意事项线程池参数 核心池大小（core pool size） 最大池的大小（maximum pool size） 存活时间（keep-alive time） 缓冲队列（work queue） 任务队列（BlockingQueue） 无限队列 LinkedBlockingQueue newSingleThreadExecutor newFixedThreadPool 有限队列 ArrayBlockingQueue LinkedBlockingQueue(int capacity) 饱和策略 setRejectedExecutionHandler ThreadPoolExecutor.AbortPolicy 中止策略（默认） 抛出RejectedExecutionException 调用者捕获后，自行实现逻辑 ThreadPoolExecutor.CallerRunsPolicy 不丢弃任务 不抛出异常 把任务退回调用者线程执行（同步调用） ThreadPoolExecutor.DiscardOldestPolicy 遗弃最旧的任务 选择本应该接下来就要执行的任务 会尝试再次提交 如果使用优先级队列，则丢弃优先级最高的元素 配合 SynchronousQueue 使用，可以实现任务提交并等待的效果 ThreadPoolExecutor.DiscardPolicy 遗弃策略 放弃这个任务 可以结合Semaphore使用 限制任务注入率（injection rate） FIFO 同步移交（synchronous handoff） 直接传递给其他线程 SynchronousQueue newCachedThreadPool 线程工厂 设置异常处理 UncaughtExceptionHandler 设置线程名称 优先级（不建议） 守护线程（不建议） 增加额外的计数器 增加额外的统计信息 Executors.privilegedThreadFactory()，使用安全策略创建线程 执行策略 执行任务，不关心结果 void execute(Runnable command) 执行任务，需要对结果进行处理 Future submit(Callable task) Future submit(Runnable task) Future submit(Runnable task, T result) 执行一批任务，需要全部成功完成 List invokeAll(Collection&lt;? extends Callable&gt; tasks) List invokeAll(Collection&lt;? extends Callable&gt; tasks, long timeout, TimeUnit unit) 执行一批任务，只需要有一个成功完成即可 T List invokeAny(Collection&lt;? extends Callable&gt; tasks) T invokeAny(Collection&lt;? extends Callable&gt; tasks, long timeout, TimeUnit unit) 执行一批任务，需要逐个处理结果 CompletionService ExecutorCompletionService]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>ExecutorService</tag>
        <tag>Executors</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[camel-ftp 使用笔记]]></title>
    <url>%2Fposts%2F6ae6b8a1.html</url>
    <content type="text"><![CDATA[解决中文目录乱码问题1ftpClient.controlEncoding=gb2312 idempotentConsumer file 123456789101112// tmp 是一个路径：./../tmp// 通过文件名缓存，如果缓存中已经有这个文件名，怎不再处理这个文件ValueBuilder messageIdExpression = header(Exchange.FILE_PATH) .append("#").append(header(Exchange.FILE_LAST_MODIFIED)) .append("#").append(header(Exchange.FILE_LENGTH));FileIdempotentRepository idempotentRepository = FileIdempotentRepository.fileIdempotentRepository(new File(tmp, this.getClass().getSimpleName() + ".txt"), 100 * 1024, 5 * 1024 * 1024);from(url.toString()) .idempotentConsumer(messageIdExpression, idempotentRepository) .process(arrearsProcessor) .log(LoggingLevel.INFO, log, "finished processor the file $&#123;file:path&#125;."); jpa 12345678910111213@Resourceprivate EntityManagerFactory entityManagerFactory;ValueBuilder messageIdExpression = header(Exchange.FILE_PATH) .append("#").append(header(Exchange.FILE_LAST_MODIFIED)) .append("#").append(header(Exchange.FILE_LENGTH));JpaMessageIdRepository idempotentRepository = JpaMessageIdRepository.jpaMessageIdRepository(entityManagerFactory, this.getClass().getName());from(url.toString()) .idempotentConsumer(messageIdExpression, idempotentRepository) .process(arrearsProcessor) .log(LoggingLevel.INFO, log, "finished processor the file $&#123;file:name&#125;."); filter12345// 标识文件名是“20180803.txt”时，才执行之后的流程.filter(header(Exchange.FILE_NAME).isEqualTo("20180803.txt")) // 标识文件名不是“20180803.txt”时，才执行之后的流程.filter(header(Exchange.FILE_NAME).isNotEqualTo("20180803.txt")) filterFile12// 只读取包含当天日期的文件：文件前缀_20_20180305.txtftp://localhost:22/test?username=xxx&amp;password=xx&amp;filterFile=$&#123;file:name&#125; contains $&#123;date:now:yyyyMMdd&#125; readLockreadLock=rename可以阻止camel读取正在被写入的文件 move 移动文件到同级 done 目录下 12# 移动到同级 done 目录下ftp://localhost:22/test?username=xxx&amp;password=xx&amp;move=done&amp;readLock=rename 移动并重命名文件 1ftp://localhost:22/test?username=xxx&amp;password=xx&amp;move=done/&#123;file:name.noext&#125;_$&#123;file:modified&#125;.$&#123;file:ext&#125;&amp;readLock=rename 参考：org.apache.camel.language.simple.SimpleLanguage.java]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Apache</tag>
        <tag>camel-ftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 使用场景]]></title>
    <url>%2Fposts%2Fc77ba0b2.html</url>
    <content type="text"><![CDATA[场景一：取最新N条数据网站最新文章、最新评论等。使用 Redis 列表(List)集合，LPUSH 命令向 list 集合头部插入数据，LTRIM 命令对 list 集合进行修剪(trim) 123456789# 将一个或多个值插入到列表头部# LPUSH key value1 [value2] 127.0.0.1:6379&gt; LPUSH latest.comments "foo"(integer) 1# 对一个列表进行修剪(trim)，就是说，让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除# LTRIM key start stop 127.0.0.1:6379&gt; LTRIM latest.comments 0 10OK 场景二：排行榜应用，取 TOP N操作场景二和场景一不同之处在于，场景一操作以时间为权重，场景二是以某一个条件为权重。比如：赞次数、评论次数等。这个时候就需要使用 Redis 有序集合(sorted set)。将需要排序的值设置为有序集合的 score，将具体的数据设置为相应的 value，每次只需要执行 ZDAA 命令即可。 123# 向有序集合添加一个或多个成员，或者更新已存在成员的分数# ZADD key score1 value1 [score2 value12] 127.0.0.1:6379&gt; ZADD myzset 1 "one" 场景三：计数器Redis 命令是原子性的，可以利用 INCR、DECR 命令来构建计数器系统，其底层写入是单线程模型，并发写入会按先后顺序执行。 12345678910111213141516# 将 key 中储存的数字值增一# INCR key127.0.0.1:6379&gt; INCR KEY_NAME# 延伸# 将 key 所储存的值加上给定的增量值（increment）# INCRBY key increment# 将 key 所储存的值加上给定的浮点增量值（increment）# INCRBYFLOAT key increment# 将 key 中储存的数字值减一# DECR key127.0.0.1:6379&gt; DECR KEY_NAME # 延伸# key 所储存的值减去给定的减量值（decrement）# DECRBY key decrement 场景四：缓存Redis 作为分布式缓存中间件，其性能优于 Memcached，且数据结构更加多样化。 场景五：队列使用 Redis 列表(List) 可以构建队列系统，使用 Redis 有序集合(sorted set)甚至可以构建有优先级的队列系统。 场景六：Pub、Sub实时消息系统使用 Redis 的 Pub/Sub 可以构建实时的消息系统。 场景七：Unique 操作获取所有数据去重。使用 Redis 集合(Set)数据结构最合适不过了，只需要不断将数据往 set 中丢就行了，set 会自动去重。 场景八：精确设置过期时间比如场景二中，score 可以设置成过期时间的时间戳，这样就可以简单的通过过期时间排序，定时清除过期数据。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[restful api 规范]]></title>
    <url>%2Fposts%2Ffea0c721.html</url>
    <content type="text"><![CDATA[RESTful API 设计规范 原文地址：https://github.com/godruoyi/restful-api-specification 关于「能愿动词」的使用为了避免歧义，文档大量使用了「能愿动词」，对应的解释如下： 必须 (MUST)：绝对，严格遵循，请照做，无条件遵守； 一定不可 (MUST NOT)：禁令，严令禁止； 应该 (SHOULD) ：强烈建议这样做，但是不强求； 不该 (SHOULD NOT)：强烈不建议这样做，但是不强求； 可以 (MAY) 和 可选 (OPTIONAL) ：选择性高一点，在这个文档内，此词语使用较少； 参见：RFC 2119 Protocol客户端在通过 API 与后端服务通信的过程中，应该 使用 HTTPS 协议。 API Root URLAPI 的根入口点应尽可能保持足够简单，这里有两个常见的 URL 根例子： api.example.com/* example.com/api/* 如果你的应用很庞大或者你预计它将会变的很庞大，那 应该 将 API 放到子域下（api.example.com）。这种做法可以保持某些规模化上的灵活性。 Versioning所有的 API 必须保持向后兼容，你 必须 在引入新版本 API 的同时确保旧版本 API 仍然可用。所以 应该 为其提供版本支持。 目前比较常见的两种版本号形式： 在 URL 中嵌入版本编号1api.example.com/v1/* 这种做法是版本号直观、易于调试；另一种做法是，将版本号放在 HTTP Header 头中： Endpoints端点就是指向特定资源或资源集合的 URL。在端点的设计中，你 必须 遵守下列约定： URL 的命名 必须 全部小写 URL 中资源（resource）的命名 必须 是名词，并且 必须 是复数形式 必须 优先使用 Restful 类型的 URL URL 必须 是易读的 URL 一定不可 暴露服务器架构 至于 URL 是否必须使用连字符（-） 或下划线（_），不做硬性规定，但 必须 根据团队情况统一一种风格。 来看一个反例 https://api.example.com/getUserInfo?userid=1 https://api.example.com/getusers https://api.example.com/sv/u https://api.example.com/cgi-bin/users/get_user.php?userid=1 再来看一个正列 https://api.example.com/zoos https://api.example.com/animals https://api.example.com/zoos/{zoo}/animals https://api.example.com/animal_types https://api.example.com/employees HTTP 动词对于资源的具体操作类型，由 HTTP 动词表示。常用的 HTTP 动词有下面五个（括号里是对应的 SQL 命令）。 GET（SELECT）：从服务器取出资源（一项或多项）。 POST（CREATE）：在服务器新建一个资源。 PUT（UPDATE）：在服务器更新资源（客户端提供改变后的完整资源）。 PATCH（UPDATE）：在服务器更新资源（客户端提供改变的属性）。 DELETE（DELETE）：从服务器删除资源。 其中 1 删除资源 必须 用 DELETE 方法2 创建新的资源 必须 使用 POST 方法3 更新资源 应该 使用 PUT 方法4 获取资源信息 必须 使用 GET 方法 针对每一个端点来说，下面列出所有可行的 HTTP 动词和端点的组合 请求方法 URL 描述 GET /zoos 列出所有的动物园(ID和名称，不要太详细) POST /zoos 新增一个新的动物园 GET /zoos/{zoo} 获取指定动物园详情 PUT /zoos/{zoo} 更新指定动物园(整个对象) PATCH /zoos/{zoo} 更新动物园(部分对象) DELETE /zoos/{zoo} 删除指定动物园 GET /zoos/{zoo}/animals 检索指定动物园下的动物列表(ID和名称，不要太详细) GET /animals 列出所有动物(ID和名称)。 POST /animals 新增新的动物 GET /animals/{animal} 获取指定的动物详情 PUT /animals/{animal} 更新指定的动物(整个对象) PATCH /animals/{animal} 更新指定的动物(部分对象) GET /animal_types 获取所有动物类型(ID和名称，不要太详细) GET /animal_types/{type} 获取指定的动物类型详情 GET /employees 检索整个雇员列表 GET /employees/{employee} 检索指定特定的员工 GET /zoos/{zoo}/employees 检索在这个动物园工作的雇员的名单(身份证和姓名) POST /employees 新增指定新员工 POST /zoos/{zoo}/employees 在特定的动物园雇佣一名员工 DELETE /zoos/{zoo}/employees/{employee} 从某个动物园解雇一名员工 超出 Restful 端点的，应该 模仿上表的方式来定义端点。 Filtering 如果记录数量很多，服务器不可能都将它们返回给用户。API 应该 提供参数，过滤返回结果。下面是一些常见的参数。 ?limit=10：指定返回记录的数量 ?offset=10：指定返回记录的开始位置。 ?page=2&amp;per_page=100：指定第几页，以及每页的记录数。 ?sortby=name&amp;order=asc：指定返回结果按照哪个属性排序，以及排序顺序。 ?animal_type_id=1：指定筛选条件 所有 URL 参数 必须 是全小写，必须 使用下划线类型的参数形式。 分页参数 必须 固定为 page、per_page 经常使用的、复杂的查询 应该 标签化，降低维护成本。如 1234GET /trades?status=closed&amp;sort=sortby=name&amp;order=asc# 可为其定制快捷方式GET /trades/recently_closed Authentication应该 使用 OAuth2.0 的方式为 API 调用者提供登录认证。必须 先通过登录接口获取 Access Token 后再通过该 token 调用需要身份认证的 API。 Oauth 的端点设计示列 RFC 6749 /token Twitter /oauth2/token Fackbook /oauth/access_token Google /o/oauth2/token Github /login/oauth/access_token Instagram /oauth/authorize 客户端在获得 access token 的同时 必须 在响应中包含一个名为 expires_in 的数据，它表示当前获得的 token 会在多少 秒 后失效。 12345&#123; "access_token": "token....", "token_type": "Bearer", "expires_in": 3600&#125; 客户端在请求需要认证的 API 时，必须 在请求头 Authorization 中带上 access_token。 1Authorization: Bearer token... 当超过指定的秒数后，access token 就会过期，再次用过期/或无效的 token 访问时，服务端 应该 返回 invalid_token 的错误或 401 错误码。 12345678HTTP/1.1 401 UnauthorizedContent-Type: application/jsonCache-Control: no-storePragma: no-cache&#123; "error": "invalid_token"&#125; Laravel 开发中，应该 使用 JWT 来为管理你的 Token，并且 一定不可 在 api 中间件中开启请求 session。 Response所有的 API 响应，必须 遵守 HTTP 设计规范，必须 选择合适的 HTTP 状态码。一定不可 所有接口都返回状态码为 200 的 HTTP 响应，如： 1234567891011HTTP/1.1 200 okContent-Type: application/jsonServer: example.com&#123; "code": 0, "msg": "success", "data": &#123; "username": "username" &#125;&#125; 或 12345678HTTP/1.1 200 okContent-Type: application/jsonServer: example.com&#123; "code": -1, "msg": "该活动不存在",&#125; 下表列举了常见的 HTTP 状态码 状态码 描述 1xx 代表请求已被接受，需要继续处理 2xx 请求已成功，请求所希望的响应头或数据体将随此响应返回 3xx 重定向 4xx 客户端原因引起的错误 5xx 服务端原因引起的错误 只有来自客户端的请求被正确的处理后才能返回 2xx 的响应，所以当 API 返回 2xx 类型的状态码时，前端 必须 认定该请求已处理成功。 必须强调的是，所有 API 一定不可 返回 1xx 类型的状态码。当 API 发生错误时，必须 返回出错时的详细信息。目前常见返回错误信息的方法有两种： 1、将错误详细放入 HTTP 响应首部； 123X-MYNAME-ERROR-CODE: 4001X-MYNAME-ERROR-MESSAGE: Bad authentication tokenX-MYNAME-ERROR-INFO: http://docs.example.com/api/v1/authentication 2、直接放入响应实体中； 123456789HTTP/1.1 401 UnauthorizedServer: nginx/1.11.9Content-Type: application/jsonTransfer-Encoding: chunkedCache-Control: no-cache, privateDate: Sun, 24 Jun 2018 10:02:59 GMTConnection: keep-alive&#123;"error_code":40100,"message":"Unauthorized"&#125; 考虑到易读性和客户端的易处理性，我们 必须 把错误信息直接放到响应实体中，并且错误格式 应该 满足如下格式： 1234&#123; "message": "您查找的资源不存在", "error_code": 404001&#125; 其中错误码（error_code）必须 和 HTTP 状态码对应，也方便错误码归类，如： 123456789HTTP/1.1 429 Too Many RequestsServer: nginx/1.11.9Content-Type: application/jsonTransfer-Encoding: chunkedCache-Control: no-cache, privateDate: Sun, 24 Jun 2018 10:15:52 GMTConnection: keep-alive&#123;"error_code":429001,"message":"你操作太频繁了"&#125; 123456789HTTP/1.1 403 ForbiddenServer: nginx/1.11.9Content-Type: application/jsonTransfer-Encoding: chunkedCache-Control: no-cache, privateDate: Sun, 24 Jun 2018 10:19:27 GMTConnection: keep-alive&#123;"error_code":403002,"message":"用户已禁用"&#125; 应该 在返回的错误信息中，同时包含面向开发者和面向用户的提示信息，前者可方便开发人员调试，后者可直接展示给终端用户查看如： 12345678&#123; "message": "直接展示给终端用户的错误信息", "error_code": "业务错误码", "error": "供开发者查看的错误信息", "debug": [ "错误堆栈，必须开启 debug 才存在" ]&#125; 下面详细列举了各种情况 API 的返回说明。 200 ok200 状态码是最常见的 HTTP 状态码，在所有 成功 的 GET 请求中，必须 返回此状态码。HTTP 响应实体部分 必须 直接就是数据，不要做多余的包装。 错误示例： 1234567891011HTTP/1.1 200 okContent-Type: application/jsonServer: example.com&#123; "user": &#123; "id":1, "nickname":"fwest", "username": "example" &#125;&#125; 正确示例： 1、获取单个资源详情 12345&#123; "id": 1, "username": "godruoyi", "age": 88,&#125; 2、获取资源集合 123456789101112[ &#123; "id": 1, "username": "godruoyi", "age": 88, &#125;, &#123; "id": 2, "username": "foo", "age": 88, &#125;] 3、额外的媒体信息 123456789101112131415161718192021222324252627282930&#123; "data": [ &#123; "id": 1, "avatar": "https://lorempixel.com/640/480/?32556", "nickname": "fwest", "last_logined_time": "2018-05-29 04:56:43", "has_registed": true &#125;, &#123; "id": 2, "avatar": "https://lorempixel.com/640/480/?86144", "nickname": "zschowalter", "last_logined_time": "2018-06-16 15:18:34", "has_registed": true &#125; ], "meta": &#123; "pagination": &#123; "total": 101, "count": 2, "per_page": 2, "current_page": 1, "total_pages": 51, "links": &#123; "next": "http://api.example.com?page=2" &#125; &#125; &#125;&#125; 其中，分页和其他额外的媒体信息，必须放到 meta 字段中。 201 Created当服务器创建数据成功时，应该 返回此状态码。常见的应用场景是使用 POST 提交用户信息，如： 添加了新用户 上传了图片 创建了新活动 等，都可以返回 201 状态码。需要注意的是，你可以选择在用户创建成功后返回新用户的数据 123456789101112131415HTTP/1.1 201 CreatedServer: nginx/1.11.9Content-Type: application/jsonTransfer-Encoding: chunkedDate: Sun, 24 Jun 2018 09:13:40 GMTConnection: keep-alive&#123; "id": 1, "avatar": "https:\/\/lorempixel.com\/640\/480\/?32556", "nickname": "fwest", "last_logined_time": "2018-05-29 04:56:43", "created_at": "2018-06-16 17:55:55", "updated_at": "2018-06-16 17:55:55"&#125; 也可以返回一个响应实体为空的 HTTP Response 如： 123456HTTP/1.1 201 CreatedServer: nginx/1.11.9Content-Type: text/html; charset=UTF-8Transfer-Encoding: chunkedDate: Sun, 24 Jun 2018 09:12:20 GMTConnection: keep-alive 这里我们 应该 采用第二种方式，因为大多数情况下，客户端只需要知道该请求操作成功与否，并不需要返回新资源的信息。 202 Accepted该状态码表示服务器已经接受到了来自客户端的请求，但还未开始处理。常用短信发送、邮件通知、模板消息推送等这类很耗时需要队列支持的场景中； 返回该状态码时，响应实体 必须 为空。 123456HTTP/1.1 202 AcceptedServer: nginx/1.11.9Content-Type: text/html; charset=UTF-8Transfer-Encoding: chunkedDate: Sun, 24 Jun 2018 09:25:15 GMTConnection: keep-alive 204 No Content该状态码表示响应实体不包含任何数据，其中： 在使用 DELETE 方法删除资源 成功 时，必须 返回该状态码 使用 PUT、PATCH 方法更新数据 成功 时，也 应该 返回此状态码 1234HTTP/1.1 204 No ContentServer: nginx/1.11.9Date: Sun, 24 Jun 2018 09:29:12 GMTConnection: keep-alive 3xx 重定向所有 API 不该 返回 3xx 类型的状态码。因为 3xx 类型的响应格式一般为下列格式： 123456789101112131415161718192021HTTP/1.1 302 FoundServer: nginx/1.11.9Content-Type: text/html; charset=UTF-8Transfer-Encoding: chunkedCache-Control: no-cache, privateDate: Sun, 24 Jun 2018 09:41:50 GMTLocation: https://example.comConnection: keep-alive&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="UTF-8" /&gt; &lt;meta http-equiv="refresh" content="0;url=https://example.com" /&gt; &lt;title&gt;Redirecting to https://example.com&lt;/title&gt; &lt;/head&gt; &lt;body&gt; Redirecting to &lt;a href="https://example.com"&gt;https://example.com&lt;/a&gt;. &lt;/body&gt;&lt;/html&gt; 所有 API 一定不可 返回纯 HTML 结构的响应；若一定要使用重定向功能，可以 返回一个响应实体为空的 3xx 响应，并在响应头中加上 Location 字段: 1234567HTTP/1.1 302 FoundServer: nginx/1.11.9Content-Type: text/html; charset=UTF-8Transfer-Encoding: chunkedDate: Sun, 24 Jun 2018 09:52:50 GMTLocation: https://godruoyi.comConnection: keep-alive 400 Bad Request由于明显的客户端错误（例如，请求语法格式错误、无效的请求、无效的签名等），服务器 应该 放弃该请求。 当服务器无法从其他 4xx 类型的状态码中找出合适的来表示错误类型时，都 必须 返回该状态码。 123456789HTTP/1.1 400 Bad RequestServer: nginx/1.11.9Content-Type: application/jsonTransfer-Encoding: chunkedCache-Control: no-cache, privateDate: Sun, 24 Jun 2018 13:22:36 GMTConnection: keep-alive&#123;"error_code":40000,"message":"无效的签名"&#125; 401 Unauthorized该状态码表示当前请求需要身份认证，以下情况都 必须 返回该状态码。 未认证用户访问需要认证的 API access_token 无效/过期 客户端在收到 401 响应后，都 应该 提示用户进行下一步的登录操作。 12345678910HTTP/1.1 401 UnauthorizedServer: nginx/1.11.9Content-Type: application/jsonTransfer-Encoding: chunkedWWW-Authenticate: JWTAuthCache-Control: no-cache, privateDate: Sun, 24 Jun 2018 13:17:02 GMTConnection: keep-alive"message":"Token Signature could not be verified.","error_code": "40100"&#125; 403 Forbidden该状态码可以简单的理解为没有权限访问该请求，服务器收到请求但拒绝提供服务。 如当普通用户请求操作管理员用户时，必须 返回该状态码。 123456789HTTP/1.1 403 ForbiddenServer: nginx/1.11.9Content-Type: application/jsonTransfer-Encoding: chunkedCache-Control: no-cache, privateDate: Sun, 24 Jun 2018 13:05:34 GMTConnection: keep-alive&#123;"error_code":40301,"message":"权限不足"&#125; 404 Not Found该状态码表示用户请求的资源不存在，如 获取不存在的用户信息 （get /users/9999999） 访问不存在的端点 都 必须 返回该状态码，若该资源已永久不存在，则 应该 返回 401 响应。 405 Method Not Allowed当客户端使用的 HTTP 请求方法不被服务器允许时，必须 返回该状态码。 如客户端调用了 POST 方法来访问只支持 GET 方法的 API 该响应 必须 返回一个 Allow 头信息用以表示出当前资源能够接受的请求方法的列表。 12345678910HTTP/1.1 405 Method Not AllowedServer: nginx/1.11.9Content-Type: application/jsonTransfer-Encoding: chunkedAllow: GET, HEADCache-Control: no-cache, privateDate: Sun, 24 Jun 2018 12:30:57 GMTConnection: keep-alive&#123;"message":"405 Method Not Allowed","error_code": 40500&#125; 406 Not AcceptableAPI 在不支持客户端指定的数据格式时，应该返回此状态码。如支持 JSON 和 XML 输出的 API 被指定返回 YAML 格式的数据时。 Http 协议一般通过请求首部的 Accept 来指定数据格式 408 Request Timeout客户端请求超时时 必须 返回该状态码，需要注意的时，该状态码表示 客户端请求超时，在涉及第三方 API 调用超时时，一定不可 返回该状态码。 409 Confilct该状态码表示因为请求存在冲突无法处理。如通过手机号码提供注册功能的 API，当用户提交的手机号已存在时，必须 返回此状态码。 123456789HTTP/1.1 409 ConflictServer: nginx/1.11.9Content-Type: application/jsonTransfer-Encoding: chunkedCache-Control: no-cache, privateDate: Sun, 24 Jun 2018 12:19:04 GMTConnection: keep-alive&#123;"error_code":40900,"message":"手机号已存在"&#125; 410 Gone和 404 类似，该状态码也表示请求的资源不存在，只是 410 状态码进一步表示所请求的资源已不存在，并且未来也不会存在。在收到 410 状态码后，客户端 应该 停止再次请求该资源。 413 Request Entity Too Large该状态码表示服务器拒绝处理当前请求，因为该请求提交的实体数据大小超过了服务器愿意或者能够处理的范围。 此种情况下，服务器可以关闭连接以免客户端继续发送此请求。 如果这个状况是临时的，服务器 应该 返回一个 Retry-After 的响应头，以告知客户端可以在多少时间以后重新尝试。 414 Request-URI Too Long该状态码表示请求的 URI 长度超过了服务器能够解释的长度，因此服务器拒绝对该请求提供服务。 415 Unsupported Media Type通常表示服务器不支持客户端请求首部 Content-Type 指定的数据格式。如在只接受 JSON 格式的 API 中放入 XML 类型的数据并向服务器发送，都 应该 返回该状态码。 该状态码也可用于如：只允许上传图片格式的文件，但是客户端提交媒体文件非法或不是图片类型，这时 应该 返回该状态码： 123456789HTTP/1.1 415 Unsupported Media TypeServer: nginx/1.11.9Content-Type: application/jsonTransfer-Encoding: chunkedCache-Control: no-cache, privateDate: Sun, 24 Jun 2018 12:09:40 GMTConnection: keep-alive&#123;"error_code":41500,"message":"不允许上传的图片格式"&#125; 429 Too Many Requests该状态码表示用户请求次数超过允许范围。如 API 设定为 60次/分钟，当用户在一分钟内请求次数超过 60 次后，都 应该 返回该状态码。并且也 应该 在响应首部中加上下列头部： 1234X-RateLimit-Limit: 10 请求速率（由应用设定，其单位一般为小时/分钟等，这里是 10次/5分钟）X-RateLimit-Remaining: 0 当前剩余的请求数量X-RateLimit-Reset: 1529839462 重置时间Retry-After: 120 下一次访问应该等待的时间（秒） 列子 12345678910111213HTTP/1.1 429 Too Many RequestsServer: nginx/1.11.9Content-Type: application/jsonTransfer-Encoding: chunkedX-RateLimit-Limit: 10X-RateLimit-Remaining: 0X-RateLimit-Reset: 1529839462Retry-After: 290Cache-Control: no-cache, privateDate: Sun, 24 Jun 2018 11:19:32 GMTConnection: keep-alive&#123;"message":"You have exceeded your rate limit.","error_code":42900&#125; 必须 为所有的 API 设置 Rate Limit 支持。 500 Internal Server Error该状态码 必须 在服务器出错时抛出，对于所有的 500 错误，都 应该 提供完整的错误信息支持，也方便跟踪调试。 503 Service Unavailable该状态码表示服务器暂时处理不可用状态，当服务器需要维护或第三方 API 请求超时/不可达时，都 应该 返回该状态码，其中若是主动关闭 API 服务，应该在返回的响应首部加上 Retry-After 头部，表示多少秒后可以再次访问。 12345678910HTTP/1.1 503 Service UnavailableServer: nginx/1.11.9Content-Type: application/jsonTransfer-Encoding: chunkedCache-Control: no-cache, privateDate: Sun, 24 Jun 2018 10:56:20 GMTRetry-After: 60Connection: keep-alive&#123;"error_code":50300,"message":"服务维护中"&#125; 其他 HTTP 状态码请参考 HTTP 状态码- 维基百科]]></content>
      <categories>
        <category>规范</category>
      </categories>
      <tags>
        <tag>restful api</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 查看端口是否被占用]]></title>
    <url>%2Fposts%2Fd03adf2b.html</url>
    <content type="text"><![CDATA[查询哪个进程在监听端口 123netstat -anop | grep 8080# 或者lsof -i:8080]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>netstat</tag>
        <tag>lsof</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring cache 常用缓存注解介绍]]></title>
    <url>%2Fposts%2F3bef8a86.html</url>
    <content type="text"><![CDATA[spring-cache 常用缓存注解介绍 包地址 注解名 作用域 作用 org.springframework.cache.annotation CacheConfig 类级别 s设置缓存的公共配置 Cacheable 方法级别 缓存读取操作 CacheEvict 方法级别 缓存失效操作 CachePut 方法级别 缓存更新操作 Caching 方法级别 h混合读取、失效、更新操作 CacheConfig主要作用是全局配置，比如配置缓存名称（cacheNames），只需要在类上面使用这个注解配置一次，类下面的方法就默认使用全局配置了。 Cacheable这个注解是最重要的，主要实现的是功能在进行读操作的时候，先从缓存中查询，如果查询不到，再走业务流程获取数据，获取成功后，保存到缓存中。 属性 默认值 描述 value 缓存的名称，在 spring 配置文件中定义，必须指定至少一个 cacheNames 缓存的名称，在 spring 配置文件中定义，必须指定至少一个 key 缓存的 key，可以为空，如果指定要按照 SpEL 表达式编写，如果不指定，则缺省按照方法的所有参数进行组合 keyGenerator cacheManager cacheResolver condition 缓存的条件，可以为空，使用 SpEL 编写，返回 true 或者 false，只有为 true 才进行缓存。不能使用返回结果 unless 不缓存的条件，可以为空，使用 SpEL 编写，返回 true 或者 false，只有为 false才进行缓存。可以使用返回结果 sync CacheEvict这个注解主要是配合@Cacheable一起使用，它的主要作用是清除缓存。当进行一些更新、删除操作时，就需要删除缓存。如果不删除缓存就会出现读取不到最新数据的情况。它有一个重要的数据allEntries默认是false。当true是，会清除所有缓存，而不以指定的key为主。 CachePut 这个注解总是会把数据缓存，而不会每次检测缓存是否存在 Caching这个注解是Cacheable、CachePut、CacheEvict的综合体，可以使用这个注解包含以上3个注解。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring retry 使用]]></title>
    <url>%2Fposts%2F9cd0a544.html</url>
    <content type="text"><![CDATA[@Retryable 被注解的方法发生异常时会重试 参数 默认值 说明 value 空 指定发生的异常，进行重试 include 空 指定异常重试。和value一样，默认空，当exclude也为空时，所有异常都重试 exclude 空 指定异常不重试。默认空，当include也为空时，所有异常都重试 maxAttemps 3 重试次数 backoff 空 重试补偿机制 @Backoff 参数 默认值 说明 delay 1000L 指定延迟时间 multiplier 0.0D 指定延迟的倍数。比如delay=5000l,multiplier=2时，第一次重试为5秒后，第二次为10秒，第三次为20秒 @Recover 当重试到达指定次数时，被注解的方法将被回调，可以在该方法中进行日志处理。需要注意的是发生的异常和入参类型一致时才会回调。 示例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import org.springframework.retry.annotation.Backoff;import org.springframework.retry.annotation.Recover;import org.springframework.retry.annotation.Retryable;import org.springframework.stereotype.Service;/** * @author Created by YL on 2018/7/18 */@Service@Slf4jpublic class RetryService &#123; @Retryable( value = &#123;Exception.class&#125;, maxAttempts = 10, backoff = @Backoff(delay = 10000L) ) public String retry() throws Exception &#123; throw new Exception("测试 spring retry"); &#125; @Recover public void exception(Exception e) &#123; log.error("errmsg: &#123;&#125;", e.getMessage(), e); &#125;&#125;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.retry.annotation.EnableRetry;@SpringBootApplication@EnableRetrypublic class App &#123; /** * Common */ private static SpringApplicationBuilder configureSpringBuilder(SpringApplicationBuilder builder) &#123; //builder.application().addListeners(new EnvironmentPreparedEventListener()); builder.application().addPrimarySources(Collections.singletonList(App.class)); return builder.sources(App.class); &#125; // /** // * for WAR deploy // */ // @Override // protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; // // // 外部容器部署 web 环境要在这里配置 EnvironmentPreparedEvent 监听器才生效 // // builder.application().addListeners(new EnvironmentPreparedEventListener()); // // return builder.sources(Application.class); // return super.configure(configureSpringBuilder(builder)); // &#125; /** * for JAR deploy */ public static void main(String[] args) &#123; // SpringApplication.run(Application.class, args); SpringApplicationBuilder builder = configureSpringBuilder(new SpringApplicationBuilder()); builder.application().run(args); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>retry</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty Epoll 和 Nio]]></title>
    <url>%2Fposts%2Fa8f7cc4d.html</url>
    <content type="text"><![CDATA[入门1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677import org.slf4j.Logger;import org.slf4j.LoggerFactory;import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.Channel;import io.netty.channel.ChannelOption;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.nio.NioServerSocketChannel;import io.netty.handler.ssl.SslContext;import io.netty.handler.ssl.SslContextBuilder;import io.netty.handler.ssl.util.SelfSignedCertificate;import io.netty.util.concurrent.DefaultEventExecutorGroup;import io.netty.util.concurrent.EventExecutorGroup;/** * Netty 启动器，初始化 spring boot 的时候会自动加载 */public class Server &#123; private static final Logger LOG = LoggerFactory.getLogger(Server.class); /* * NioEventLoopGroup 默认创建数量为 CPU * 2，类型为 NioEventLoop 的实例。 * 每个 NioEventLoop 实例都持有一个线程，以及一个类型为 LinkedBlockingQueue 的任务队列 */ EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); // 业务线程 EventExecutorGroup eventExecutorGroup = new DefaultEventExecutorGroup(16); static final boolean isSsl = System.getProperty("ssl") != null; /** * 初始化 Netty */ public void startNetty() &#123; try &#123; final SslContext sslCtx; if (isSsl) &#123; SelfSignedCertificate ssc = new SelfSignedCertificate(); sslCtx = SslContextBuilder.forServer(ssc.certificate(), ssc.privateKey()).build(); &#125; else &#123; sslCtx = null; &#125; // 引导辅助程序 ServerBootstrap bs = new ServerBootstrap(); // 通过NIO方式来接收连接和处理连接 bs.group(bossGroup, workerGroup); // 设置NIO的Channel bs.channel(NioServerSocketChannel.class); bs.childHandler(new HttpChannelInitializer(sslCtx, eventExecutorGroup)); bs.option(ChannelOption.SO_BACKLOG, 1024); // 连接数 // bs.childOption(ChannelOption.SO_KEEPALIVE, true); // 是否长链接 bs.childOption(ChannelOption.TCP_NODELAY, true); // 是否TCP延迟 // 配置完成，开始绑定server，通过调用sync同步方法阻塞直到绑定成功 Channel ch = bs.bind(9999).sync().channel(); LOG.info("Server startup. listen on &#123;&#125;-&#123;&#125;", (isSsl ? "https" : "http"), 9999); // 应用程序会一直等待，直到Channel关闭 ch.closeFuture().sync(); &#125; catch (Exception e) &#123; LOG.error("server startup failed. &#123;&#125;", e.getMessage(), e); &#125; finally &#123; LOG.info("释放资源..."); bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); eventExecutorGroup.shutdownGracefully(); bossGroup = null; workerGroup = null; eventExecutorGroup = null; &#125; &#125; public static void main(String[] args) &#123; new Server().startNetty(); &#125;&#125; 优化：Epoll 和 Nio123456private static final boolean isEpoll = Epoll.isAvailable();private EventLoopGroup bossGroup = isEpoll ? new EpollEventLoopGroup() : new NioEventLoopGroup();private EventLoopGroup workerGroup = isEpoll ? new EpollEventLoopGroup() : new NioEventLoopGroup();ServerBootstrap bootstrap = new ServerBootstrap();bootstrap.group(bossGroup, workerGroup) .channel(isEpoll ? EpollServerSocketChannel.class : NioServerSocketChannel.class);]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-boot 事件监听 ApplicationListener]]></title>
    <url>%2Fposts%2Fba3065f8.html</url>
    <content type="text"><![CDATA[介绍SpringBoot 为 ApplicationContextEvent 提供了四种事件： ApplicationStartedEvent ：spring boot 启动开始时执行的事件 ApplicationEnvironmentPreparedEvent：spring boot 对应 Enviroment 已经准备完毕，但此时上下文 context 还没有创建 ApplicationPreparedEvent：spring boot 上下文 context 创建完成，但此时 spring 中的 bean 是没有完全加载完成的 ApplicationFailedEvent：spring boot启动异常时执行事件 ApplicationEnvironmentPreparedEvent事件监听123456789101112131415161718192021import lombok.extern.slf4j.Slf4j;import org.springframework.boot.context.event.ApplicationEnvironmentPreparedEvent;import org.springframework.context.ApplicationListener;import org.springframework.core.env.ConfigurableEnvironment;/** * 环境配置事件监听器 * * @author Created by YL on 2018/7/5 */@Slf4jpublic class EnvironmentPreparedEventListener implements ApplicationListener&lt;ApplicationEnvironmentPreparedEvent&gt; &#123; @Override public void onApplicationEvent(ApplicationEnvironmentPreparedEvent event) &#123; ConfigurableEnvironment environment = event.getEnvironment(); // 获取 spring.profiles.active 的值 String activeProfile = environment.getActiveProfiles()[0]; log.info("激活环境 ---&gt; activeProfile: &#123;&#125;", activeProfile); &#125;&#125; 这里要注意注册ApplicationEnvironmentPreparedEvent监听器的方式 如果是 jar 环境部署 12345678910111213141516171819202122232425262728293031323334353637import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import java.util.Collections;/** * @author Created by YL on 2018/7/5 */@SpringBootApplicationpublic class App &#123; /** * Common */ private static SpringApplicationBuilder configureSpringBuilder(SpringApplicationBuilder builder) &#123; builder.listeners(new EnvironmentPreparedEventListener()); return builder.sources(App.class); &#125; /** * for JAR deploy */ public static void main(String[] args) &#123; configureSpringBuilder(new SpringApplicationBuilder()) .run(args); synchronized (App.class) &#123; while (true) &#123; try &#123; App.class.wait(); &#125; catch (Exception e) &#123; e.printStackTrace(); break; &#125; &#125; &#125; &#125;&#125; 或者 123456789101112131415161718192021222324252627282930import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import java.util.Collections;/** * @author Created by YL on 2018/7/5 */@SpringBootApplicationpublic class App &#123; /** * for JAR deploy */ public static void main(String[] args) &#123; SpringApplication app = new SpringApplication(Application.class); app.addListeners(new EnvironmentPreparedEventListener()); app.run(args); synchronized (App.class) &#123; while (true) &#123; try &#123; App.class.wait(); &#125; catch (Exception e) &#123; e.printStackTrace(); break; &#125; &#125; &#125; &#125;&#125; 如果是 war 环境部署 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.boot.web.servlet.support.SpringBootServletInitializer;import java.util.Collections;/** * @author Created by YL on 2018/7/2 */@SpringBootApplicationpublic class App extends SpringBootServletInitializer &#123; /** * Common */ private static SpringApplicationBuilder configureSpringBuilder(SpringApplicationBuilder builder) &#123; builder.listeners(new EnvironmentPreparedEventListener()); return builder.sources(App.class); &#125; /** * for WAR deploy */ @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; return configureSpringBuilder(builder); &#125; /** * for JAR deploy */ public static void main(String[] args) &#123; configureSpringBuilder(new SpringApplicationBuilder()) .run(args); synchronized (App.class) &#123; while (true) &#123; try &#123; App.class.wait(); &#125; catch (Exception e) &#123; e.printStackTrace(); break; &#125; &#125; &#125; &#125;&#125; Junit 测试 测试单元下，自定义事件不生效的问题 123456789101112131415161718192021222324252627@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTest(classes = App.class)@ContextConfiguration(loader = IAmTest.CustomLoader.class)@ActiveProfiles("local")// 单元测试配置数据库默认会事务会退，此时强制事务提交// @Rollback(false) @Slf4jpublic class IAmTest &#123; public static class CustomLoader extends SpringBootContextLoader &#123; @Override protected SpringApplication getSpringApplication() &#123; SpringApplication app = super.getSpringApplication(); app.addListeners(new EnvironmentPreparedEventListener()); return app; &#125; &#125; @Resource private TestService testService; @Test public void get() &#123; JSONObject json = testService.get("name", "200~180****2307~01~~"); System.out.println(json); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[返回 JSON 格式数据，Long 前端精准度丢失问题]]></title>
    <url>%2Fposts%2Fa56434f6.html</url>
    <content type="text"><![CDATA[spring-boot 2.0.0 以下版本 12345678910111213141516171819@Configurationpublic class WebMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; // 返回 JSON，Long 前端精准度丢失问题 MappingJackson2HttpMessageConverter converter = new MappingJackson2HttpMessageConverter(); ObjectMapper mapper = new ObjectMapper(); /* * 序列换成json时,将所有的long变成string * 因为js中得数字类型不能包含所有的java long值 */ SimpleModule module = new SimpleModule(); module.addSerializer(Long.class, ToStringSerializer.instance); module.addSerializer(Long.TYPE, ToStringSerializer.instance); mapper.registerModule(module); converter.setObjectMapper(mapper); converters.add(converter); &#125;&#125; 在spring-boot 2.0.x以上版本，要在WebMvConfig上添加@Order(0)注解，否则配置不生效 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import com.fasterxml.jackson.databind.module.SimpleModule;import com.fasterxml.jackson.databind.ser.std.ToStringSerializer;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.core.annotation.Order;import org.springframework.http.converter.HttpMessageConverter;import org.springframework.http.converter.json.Jackson2ObjectMapperBuilder;import org.springframework.http.converter.json.MappingJackson2HttpMessageConverter;import org.springframework.web.servlet.config.annotation.InterceptorRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;import java.math.BigInteger;import java.text.SimpleDateFormat;import java.util.List;/** * Web Mvc 自定义配置 * * &lt;pre&gt; * spring-boot 2.0.0.RELEASE configureMessageConverters生效，2.0.3.RELEASE不生效问题 * 2.0.3.RELEASE要加&amp;#64;Order(0)才可以，而2.0.0.RELEASE以下版本不用加 * &lt;/pre&gt; * * @author Created by YL on 2017/6/5. */@Configuration@Order(0)public class WebMvcConfig implements WebMvcConfigurer &#123; @Override public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; Jackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.json(); builder.dateFormat(new SimpleDateFormat("yyyy-MM-dd HH:mm:ss")); // if (this.applicationContext != null) &#123; // builder.applicationContext(this.applicationContext); // &#125; // messageConverters.add(new MappingJackson2HttpMessageConverter(builder.build())); // 返回 JSON，Long 前端精准度丢失问题 // ObjectMapper mapper = new ObjectMapper(); // // 格式化日志格式 // mapper.setDateFormat(new SimpleDateFormat("yyyy-MM-dd HH:mm:ss")); /* * 序列换成json时,将所有的long变成string * 因为js中得数字类型不能包含所有的java long值 */ SimpleModule module = new SimpleModule(); module.addSerializer(Long.TYPE, ToStringSerializer.instance); module.addSerializer(Long.class, ToStringSerializer.instance); module.addSerializer(BigInteger.class, ToStringSerializer.instance); builder.modules(module); // mapper.registerModule(module); // MappingJackson2HttpMessageConverter converter = new MappingJackson2HttpMessageConverter(builder.build()); // converter.setObjectMapper(mapper); converters.add(new MappingJackson2HttpMessageConverter(builder.build())); &#125;&#125; spring-boot 2.1.x 版本 1234567891011121314151617@Beanpublic Jackson2ObjectMapperBuilderCustomizer jackson2ObjectMapperBuilderCustomizer() &#123; Jackson2ObjectMapperBuilderCustomizer customizer = new Jackson2ObjectMapperBuilderCustomizer() &#123; @Override public void customize(Jackson2ObjectMapperBuilder builder) &#123; builder.dateFormat(new SimpleDateFormat("yyyy-MM-dd HH:mm:ss")) /* * 序列换成json时,将所有的long变成string * 因为js中得数字类型不能包含所有的java long值 */ .serializerByType(Long.class, ToStringSerializer.instance) .serializerByType(Long.TYPE, ToStringSerializer.instance) .serializerByType(BigInteger.class, ToStringSerializer.instance); &#125; &#125;; return customizer;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[vue-cli 2.x 使用]]></title>
    <url>%2Fposts%2F58b4b1b8.html</url>
    <content type="text"><![CDATA[安装 vue-cli 12# 全局安装npm install -g vue-cli 如果安装失败，可以使用npm cache clean清理缓存，然后再重新安装 生成项目 首先需要在命令行中进入到工作区间，然后输入 1vue init webpack vue-project 全局安装webpack命令npm install -g webpack vue-project 是自定义的项目名称，命令执行之后，会在当前目录生成一个以该名称命名的项目文件夹 proxyTable 代理设置 前后端分离项目本地测试，可以使用 proxyTable 代理到后台服务器，方便调试 12345678910proxyTable: &#123; '/api': &#123; targer: 'https:localhost:8080/service/api', secure: false, changeOrigin: true, pathRewrite: &#123; '^/api': '/' &#125; &#125;&#125; 使用时直接/api/接口名就行了]]></content>
      <categories>
        <category>vuejs</category>
      </categories>
      <tags>
        <tag>vue</tag>
        <tag>nodejs</tag>
        <tag>vue-cli</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle 分区]]></title>
    <url>%2Fposts%2F7150914.html</url>
    <content type="text"><![CDATA[自增分区 numtoyminterval 按年、月分区 numtoyminterval(1, ‘year’)、numtoyminterval(1, ‘month’) numtodsinterval 按天、时、分、秒分区 numtodsinterval(1, ‘day’)、numtodsinterval(1, ‘hour’)、numtodsinterval(1, ‘minute’)、numtodsinterval(1, ‘second’) 例子 1234567create table user (id number, create_dt date) tablespace users partition by range (create_dt) interval(numtoyminterval(1, 'month')) ( partition p1 values less than (to_date('2018-01-01 00:00:00', 'yyyy-mm-dd hh24:mi:ss')) ); 清空、删除分区操作1234567891011121314151617181920212223242526272829303132333435# 创建分区表略# 检查分区表及数据sql&gt; select t.table_name,t.partition_name,t.num_rows,t.blocks,t.interval,t.high_value from USER_TAB_PARTITIONS t;# 创建主键和索引sql&gt; alter table TEST_PARTAS add constraint pk_id primary key(ID);sql&gt; CREATE INDEX IND_ACCOUNT_ID ON TEST_PARTAS (ACCOUNT_ID);# 检查索引状态，当前状态可用sql&gt; select T.INDEX_NAME,T.TABLE_NAME,T.STATUS from user_indexes t where t.table_name='TEST_PARTAS';INDEX_NAME TABLE_NAME STATUS------------------------------ ------------------------------ --------PK_ID TEST_PARTAS VALIDIND_ACCOUNT_ID TEST_PARTAS VALID# 用truncate 删除p0分区数据，不加update index参数sql&gt; alter table test_partas truncate partition p0;# 检查索引状态，状态不可用INDEX_NAME TABLE_NAME STATUS------------------------------ ------------------------------ --------PK_ID TEST_PARTAS UNUSABLEIND_ACCOUNT_ID TEST_PARTAS UNUSABLE# 重建立索引，要加online ，尽量减小对业务的冲击sql&gt; alter index PK_ID rebuild online;sql&gt; alter index IND_ACCOUNT_ID rebuild online;此时索引恢复正常可用状态# 用truncate 删除p1分区数据，增加update index参数sql&gt; alter table test_partas truncate partition p1 update indexes;此时索引是正常可用状态 扩展 如果 truncate 清空分区数据、drop 删除分区，索引都会失效 1sql&gt; alter table test_partas drop partition SYS_P1611; 1234567891011CREATE TABLE IM_WX_PAGEOPEN_LOG_02 NOLOGGING AS SELECT * FROM IM_WX_PAGEOPEN_LOG;ALTER TABLE IM_WX_PAGEOPEN_LOG DROP PARTITION P2020Y010;ALTER TABLE IM_WX_PAGEOPEN_LOG DROP PARTITION P2020Y11;ALTER TABLE IM_WX_PAGEOPEN_LOG DROP PARTITION P2020Y12;ALTER TABLE IM_WX_PAGEOPEN_LOG ADD PARTITION P2020Y09 VALUES LESS THAN(TO_DATE('2020-10-01 00:00:00', 'yyyy-mm-dd hh24:mi:ss'));ALTER TABLE IM_WX_PAGEOPEN_LOG ADD PARTITION P2020Y10 VALUES LESS THAN(TO_DATE('2020-11-01 00:00:00', 'yyyy-mm-dd hh24:mi:ss'));ALTER TABLE IM_WX_PAGEOPEN_LOG ADD PARTITION P2020Y11 VALUES LESS THAN(TO_DATE('2020-12-01 00:00:00', 'yyyy-mm-dd hh24:mi:ss'));ALTER TABLE IM_WX_PAGEOPEN_LOG ADD PARTITION P2020Y12 VALUES LESS THAN(TO_DATE('2021-01-01 00:00:00', 'yyyy-mm-dd hh24:mi:ss')); 查询索引状态不可用123SELECT T.INDEX_NAME, T.TABLE_NAME, T.STATUS FROM USER_INDEXES T WHERE T.TABLE_NAME IN (SELECT T.TABLE_NAME FROM USER_TABLES T);]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[druid 打印 sql 日志]]></title>
    <url>%2Fposts%2Fbee514fe.html</url>
    <content type="text"><![CDATA[依赖包 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt;&lt;/dependency&gt; 在 application.yml 中配置 slf4j.enabled=true 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051spring: datasource: url: jdbc:oracle:thin:@ip:port username: admin password: admin druid: initial-size: 3 min-idle: 3 max-active: 10 max-wait: 60000 keep-alive: true time-between-eviction-runs-millis: 60000 min-evictable-idle-time-millis: 300000 validation-query: SELECT 'x' FROM DUAL test-while-idle: true test-on-borrow: false test-on-return: false pool-prepared-statements: true max-pool-prepared-statement-per-connection-size: 20 filter: wall: enabled: true stat: enabled: false slf4j: enabled: true# connection-log-enabled: true# connection-log-error-enabled: true# connection-close-after-log-enabled: true# connection-commit-after-log-enabled: true# connection-connect-after-log-enabled: true# connection-connect-before-log-enabled: true# connection-rollback-after-log-enabled: true# statement-log-enabled: true# statement-log-error-enabled: true# statement-close-after-log-enabled: true# statement-create-after-log-enabled: true statement-executable-sql-log-enable: true# statement-execute-after-log-enabled: true# statement-execute-batch-after-log-enabled: true# statement-execute-query-after-log-enabled: true# statement-execute-update-after-log-enabled: true# statement-parameter-clear-log-enable: true# statement-parameter-set-log-enabled: true# statement-prepare-after-log-enabled: true# statement-prepare-call-after-log-enabled: true# result-set-log-enabled: true# result-set-log-error-enabled: true# result-set-close-after-log-enabled: true# result-set-next-after-log-enabled: true# result-set-open-after-log-enabled: true 在 logback.xml 中配置 12345678910111213141516171819202122232425262728&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration scan="true" scanPeriod="60 seconds" debug="false"&gt; &lt;property name="logger.charset" value="UTF-8"/&gt; &lt;property name="logger.path" value="./logs"/&gt; &lt;property name="logger.pattern" value="%d&#123;yy-MM-dd HH:mm:ss&#125; %p %t %c&#123;2&#125;.%M\\(%L\\) | %m%n"/&gt; &lt;property name="logger.maxHistory" value="7"/&gt; &lt;appender name="stdout" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder charset="$&#123;logger.charset&#125;"&gt; &lt;pattern&gt;$&#123;logger.pattern&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- druid --&gt; &lt;!-- &lt;logger name="druid.sql.Connection" level="debug"/&gt; &lt;logger name="druid.sql.DataSource" level="debug"/&gt; --&gt; &lt;logger name="druid.sql.Statement" level="debug"/&gt; &lt;!-- &lt;logger name="druid.sql.ResultSet" level="debug"/&gt; --&gt; &lt;root level="info"&gt; &lt;appender-ref ref="stdout"/&gt; &lt;/root&gt;&lt;/configuration&gt; sql 日志 123456789[18-06-05 11:56:40 DEBUG] main d.s.Statement.statementLog(134) | &#123;conn-10003, pstmt-20002&#125; created. select user0_.id as id1_0_, user0_.openid as openid2_0_ from user user0_ where user0_.openid=?[18-06-05 11:56:40 DEBUG] main d.s.Statement.statementLog(134) | &#123;conn-10003, pstmt-20002&#125; Parameters : [oTlSg04-KUsQZc_OCKyDCALMizxw][18-06-05 11:56:40 DEBUG] main d.s.Statement.statementLog(134) | &#123;conn-10003, pstmt-20002&#125; Types : [VARCHAR][18-06-05 11:56:40 DEBUG] main d.s.Statement.statementLog(134) | &#123;conn-10003, pstmt-20002, rs-50001&#125; query executed. 20.335752 millis. select user0_.id as id1_0_, user0_.openid as openid2_0_ from user user0_ where user0_.openid=?[18-06-05 11:56:40 DEBUG] main d.s.ResultSet.resultSetLog(139) | &#123;conn-10003, pstmt-20002, rs-50001&#125; open[18-06-05 11:56:40 DEBUG] main d.s.ResultSet.resultSetLog(139) | &#123;conn-10003, pstmt-20002, rs-50001&#125; Header: [ID1_0_, OPENID2_0_][18-06-05 11:56:40 DEBUG] main d.s.ResultSet.resultSetLog(139) | &#123;conn-10003, pstmt-20002, rs-50001&#125; Result: [14248992, oTlSg04-KUsQZc_OCKyDCALMizxw][18-06-05 11:56:40 DEBUG] main d.s.ResultSet.resultSetLog(139) | &#123;conn-10003, pstmt-20002, rs-50001&#125; closed[18-06-05 11:56:40 DEBUG] main d.s.Statement.statementLog(134) | &#123;conn-10003, pstmt-20002&#125; clearParameters.]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
        <tag>alibaba</tag>
        <tag>druid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-boot cxf 集成]]></title>
    <url>%2Fposts%2Fb0385cf0.html</url>
    <content type="text"><![CDATA[坑一123456789101112131415161718192021222324@Beanpublic AegisDatabinding aegisDatabinding() &#123; return new AegisDatabinding();&#125;/** * 这个要配置成多例模式 */@Bean@Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE)public org.apache.cxf.jaxws.support.JaxWsServiceFactoryBean jaxWsServiceFactoryBean() &#123; JaxWsServiceFactoryBean sf = new JaxWsServiceFactoryBean(); sf.setWrapped(true); sf.setDataBinding(aegisDatabinding()); return sf;&#125;@Beanpublic Endpoint userEndpoint(UserService userService) &#123; EndpointImpl endpoint = new EndpointImpl(userService); endpoint.setServiceFactory(jaxWsServiceFactoryBean()); endpoint.publish("/imCheckRelatedWeixinService.ws"); return endpoint;&#125; 这里 endpoint.publish 要在最后，否则获取到的 serviceFactory、dataBinding 等参数是空的]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>cxf</tag>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hibernate 函数]]></title>
    <url>%2Fposts%2F35958b11.html</url>
    <content type="text"><![CDATA[HQL(Hibernate Query Language) 提供了丰富的、灵活的查询特性，提供了类似标准SQL语句的查询方式，同时也提供了面向对象的封装。以下是HQL的一些常用函数，比如时间函数、字符串函数等。 时间函数 函数名称 说明 支持 使用方法 备注 CURRENT_DATE() 数据库当前日期 JPAQL、HQL CURRENT_DATE() CURRENT_TIME() 数据库当前时间 JPAQL、HQL CURRENT_TIME() CURRENT_TIMESTAMP() 数据库当前日期+时间 JPAQL、HQL CURRENT_TIMESTAMP() SECOND(d) 日期中提取秒 HQL SECOND(时间字段) 空的时候返回null MINUTE(d) 日期中提取分 HQL MINUTE(时间字段) 空的时候返回null HOUR(d) 日期中提取小时 HQL HOUR(时间字段) 空的时候返回null DAY(d) 日期中提取天 HQL DAY(时间字段) 空的时候返回null MONTH(d) 日期中提取月 HQL MONTH(时间字段) 空的时候返回null YEAR(d) 日期中提取年 HQL YEAR(时间字段) 空的时候返回null 字符串函数 函数名称 说明 支持 使用方法 备注 SUBSTRIGN(s,offset,length) 字符截取 JPAQL、HQL TRIM(s) 去掉两端的空格 JPAQL、HQL LOWER(s) 转换小写 JPAQL、HQL UPPER(s) 转换大写 JPAQL、HQL LENGTH(s) 字符长度 JPAQL、HQL CONCAT(s1,s2) 连接字符串 JPAQL、HQL 数学函数 函数名称 说明 支持 使用方法 备注 ABS(n) 取绝对值 JPAQL、HQL ABS(col_name[数字类型对象属性]) SQRT(n) 取平方根 JPAQL、HQL SQRT(col_name[数字类型对象属性]) MOD(n1, n2) 取余数 JPAQL、HQL MOD([对象属性(数字)或值],[对象属性（数字）或值]) 数字必须是整型 集合函数 函数名称 说明 支持 使用方法 备注 MAX(c) 最大值 JPQHQL 、HQL MIN(c) 最小值 JPQHQL 、HQL COUNT(c) 返回计数 JPQHQL 、HQL SIZE(c) 方法集合内对象数量 JPAQL HQL MINELEMENT(c) 返回集合中最小元素 HQL MAXELEMENT(c) 返回集合中最大元素 HQL MININDEX(c) 返回索引集合最小索引 HQL MAXINDEX(c) 返回索引集合最大索引 HQL]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql for Mac 使用]]></title>
    <url>%2Fposts%2F4ae0cbaa.html</url>
    <content type="text"><![CDATA[配置环境变量1234567$ cd ~# 如果没有 .bash_profile 文件，可以通过 touch 来创建一个$ touch .bash_profile# 编辑已经存在的文件，先打开文件$ open -e .bash_profile# 使配置生效$ source .bash_profile 在 .base_profile 中加入如下内容 1export PATH=$PATH:/usr/local/mysql/bin 修改root默认密码1$ mysqladmin -u root -p password "new password" 终端登录 mysql1$ mysql -u root -p]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Tomcat 使用注意事项]]></title>
    <url>%2Fposts%2Fd13f7d34.html</url>
    <content type="text"><![CDATA[setenv.sh在Tomcat的bin目录下添加setenv.sh文件，在启动Tomcat的时候，该脚本会被自动执行。一般在该脚本配置一些环境变量、JVM参数等 123456789101112# @Author: YL# @Date: 2017-12-18 12:15:52# @Last Modified by: YL# @Last Modified time: 2017-12-18 12:16:03# 本文件放到 Tomcat 的 bin 目录下export LANG=en_US.UTF-8export JAVA_HOME=/usr/java/jdk1.8.0_144export PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$CLASSPATHJAVA_OPT="$JAVA_OPT -Xss256k" Tomcat 安全配置相关删除默认项目删除 webapps目录下的 docs、examples、host-manager、manager、ROOT文件夹 tomcat-users.xml保持默认，不要添加帐号等信息 server.xml port 改成 -1 1&lt;Server port="-1" shutdown="SHUTDOWN"&gt; 配置线程池最小、最大值 1maxThreads=&quot;1024&quot; minSpareThreads=&quot;5&quot; 注释掉 AJP Connector 1&lt;!-- &lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" /&gt; --&gt; autoDeploy 改成 false 1&lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="false"&gt; 禁用日志输出 123&lt;!-- &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; --&gt; context 配置 123&lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="false"&gt; &lt;Context path="/outserver" docBase="../../project/outserver.war" privileged="true" reloadable="false" /&gt;&lt;/Host&gt; 这样配置，outserver.war会解压到tomcat/webapps下，也就是在webapps下生成outserver文件夹。 docBase应该指定对应的war包全路径，不应该指定路径，比如：../../project/outserver。 如果指定路径，有可以出现war包不会解压，到时项目没有更新的问题 server.xml修改了一个配置名 低版本是compressableMimeType —&gt; 高版本是compressibleMimeType]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[zookeeper 命令使用]]></title>
    <url>%2Fposts%2F56017bc5.html</url>
    <content type="text"><![CDATA[zkCli.sh123# 指定ip和端口，zkCli.sh默认进入的是2181端口# sh zkCli.sh -server localhsot:2170sh zkCli.sh -server ip:port zkServer.sh1234# 启动sh zkServer.sh start# 查看状态sh zkServersh status]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IP 操作工具类]]></title>
    <url>%2Fposts%2F27e8862d.html</url>
    <content type="text"><![CDATA[IpUtils.java1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798import javax.servlet.http.HttpServletRequest;import java.io.IOException;import java.io.InputStreamReader;import java.io.LineNumberReader;import java.net.InetAddress;import java.net.UnknownHostException;/** * IP 操作工具类 * * @author Created by YL on 2018/4/4 */public class IpUtils &#123; /** * 获取 IP * &lt;pre&gt; * 1、如果使用ngnix反向代理，导致不能使用HttpServletRequest.getRemoteAddr()获取来访者真实ip的问题， * 2、对于通过多个代理的情况，第一个IP为客户端真实IP,多个IP按照','分割 * &lt;/pre&gt; */ public static String getIpAddr(HttpServletRequest request) &#123; String ipAddr = request.getHeader("x-forwarded-for"); if (ipAddr == null || ipAddr.length() == 0 || "unknown".equalsIgnoreCase(ipAddr)) &#123; ipAddr = request.getHeader("Proxy-Client-IP"); &#125; if (ipAddr == null || ipAddr.length() == 0 || "unknown".equalsIgnoreCase(ipAddr)) &#123; ipAddr = request.getHeader("WL-Proxy-Client-IP"); &#125; if (ipAddr == null || ipAddr.length() == 0 || "unknown".equalsIgnoreCase(ipAddr)) &#123; ipAddr = request.getRemoteAddr(); if ("127.0.0.1".equals(ipAddr) || "0:0:0:0:0:0:0:1".equals(ipAddr)) &#123; //根据网卡取本机配置的IP InetAddress inet = null; try &#123; inet = InetAddress.getLocalHost(); ipAddr = inet.getHostAddress(); &#125; catch (UnknownHostException e) &#123; e.printStackTrace(); &#125; &#125; &#125; // 对于通过多个代理的情况，第一个IP为客户端真实IP,多个IP按照','分割 // 没有考虑ipv6 // if (ipAddr != null &amp;&amp; ipAddr.length() &gt; 15) &#123; //"***.***.***.***".length() = 15 // if (ipAddr.indexOf(",") &gt; 0) &#123; // ipAddr = ipAddr.substring(0, ipAddr.indexOf(",")); // &#125; // &#125; if (ipAddr != null &amp;&amp; ipAddr.contains(",")) &#123; ipAddr = ipAddr.substring(0, ipAddr.indexOf(",")); &#125; return ipAddr; &#125; /** * 根据 IP 获得 MAC 地址 * * @param ip IP 地址 */ public static String getMacAddr(String ip) &#123; String macAddr = ""; InputStreamReader isr = null; LineNumberReader reader = null; try &#123; Process p = Runtime.getRuntime().exec("nbtstat -A " + ip); isr = new InputStreamReader(p.getInputStream()); reader = new LineNumberReader(isr); for (int i = 1; i &lt; 100; i++) &#123; String str = reader.readLine(); if (str != null) &#123; if (str.indexOf("MAC Address") &gt; 1) &#123; macAddr = str.substring(str.indexOf("MAC Address") + 14, str.length()); break; &#125; &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; if (isr != null) &#123; try &#123; isr.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; if (reader != null) &#123; try &#123; reader.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; return macAddr; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Oracle 使用]]></title>
    <url>%2Fposts%2Fdb736859.html</url>
    <content type="text"><![CDATA[修改表名1rename &lt;old table_name&gt; to &lt;new table_name&gt; 修改用户名、密码123456789101112-- 用sysdba帐号登陆，查询用户信息SELECT USER#, NAME FROM USER$;-- 更改用户名并提交UPDATE USER$ SET NAME = 'HISTORY' WHERE USER# = 85;-- 强制刷新，执行数据统一性alter SYSTEM checkpoint;alter SYSTEM flush SHARED_POOL;-- 更改用户密码ALTER USER HISTORY IDENTIFIED BY SUNFLOWER_WXINNEAR_0627; 删除用户12-- CASCADE 的意思是将用户的数据库数据一并删除，并没有删除相应的表空间drop user user_name CASCADE; 修改 process1234567891011121314# 查询连接数信息SQL&gt; show parameter processes;# 当前已使用的连接数SQL&gt; select count(*) from v$process;# 修改最大连接数SQL&gt; alter system set processes = 500 scope = spfile; # 重启数据库sqlplus /nologSQL&gt; conn as sysdba;SQL&gt; shutdown immediate;SQL&gt; startup; adrci1adrci Oracle 的 trace、alert日志很大MAX_DUMP_FILE_SIZE参数 限定了trace files 以及alert file大小，其值 1、当给具体数字时，是操作系统的数据块数。2、当以m或k作为后缀时，表示以m或k为单位。3、unlimited表示没有限制，只要os允许。（默认） cd /data/app/oracle/diag/rdbms/orcl/orcl/alert/ cd /data/app/oracle/diag/rdbms/orcl/orcl/trace/ show parameter max_dump_file_size; alter system set max_dump_file_size=’1024m’; 删除 alert 日志 1find /data/app/oracle/diag/rdbms/orcl/orcl/alert/ -name "*.xml" -mtime +1 -exec rm &#123;&#125; \; 删除 trace 日志 1234567891011121314# 删除1天前的trc、trmfind /data/app/oracle/diag/rdbms/orcl/orcl/trace -name "*.trc" -mtime +1 -exec rm &#123;&#125; \;find /data/app/oracle/diag/rdbms/orcl/orcl/trace -name "*.trm" -mtime +1 -exec rm &#123;&#125; \;# alert_orcl.log 日志过大cd /data/app/oracle/diag/rdbms/orcl/orcl/tracemv alert_orcl.log alert_orcl.log_20201026touch alert_orcl.log alert_orcl.logsqlplus / as sysdbaSQL&gt; alter system switch logfile;tail -20 alert_orcl.logFri Nov 13 16:54:03 2015Thread 1 advanced to log sequence 2912 (LGWR switch) Current log# 2 seq# 2912 mem# 0: /data/app/oracle/oradata/orcl/redo02.log 删除数据表123456789101112131415-- 如果表存在，删除数据表create or replace procedure drop_table_if_exists( p_table in varchar2) is v_count number(10);beginSELECT COUNT(*) INTO V_COUNT FROM USER_OBJECTS WHERE OBJECT_NAME = UPPER(P_TABLE);IF V_COUNT &gt; 0 THEN EXECUTE IMMEDIATE 'drop table ' || P_TABLE || ' purge';END IF;END;]]></content>
      <categories>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot 打包相关]]></title>
    <url>%2Fposts%2Fab825d27.html</url>
    <content type="text"><![CDATA[webjars打包包路径：src\main\resources\webjars123456789&lt;build&gt; &lt;finalName&gt;$&#123;project.artifactId&#125;&lt;/finalName&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/resources&lt;/directory&gt; &lt;targetPath&gt;$&#123;project.build.outputDirectory&#125;/META-INF/resources/&lt;/targetPath&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt; 使用外部配置文件，静态资源123456789101112131415&lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;excludes&gt; &lt;exclude&gt;freemarker/**/*&lt;/exclude&gt; &lt;/excludes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;targetPath&gt;$&#123;project.build.directory&#125;/&lt;/targetPath&gt; &lt;includes&gt; &lt;include&gt;freemarker/**/*&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt;&lt;/resources&gt; JAR部署方式 外部 lib 打包方式 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-boot.version&#125;&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;layout&gt;ZIP&lt;/layout&gt; &lt;includes&gt; &lt;include&gt; &lt;groupId&gt;nothing&lt;/groupId&gt; &lt;artifactId&gt;nothing&lt;/artifactId&gt; &lt;/include&gt; &lt;/includes&gt; &lt;attach&gt;false&lt;/attach&gt; &lt;/configuration&gt;&lt;/plugin&gt;&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-dependencies&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;type&gt;jar&lt;/type&gt; &lt;includeTypes&gt;jar&lt;/includeTypes&gt; &lt;includeScope&gt;runtime&lt;/includeScope&gt; &lt;outputDirectory&gt; $&#123;project.build.directory&#125;/lib &lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; WAR包部署方式1234567891011121314151617181920212223&lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;repackage&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;layout&gt;WAR&lt;/layout&gt; &lt;includes&gt; &lt;include&gt; &lt;groupId&gt;nothing&lt;/groupId&gt; &lt;artifactId&gt;nothing&lt;/artifactId&gt; &lt;/include&gt; &lt;/includes&gt; &lt;attach&gt;false&lt;/attach&gt; &lt;/configuration&gt; &lt;/plugin&gt;&lt;/plugins&gt;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot 2.0 + redis自定义注解]]></title>
    <url>%2Fposts%2Fc85b105d.html</url>
    <content type="text"><![CDATA[源码https://github.com/foreveryang321/java-best-practice 自定义CacheExpire注解1234567891011121314151617181920212223242526import org.springframework.core.annotation.AliasFor;import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Inherited;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Inherited@Documentedpublic @interface CacheExpire &#123; /** * expire time, default 60s */ @AliasFor("expire") long value() default 60L; /** * expire time, default 60s */ @AliasFor("value") long expire() default 60L;&#125; 自定义Redis缓存管理器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141import com.alibaba.fastjson.support.spring.GenericFastJsonRedisSerializer;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.BeansException;import org.springframework.beans.factory.InitializingBean;import org.springframework.cache.Cache;import org.springframework.cache.annotation.CacheConfig;import org.springframework.cache.annotation.Cacheable;import org.springframework.cache.annotation.Caching;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import org.springframework.core.annotation.AnnotationUtils;import org.springframework.data.redis.cache.RedisCache;import org.springframework.data.redis.cache.RedisCacheConfiguration;import org.springframework.data.redis.cache.RedisCacheManager;import org.springframework.data.redis.cache.RedisCacheWriter;import org.springframework.data.redis.serializer.RedisSerializationContext;import org.springframework.data.redis.serializer.StringRedisSerializer;import org.springframework.util.ReflectionUtils;import java.time.Duration;import java.util.Collection;import java.util.LinkedHashMap;import java.util.LinkedList;import java.util.List;import java.util.Map;/** * redis 缓存管理器 * &lt;pre&gt; * support spring-data-redis 1.8.10.RELEASE * not support spring-data-redis 2.0.0.RELEASE + * &lt;/pre&gt; * &lt;pre&gt; * 解决的问题： * Redis 容易出现缓存问题（超时、Redis 宕机等），当使用 spring cache 的注释 Cacheable、Cacheput 等处理缓存问题时， * 我们无法使用 try catch 处理出现的异常，所以最后导致结果是整个服务报错无法正常工作。 * 通过自定义 CustomRedisCacheManager 并继承 RedisCacheManager 来处理异常可以解决这个问题。 * &lt;/pre&gt; * * @author Created by YL on 2017/10/2 */@Slf4jpublic class CustomJedisCacheManager extends RedisCacheManager implements ApplicationContextAware, InitializingBean &#123; private ApplicationContext applicationContext; private Map&lt;String, RedisCacheConfiguration&gt; initialCacheConfiguration = new LinkedHashMap&lt;&gt;(); /** * key serializer */ public static final StringRedisSerializer STRING_SERIALIZER = new StringRedisSerializer(); /** * value serializer * &lt;pre&gt; * 使用 FastJsonRedisSerializer 会报错：java.lang.ClassCastException * FastJsonRedisSerializer&lt;Object&gt; fastSerializer = new FastJsonRedisSerializer&lt;&gt;(Object.class); * &lt;/pre&gt; */ public static final GenericFastJsonRedisSerializer FASTJSON_SERIALIZER = new GenericFastJsonRedisSerializer(); /** * key serializer pair */ public static final RedisSerializationContext.SerializationPair&lt;String&gt; STRING_PAIR = RedisSerializationContext .SerializationPair.fromSerializer(STRING_SERIALIZER); /** * value serializer pair */ public static final RedisSerializationContext.SerializationPair&lt;Object&gt; FASTJSON_PAIR = RedisSerializationContext .SerializationPair.fromSerializer(FASTJSON_SERIALIZER); public CustomJedisCacheManager(RedisCacheWriter cacheWriter, RedisCacheConfiguration defaultCacheConfiguration) &#123; super(cacheWriter, defaultCacheConfiguration); &#125; @Override public Cache getCache(String name) &#123; Cache cache = super.getCache(name); return new RedisCacheWrapper(cache); &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; &#125; @Override public void afterPropertiesSet() &#123; String[] beanNames = applicationContext.getBeanNamesForType(Object.class); for (String beanName : beanNames) &#123; final Class clazz = applicationContext.getType(beanName); doWith(clazz); &#125; super.afterPropertiesSet(); &#125; @Override protected Collection&lt;RedisCache&gt; loadCaches() &#123; List&lt;RedisCache&gt; caches = new LinkedList&lt;&gt;(); for (Map.Entry&lt;String, RedisCacheConfiguration&gt; entry : initialCacheConfiguration.entrySet()) &#123; caches.add(super.createRedisCache(entry.getKey(), entry.getValue())); &#125; return caches; &#125; private void doWith(final Class clazz) &#123; ReflectionUtils.doWithMethods(clazz, method -&gt; &#123; ReflectionUtils.makeAccessible(method); CacheExpire cacheExpire = AnnotationUtils.findAnnotation(method, CacheExpire.class); Cacheable cacheable = AnnotationUtils.findAnnotation(method, Cacheable.class); Caching caching = AnnotationUtils.findAnnotation(method, Caching.class); CacheConfig cacheConfig = AnnotationUtils.findAnnotation(clazz, CacheConfig.class); List&lt;String&gt; cacheNames = CacheUtils.getCacheNames(cacheable, caching, cacheConfig); add(cacheNames, cacheExpire); &#125;, method -&gt; null != AnnotationUtils.findAnnotation(method, CacheExpire.class)); &#125; private void add(List&lt;String&gt; cacheNames, CacheExpire cacheExpire) &#123; for (String cacheName : cacheNames) &#123; if (cacheName == null || "".equals(cacheName.trim())) &#123; continue; &#125; long expire = cacheExpire.expire(); log.info("cacheName: &#123;&#125;, expire: &#123;&#125;", cacheName, expire); if (expire &gt;= 0) &#123; // 缓存配置 RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig() .entryTtl(Duration.ofSeconds(expire)) .disableCachingNullValues() // .prefixKeysWith(cacheName) .serializeKeysWith(STRING_PAIR) .serializeValuesWith(FASTJSON_PAIR); initialCacheConfiguration.put(cacheName, config); &#125; else &#123; log.warn("&#123;&#125; use default expiration.", cacheName); &#125; &#125; &#125;&#125; RedisCacheWrapper.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112import lombok.extern.slf4j.Slf4j;import org.springframework.cache.Cache;import java.util.concurrent.Callable;/** * @author Created by YL on 2018/3/28 */@Slf4jpublic class RedisCacheWrapper implements Cache &#123; private final Cache cache; public RedisCacheWrapper(Cache cache) &#123; this.cache = cache; &#125; @Override public String getName() &#123; // log.info("name: &#123;&#125;", cache.getName()); try &#123; return cache.getName(); &#125; catch (Exception e) &#123; log.error("getName ---&gt; errmsg: &#123;&#125;", e.getMessage(), e); return null; &#125; &#125; @Override public Object getNativeCache() &#123; // log.info("nativeCache: &#123;&#125;", cache.getNativeCache()); try &#123; return cache.getNativeCache(); &#125; catch (Exception e) &#123; log.error("getNativeCache ---&gt; errmsg: &#123;&#125;", e.getMessage(), e); return null; &#125; &#125; @Override public ValueWrapper get(Object o) &#123; // log.info("get ---&gt; o: &#123;&#125;", o); try &#123; return cache.get(o); &#125; catch (Exception e) &#123; log.error("get ---&gt; o: &#123;&#125;, errmsg: &#123;&#125;", o, e.getMessage(), e); return null; &#125; &#125; @Override public &lt;T&gt; T get(Object o, Class&lt;T&gt; aClass) &#123; // log.info("get ---&gt; o: &#123;&#125;, clazz: &#123;&#125;", o, aClass); try &#123; return cache.get(o, aClass); &#125; catch (Exception e) &#123; log.error("get ---&gt; o: &#123;&#125;, clazz: &#123;&#125;, errmsg: &#123;&#125;", o, aClass, e.getMessage(), e); return null; &#125; &#125; @Override public &lt;T&gt; T get(Object o, Callable&lt;T&gt; callable) &#123; // log.info("get ---&gt; o: &#123;&#125;", o); try &#123; return cache.get(o, callable); &#125; catch (Exception e) &#123; log.error("get ---&gt; o: &#123;&#125;, errmsg: &#123;&#125;", o, e.getMessage(), e); return null; &#125; &#125; @Override public void put(Object o, Object o1) &#123; // log.info("put ---&gt; o: &#123;&#125;, o1: &#123;&#125;", o, o1); try &#123; cache.put(o, o1); &#125; catch (Exception e) &#123; log.error("put ---&gt; o: &#123;&#125;, o1: &#123;&#125;, errmsg: &#123;&#125;", o, o1, e.getMessage(), e); &#125; &#125; @Override public ValueWrapper putIfAbsent(Object o, Object o1) &#123; // log.info("putIfAbsent ---&gt; o: &#123;&#125;, o1: &#123;&#125;", o, o1); try &#123; return cache.putIfAbsent(o, o1); &#125; catch (Exception e) &#123; log.error("putIfAbsent ---&gt; o: &#123;&#125;, o1: &#123;&#125;, errmsg: &#123;&#125;", o, o1, e.getMessage(), e); return null; &#125; &#125; @Override public void evict(Object o) &#123; // log.info("evict ---&gt; o: &#123;&#125;", o); try &#123; cache.evict(o); &#125; catch (Exception e) &#123; log.error("evict ---&gt; o: &#123;&#125;, errmsg: &#123;&#125;", o, e.getMessage(), e); &#125; &#125; @Override public void clear() &#123; // log.info("clear"); try &#123; cache.clear(); &#125; catch (Exception e) &#123; log.error("clear ---&gt; errmsg: &#123;&#125;", e.getMessage(), e); &#125; &#125;&#125; CacheUtils工具类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import org.springframework.cache.annotation.CacheConfig;import org.springframework.cache.annotation.Cacheable;import org.springframework.cache.annotation.Caching;import java.util.ArrayList;import java.util.Arrays;import java.util.List;/** * 缓存工具 * * @author Created by YL on 2018/4/2 */public class CacheUtils &#123; /** * 获取 cacheNames * &lt;pre&gt; * 处理优先级 cacheable &gt; caching &gt; cacheConfig * &lt;/pre&gt; * * @param cacheable 缓存注解 Cacheable * @param caching 缓存注解 Caching * @param cacheConfig 缓存注解 CacheConfig */ public static List&lt;String&gt; getCacheNames(Cacheable cacheable, Caching caching, CacheConfig cacheConfig) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); // Cacheable if (cacheable != null) &#123; String[] cacheNames = cacheable.cacheNames(); if (cacheNames.length &gt; 0) &#123; list.addAll(Arrays.asList(cacheNames)); &#125; &#125; if (list.size() &gt; 0) &#123; return list; &#125; // Caching if (caching != null) &#123; Cacheable[] cacheables = caching.cacheable(); for (Cacheable cache : cacheables) &#123; String[] cacheNames = cache.cacheNames(); if (cacheNames.length &gt; 0) &#123; list.addAll(Arrays.asList(cacheNames)); &#125; &#125; &#125; if (list.size() &gt; 0) &#123; return list; &#125; // CacheConfig if (cacheConfig != null) &#123; String[] cacheNames = cacheConfig.cacheNames(); if (cacheNames.length &gt; 0) &#123; list.addAll(Arrays.asList(cacheNames)); &#125; &#125; return list; &#125;&#125; Redis相关Bean初始化123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142import com.alibaba.fastjson.support.spring.GenericFastJsonRedisSerializer;import lombok.extern.slf4j.Slf4j;import org.springframework.boot.autoconfigure.condition.ConditionalOnBean;import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;import org.springframework.boot.autoconfigure.data.redis.RedisProperties;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.cache.CacheManager;import org.springframework.cache.annotation.CachingConfigurerSupport;import org.springframework.cache.annotation.EnableCaching;import org.springframework.cache.interceptor.KeyGenerator;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.cache.RedisCacheConfiguration;import org.springframework.data.redis.cache.RedisCacheWriter;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.StringRedisSerializer;import java.time.Duration;/** * 初始化 redis 相关 * &lt;pre&gt; * support spring-data-redis 1.8.10.RELEASE * not support spring-data-redis 2.0.0.RELEASE + * &lt;/pre&gt; * * @author Created by YL on 2017/12/6 */@Configuration// 如果 application.properties、application.yml 中没有 spring.redis.host 配置，则不初始化这些 Bean@ConditionalOnProperty(name = "spring.redis.host")@EnableConfigurationProperties(RedisProperties.class)// @EnableAutoConfiguration(exclude = &#123;RedisConnectionFactory.class&#125;)@EnableCaching(proxyTargetClass = true) // 加上这个注解是为了支持 @Cacheable、@CachePut、@CacheEvict 等缓存注解@Slf4jpublic class CustomJedisAutoConfiguration extends CachingConfigurerSupport &#123; private final RedisConnectionFactory redisConnectionFactory; CustomJedisAutoConfiguration(RedisConnectionFactory redisConnectionFactory) &#123; this.redisConnectionFactory = redisConnectionFactory; &#125; /** * 配置 RedisTemplate，设置序列化器 * &lt;pre&gt; * 在类里面配置 RestTemplate，需要配置 key 和 value 的序列化类。 * key 序列化使用 StringRedisSerializer, 不配置的话，key 会出现乱码。 * &lt;/pre&gt; */ @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate() &#123; RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;(); // set key serializer StringRedisSerializer serializer = CustomJedisCacheManager.STRING_SERIALIZER; // 设置key序列化类，否则key前面会多了一些乱码 template.setKeySerializer(serializer); template.setHashKeySerializer(serializer); // fastjson serializer GenericFastJsonRedisSerializer fastSerializer = CustomJedisCacheManager.FASTJSON_SERIALIZER; template.setValueSerializer(fastSerializer); template.setHashValueSerializer(fastSerializer); // 如果 KeySerializer 或者 ValueSerializer 没有配置，则对应的 KeySerializer、ValueSerializer 才使用这个 Serializer template.setDefaultSerializer(fastSerializer); log.info("redis: &#123;&#125;", redisConnectionFactory); LettuceConnectionFactory factory = (LettuceConnectionFactory) redisConnectionFactory; log.info("spring.redis.database: &#123;&#125;", factory.getDatabase()); log.info("spring.redis.host: &#123;&#125;", factory.getHostName()); log.info("spring.redis.port: &#123;&#125;", factory.getPort()); log.info("spring.redis.timeout: &#123;&#125;", factory.getTimeout()); log.info("spring.redis.password: &#123;&#125;", factory.getPassword()); // factory template.setConnectionFactory(redisConnectionFactory); template.afterPropertiesSet(); return template; &#125; /** * 如果 @Cacheable、@CachePut、@CacheEvict 等注解没有配置 key，则使用这个自定义 key 生成器 * &lt;pre&gt; * 但自定义了缓存的 key 时，难以保证 key 的唯一性，此时最好指定方法名，比如：@Cacheable(value="", key="&#123;#root.methodName, #id&#125;") * &lt;/pre&gt; */ @Override public KeyGenerator keyGenerator() &#123; return (o, method, objects) -&gt; &#123; StringBuilder sb = new StringBuilder(32); sb.append(o.getClass().getSimpleName()); sb.append("."); sb.append(method.getName()); if (objects.length &gt; 0) &#123; sb.append("#"); &#125; String sp = ""; for (Object object : objects) &#123; sb.append(sp); if (object == null) &#123; sb.append("NULL"); &#125; else &#123; sb.append(object.toString()); &#125; sp = "."; &#125; return sb.toString(); &#125;; &#125; /** * 配置 RedisCacheManager，使用 cache 注解管理 redis 缓存 */ @Bean @Override public CacheManager cacheManager() &#123; // 初始化一个 RedisCacheWriter RedisCacheWriter cacheWriter = RedisCacheWriter.nonLockingRedisCacheWriter(redisConnectionFactory); // 设置默认过期时间：30 min RedisCacheConfiguration defaultCacheConfig = RedisCacheConfiguration.defaultCacheConfig() .entryTtl(Duration.ofMinutes(30)) // .disableCachingNullValues() // 使用注解时 key、value 的序列化方式 .serializeKeysWith(CustomJedisCacheManager.STRING_PAIR) .serializeValuesWith(CustomJedisCacheManager.FASTJSON_PAIR); // Map&lt;String, RedisCacheConfiguration&gt; caches = new HashMap&lt;&gt;(); // // 缓存配置 // RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig() // .entryTtl(Duration.ofSeconds(60)) // .disableCachingNullValues() // // .prefixKeysWith("redis.service") // .serializeKeysWith(stringPair) // .serializeValuesWith(fastJsonPair); // caches.put("redis.service", config); // return new CustomJedisCacheManager(cacheWriter, defaultCacheConfig, caches); return new CustomJedisCacheManager(cacheWriter, defaultCacheConfig); &#125;&#125; pom.xml12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;version&gt;2.0.0.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.44&lt;/version&gt;&lt;/dependency&gt; 测试例子123456789101112131415161718import org.springframework.cache.annotation.Cacheable;import org.springframework.stereotype.Service;import java.util.HashMap;import java.util.Map;@Servicepublic class RedisService &#123; @Cacheable(value = "redis.service", unless = "#result == null or #result.empty") @CacheExpire(expire = 60) public Map&lt;String, Object&gt; get(String name) &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("id", 123); map.put("name", name); return map; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot + redis自定义注解]]></title>
    <url>%2Fposts%2F68714344.html</url>
    <content type="text"><![CDATA[注意：该方法，不兼容spring-boot 2.0 源码https://github.com/foreveryang321/java-best-practice 自定义CacheExpire注解1234567891011121314151617@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Inherited@Documentedpublic @interface CacheExpire &#123; /** * expire time, default 60s */ @AliasFor("expire") long value() default 60L; /** * expire time, default 60s */ @AliasFor("value") long expire() default 60L;&#125; 自定义redis缓存管理器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108import lombok.extern.slf4j.Slf4j;import org.springframework.beans.BeansException;import org.springframework.beans.factory.InitializingBean;import org.springframework.cache.Cache;import org.springframework.cache.annotation.CacheConfig;import org.springframework.cache.annotation.Cacheable;import org.springframework.cache.annotation.Caching;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import org.springframework.core.annotation.AnnotationUtils;import org.springframework.data.redis.cache.RedisCacheManager;import org.springframework.data.redis.core.RedisOperations;import org.springframework.util.ReflectionUtils;import java.lang.reflect.Method;import java.util.LinkedHashMap;import java.util.List;import java.util.Map;/** * Redis 缓存管理器 * &lt;pre&gt; * support spring-data-redis 1.8.10.RELEASE * not support spring-data-redis 2.0.0.RELEASE + * &lt;/pre&gt; * * &lt;pre&gt; * 解决的问题： * Redis 容易出现缓存问题（超时、Redis 宕机等），当使用 spring cache 的注释 Cacheable、Cacheput 等处理缓存问题时， * 我们无法使用 try catch 处理出现的异常，所以最后导致结果是整个服务报错无法正常工作。 * 通过自定义 CustomRedisV1CacheManager 并继承 RedisCacheManager 来处理异常可以解决这个问题。 * &lt;/pre&gt; * * @author Created by YL on 2017/10/2 */@Slf4jpublic class CustomJedisCacheManager extends RedisCacheManager implements ApplicationContextAware, InitializingBean &#123; private ApplicationContext applicationContext; private Map&lt;String, Long&gt; expires = new LinkedHashMap&lt;&gt;(); public CustomJedisCacheManager(RedisOperations redisOperations) &#123; super(redisOperations); log.info("Initialize RedisCacheManager. redisOperations: &#123;&#125;", redisOperations); &#125; @Override public Cache getCache(String name) &#123; Cache cache = super.getCache(name); return new RedisCacheWrapper(cache); &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; &#125; @Override public void afterPropertiesSet() &#123; String[] beanNames = applicationContext.getBeanNamesForType(Object.class); for (String beanName : beanNames) &#123; Class clazz = applicationContext.getType(beanName); doWith(clazz); &#125; //设置有效期 if (!expires.isEmpty()) &#123; super.setExpires(expires); &#125; &#125; private void doWith(final Class clazz) &#123; ReflectionUtils.doWithMethods(clazz, new ReflectionUtils.MethodCallback() &#123; @Override public void doWith(Method method) throws IllegalArgumentException, IllegalAccessException &#123; CacheExpire cacheExpire = AnnotationUtils.findAnnotation(method, CacheExpire.class); // cacheNames 配置优先级：Cacheable &gt; Caching &gt; CacheConfig Cacheable cacheable = AnnotationUtils.findAnnotation(method, Cacheable.class); Caching caching = AnnotationUtils.findAnnotation(method, Caching.class); CacheConfig cacheConfig = AnnotationUtils.findAnnotation(clazz, CacheConfig.class); List&lt;String&gt; cacheNames = CacheUtils.getCacheNames(cacheable, caching, cacheConfig); putExpires(cacheNames, cacheExpire); &#125; &#125;, new ReflectionUtils.MethodFilter() &#123; @Override public boolean matches(Method method) &#123; return AnnotationUtils.findAnnotation(method, CacheExpire.class) != null; &#125; &#125;); &#125; private void putExpires(List&lt;String&gt; cacheNames, CacheExpire cacheExpire) &#123; for (String cacheName : cacheNames) &#123; if (cacheName == null || "".equals(cacheName.trim())) &#123; continue; &#125; long expire = cacheExpire.expire(); if (log.isDebugEnabled()) &#123; log.debug("cacheNames: &#123;&#125;, expire: &#123;&#125;s", cacheNames, expire); &#125; if (expire &gt;= 0) &#123; expires.put(cacheName, expire); &#125; else &#123; log.warn("&#123;&#125; use default expiration.", cacheName); &#125; &#125; &#125;&#125; RedisCacheWrapper.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112import lombok.extern.slf4j.Slf4j;import org.springframework.cache.Cache;import java.util.concurrent.Callable;/** * @author Created by YL on 2018/3/28 */@Slf4jpublic class RedisCacheWrapper implements Cache &#123; private final Cache cache; public RedisCacheWrapper(Cache cache) &#123; this.cache = cache; &#125; @Override public String getName() &#123; // log.info("name: &#123;&#125;", cache.getName()); try &#123; return cache.getName(); &#125; catch (Exception e) &#123; log.error("getName ---&gt; errmsg: &#123;&#125;", e.getMessage(), e); return null; &#125; &#125; @Override public Object getNativeCache() &#123; // log.info("nativeCache: &#123;&#125;", cache.getNativeCache()); try &#123; return cache.getNativeCache(); &#125; catch (Exception e) &#123; log.error("getNativeCache ---&gt; errmsg: &#123;&#125;", e.getMessage(), e); return null; &#125; &#125; @Override public ValueWrapper get(Object o) &#123; // log.info("get ---&gt; o: &#123;&#125;", o); try &#123; return cache.get(o); &#125; catch (Exception e) &#123; log.error("get ---&gt; o: &#123;&#125;, errmsg: &#123;&#125;", o, e.getMessage(), e); return null; &#125; &#125; @Override public &lt;T&gt; T get(Object o, Class&lt;T&gt; aClass) &#123; // log.info("get ---&gt; o: &#123;&#125;, clazz: &#123;&#125;", o, aClass); try &#123; return cache.get(o, aClass); &#125; catch (Exception e) &#123; log.error("get ---&gt; o: &#123;&#125;, clazz: &#123;&#125;, errmsg: &#123;&#125;", o, aClass, e.getMessage(), e); return null; &#125; &#125; @Override public &lt;T&gt; T get(Object o, Callable&lt;T&gt; callable) &#123; // log.info("get ---&gt; o: &#123;&#125;", o); try &#123; return cache.get(o, callable); &#125; catch (Exception e) &#123; log.error("get ---&gt; o: &#123;&#125;, errmsg: &#123;&#125;", o, e.getMessage(), e); return null; &#125; &#125; @Override public void put(Object o, Object o1) &#123; // log.info("put ---&gt; o: &#123;&#125;, o1: &#123;&#125;", o, o1); try &#123; cache.put(o, o1); &#125; catch (Exception e) &#123; log.error("put ---&gt; o: &#123;&#125;, o1: &#123;&#125;, errmsg: &#123;&#125;", o, o1, e.getMessage(), e); &#125; &#125; @Override public ValueWrapper putIfAbsent(Object o, Object o1) &#123; // log.info("putIfAbsent ---&gt; o: &#123;&#125;, o1: &#123;&#125;", o, o1); try &#123; return cache.putIfAbsent(o, o1); &#125; catch (Exception e) &#123; log.error("putIfAbsent ---&gt; o: &#123;&#125;, o1: &#123;&#125;, errmsg: &#123;&#125;", o, o1, e.getMessage(), e); return null; &#125; &#125; @Override public void evict(Object o) &#123; // log.info("evict ---&gt; o: &#123;&#125;", o); try &#123; cache.evict(o); &#125; catch (Exception e) &#123; log.error("evict ---&gt; o: &#123;&#125;, errmsg: &#123;&#125;", o, e.getMessage(), e); &#125; &#125; @Override public void clear() &#123; // log.info("clear"); try &#123; cache.clear(); &#125; catch (Exception e) &#123; log.error("clear ---&gt; errmsg: &#123;&#125;", e.getMessage(), e); &#125; &#125;&#125; CacheUtils工具类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import org.springframework.cache.annotation.CacheConfig;import org.springframework.cache.annotation.Cacheable;import org.springframework.cache.annotation.Caching;import java.util.ArrayList;import java.util.Arrays;import java.util.List;/** * 缓存工具 * * @author Created by YL on 2018/4/2 */public class CacheUtils &#123; /** * 获取 cacheNames * &lt;pre&gt; * 处理优先级 cacheable &gt; caching &gt; cacheConfig * &lt;/pre&gt; * * @param cacheable 缓存注解 Cacheable * @param caching 缓存注解 Caching * @param cacheConfig 缓存注解 CacheConfig */ public static List&lt;String&gt; getCacheNames(Cacheable cacheable, Caching caching, CacheConfig cacheConfig) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); // Cacheable if (cacheable != null) &#123; String[] cacheNames = cacheable.cacheNames(); if (cacheNames.length &gt; 0) &#123; list.addAll(Arrays.asList(cacheNames)); &#125; &#125; if (list.size() &gt; 0) &#123; return list; &#125; // Caching if (caching != null) &#123; Cacheable[] cacheables = caching.cacheable(); for (Cacheable cache : cacheables) &#123; String[] cacheNames = cache.cacheNames(); if (cacheNames.length &gt; 0) &#123; list.addAll(Arrays.asList(cacheNames)); &#125; &#125; &#125; if (list.size() &gt; 0) &#123; return list; &#125; // CacheConfig if (cacheConfig != null) &#123; String[] cacheNames = cacheConfig.cacheNames(); if (cacheNames.length &gt; 0) &#123; list.addAll(Arrays.asList(cacheNames)); &#125; &#125; return list; &#125;&#125; Redis相关Bean初始化123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139import com.alibaba.fastjson.support.spring.GenericFastJsonRedisSerializer;import lombok.extern.slf4j.Slf4j;import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;import org.springframework.boot.autoconfigure.data.redis.RedisProperties;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.cache.CacheManager;import org.springframework.cache.annotation.CachingConfigurerSupport;import org.springframework.cache.annotation.EnableCaching;import org.springframework.cache.interceptor.KeyGenerator;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.connection.jedis.JedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.StringRedisSerializer;import redis.clients.jedis.JedisPoolConfig;/** * 初始化 Redis 相关 Bean * &lt;pre&gt; * support spring-data-redis 1.8.10.RELEASE * not support spring-data-redis 2.0.0.RELEASE + * &lt;/pre&gt; * * @author Created by YL on 2017/12/6 */@Configuration// 如果 application.properties、application.yml 中没有 spring.redis.host 配置，则不初始化这些 Bean@ConditionalOnProperty(name = "spring.redis.host")@EnableConfigurationProperties(RedisProperties.class)@EnableCaching(proxyTargetClass = true) // 加上这个注解是为了支持 @Cacheable、@CachePut、@CacheEvict 等缓存注解@Slf4jpublic class CustomJedisAutoConfiguration extends CachingConfigurerSupport &#123; private final RedisConnectionFactory redisConnectionFactory; CustomJedisAutoConfiguration(RedisConnectionFactory redisConnectionFactory) &#123; this.redisConnectionFactory = redisConnectionFactory; &#125; private static final StringRedisSerializer SERIALIZER = new StringRedisSerializer(); /** * fastjson serializer * &lt;pre&gt; * 使用 FastJsonRedisSerializer 会报错：java.lang.ClassCastException * FastJsonRedisSerializer&lt;Object&gt; fastSerializer = new FastJsonRedisSerializer&lt;&gt;(Object.class); * &lt;/pre&gt; */ private static final GenericFastJsonRedisSerializer FAST_SERIALIZER = new GenericFastJsonRedisSerializer(); /** * 配置 RedisTemplate，设置序列化器 * &lt;pre&gt; * 在类里面配置 RestTemplate，需要配置 key 和 value 的序列化类。 * key 序列化使用 StringRedisSerializer, 不配置的话，key 会出现乱码。 * &lt;/pre&gt; */ @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate() &#123; RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;(); // set key serializer // 设置key序列化类，否则key前面会多了一些乱码 template.setKeySerializer(SERIALIZER); template.setHashKeySerializer(SERIALIZER); // fastjson serializer template.setValueSerializer(FAST_SERIALIZER); template.setHashValueSerializer(FAST_SERIALIZER); // 如果 KeySerializer 或者 ValueSerializer 没有配置，则对应的 KeySerializer、ValueSerializer 才使用这个 Serializer template.setDefaultSerializer(FAST_SERIALIZER); JedisConnectionFactory factory = (JedisConnectionFactory) redisConnectionFactory; log.info("spring.redis.database: &#123;&#125;", factory.getDatabase()); log.info("spring.redis.host: &#123;&#125;", factory.getHostName()); log.info("spring.redis.port: &#123;&#125;", factory.getPort()); log.info("spring.redis.timeout: &#123;&#125;", factory.getTimeout()); log.info("spring.redis.password: &#123;&#125;", factory.getPassword()); JedisPoolConfig pool = factory.getPoolConfig(); log.info("spring.redis.use-pool: &#123;&#125;", factory.getUsePool()); log.info("spring.redis.min-idle: &#123;&#125;", pool.getMinIdle()); log.info("spring.redis.max-idle: &#123;&#125;", pool.getMaxIdle()); log.info("spring.redis.max-active: &#123;&#125;", pool.getMaxTotal()); log.info("spring.redis.max-wait: &#123;&#125;", pool.getMaxWaitMillis()); log.info("spring.redis.test-on-borrow: &#123;&#125;", pool.getTestOnBorrow()); log.info("spring.redis.test-on-create: &#123;&#125;", pool.getTestOnCreate()); log.info("spring.redis.test-while-idle: &#123;&#125;", pool.getTestWhileIdle()); log.info("spring.redis.time-between-eviction-runs-millis: &#123;&#125;", pool .getTimeBetweenEvictionRunsMillis()); template.setConnectionFactory(redisConnectionFactory); template.afterPropertiesSet(); return template; &#125; /** * 如果 @Cacheable、@CachePut、@CacheEvict 等注解没有配置 key，则使用这个自定义 key 生成器 * &lt;pre&gt; * 但自定义了缓存的 key 时，难以保证 key 的唯一性，此时最好指定方法名，比如：@Cacheable(value="", key="&#123;#root.methodName, #id&#125;") * &lt;/pre&gt; */ @Override public KeyGenerator keyGenerator() &#123; return (o, method, objects) -&gt; &#123; StringBuilder sb = new StringBuilder(32); sb.append(o.getClass().getSimpleName()); sb.append("."); sb.append(method.getName()); if (objects.length &gt; 0) &#123; sb.append("#"); &#125; String sp = ""; for (Object object : objects) &#123; sb.append(sp); if (object == null) &#123; sb.append("NULL"); &#125; else &#123; sb.append(object.toString()); &#125; sp = "."; &#125; return sb.toString(); &#125;; &#125; /** * 配置 RedisCacheManager，使用 cache 注解管理 redis 缓存 */ @Bean @Override public CacheManager cacheManager() &#123; CustomJedisCacheManager manager = new CustomJedisCacheManager(redisTemplate()); // manager.setLoadRemoteCachesOnStartup(true); // 如果没有配置过期时间，则使用默认的过期时间：30 min manager.setDefaultExpiration(30 * 60L); // 注 默认会添加 key 前缀以防止两个单独的缓存使用相同的 key，否则 Redis 将存在重复的 key，有可能返回不可用的值。 // 如果创建自己的 RedisCacheManager，强烈建议你保留该配置处于启用状态。 manager.setUsePrefix(true); return manager; &#125;&#125; pom.xml12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;version&gt;&lt;version&gt;1.5.10.RELEASE&lt;/version&gt;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.44&lt;/version&gt;&lt;/dependency&gt; 使用例子123456789101112@Servicepublic class TestService &#123; @Cacheable(value = "test", unless = "#result == null or #result.empty") @CacheExpire(expire = 60) public Map&lt;String, Object&gt; get(String name) &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("id", 123); map.put("name", name); return map; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java、JS版AES加密算法工具类]]></title>
    <url>%2Fposts%2F1f7e0ef5.html</url>
    <content type="text"><![CDATA[[TOC] 本文主要是实现AES算法的Java版本和Javascript版本，并提供测试例子。 AES是一个对称分组密码算法，旨在取代DES成为广泛使用的标准。根据使用的密码长度，AES最常见的有3种方案，用以适应不同的场景要求，分别是AES-128、AES-192和AES-256。 Java中的PKCS5Padding和Javascript中的PKCS7Padding的结果是一样。 Java 版 AES 工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143package top.ylonline.common.util;import javax.crypto.BadPaddingException;import javax.crypto.Cipher;import javax.crypto.IllegalBlockSizeException;import javax.crypto.NoSuchPaddingException;import javax.crypto.spec.SecretKeySpec;import java.io.UnsupportedEncodingException;import java.security.InvalidKeyException;import java.security.NoSuchAlgorithmException;/** * AES 加密、解密 * * @author Created by YL on 2018/2/9 */public enum AESUtils &#123; GBK &#123; public String getCharset() &#123; return "GBK"; &#125; &#125;, UTF8 &#123; public String getCharset() &#123; return "UTF-8"; &#125; &#125;; public static final String AES_KEY = "MHYKD5tes6fhkdv9"; /** * 获取编码 */ public String getCharset() &#123; throw new AbstractMethodError(); &#125; /** * 加密 * * @param str 需要加密的内容 * @param key 加密密码 * * @return 加密后的字符串 */ private byte[] enc(String str, String key) &#123; try &#123; SecretKeySpec skeySpec = new SecretKeySpec(key.getBytes(getCharset()), "AES"); Cipher cipher = Cipher.getInstance("AES/ECB/PKCS5Padding"); cipher.init(Cipher.ENCRYPT_MODE, skeySpec); return cipher.doFinal(str.getBytes(getCharset())); &#125; catch (UnsupportedEncodingException e) &#123; throw new RuntimeException("不支持的编码格式", e); &#125; catch (NoSuchAlgorithmException e) &#123; throw new RuntimeException("不支持的加密算法", e); &#125; catch (NoSuchPaddingException e) &#123; throw new RuntimeException("不支持的填充机制", e); &#125; catch (InvalidKeyException e) &#123; throw new RuntimeException("无效的Key、错误的长度、未初始化等", e); &#125; catch (IllegalBlockSizeException e) &#123; throw new RuntimeException("密码的块大小不匹配", e); &#125; catch (BadPaddingException e) &#123; throw new RuntimeException("输入的数据错误，导致填充机制未能正常填充", e); &#125; &#125; private byte[] dec(byte[] str, String key) &#123; try &#123; SecretKeySpec skeySpec = new SecretKeySpec(key.getBytes(getCharset()), "AES"); Cipher cipher = Cipher.getInstance("AES/ECB/PKCS5Padding"); cipher.init(Cipher.DECRYPT_MODE, skeySpec); return cipher.doFinal(str); &#125; catch (UnsupportedEncodingException e) &#123; throw new RuntimeException("不支持的编码格式", e); &#125; catch (NoSuchAlgorithmException e) &#123; throw new RuntimeException("不支持的加密算法", e); &#125; catch (NoSuchPaddingException e) &#123; throw new RuntimeException("不支持的填充机制", e); &#125; catch (InvalidKeyException e) &#123; throw new RuntimeException("无效的Key、错误的长度、未初始化等", e); &#125; catch (IllegalBlockSizeException e) &#123; throw new RuntimeException("密码的块大小不匹配", e); &#125; catch (BadPaddingException e) &#123; throw new RuntimeException("输入的数据错误，导致填充机制未能正常填充", e); &#125; &#125; /** * AES 加密，使用默认 key 加密 * * @param str 要加密的明文 * * @return 加密后的密文 */ public String encrypt(String str) &#123; return encrypt(str, AESUtils.AES_KEY); &#125; /** * AES加密，使用指定 key 加密 * * @param str 要加密的明文 * @param key 加密 key * * @return 解密后字符串 */ public String encrypt(String str, String key) &#123; byte[] encryptBytes = enc(str, key); return Base64Utils.UTF8.encode(encryptBytes); &#125; /** * AES 解密，使用默认 key 解密 * * @param str 要解密的密文 * * @return 解密后的明文 */ public String decrypt(String str) &#123; return decrypt(str, AESUtils.AES_KEY); &#125; /** * AES 解密，使用默认 key 解密 * * @param str 要解密的密文 * @param key 解密 key * * @return 解密后的明文 */ public String decrypt(String str, String key) &#123; if (str == null || "".equals(str)) &#123; return ""; &#125; byte[] bytes = Base64Utils.UTF8.decode2byte(str); try &#123; return new String(dec(bytes, key), getCharset()); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; return ""; &#125;&#125; Java 版 AES 工具类测试123456789101112131415161718192021package top.ylonline.common.util;import org.junit.Assert;import org.junit.Test;/** * @author Created by YL on 2018/2/13 */public class AESUtilsTest &#123; private static final String KEY = "SYhU9Qf3nmrZAx7D"; private static final String STR = "法拉利_24234slfkjsl《》？：“”｛｝+——"; @Test public void aes() &#123; String encrypt = AESUtils.UTF8.encrypt(STR, KEY); System.out.println("encrypt ---&gt; " + encrypt); String decrypt = AESUtils.UTF8.decrypt(encrypt, KEY); System.out.println(decrypt); Assert.assertEquals(STR, decrypt); &#125;&#125; JS 版 AES 工具类要引入的 js 文件，地址：https://github.com/brix/crypto-js12345&lt;script th:src="@&#123;/crypto-js/core.js&#125;"&gt;&lt;/script&gt;&lt;script th:src="@&#123;/crypto-js/enc-base64.js&#125;"&gt;&lt;/script&gt;&lt;script th:src="@&#123;/crypto-js/cipher-core.js&#125;"&gt;&lt;/script&gt;&lt;script th:src="@&#123;/crypto-js/aes.js&#125;"&gt;&lt;/script&gt;&lt;script th:src="@&#123;/crypto-js/mode-ecb.js&#125;"&gt;&lt;/script&gt; JS 版 AES 工具类扩展123456789101112131415161718192021222324252627282930313233343536function getRandom(len) &#123; var a = len || 16, s = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789', n = s.length; var r = ''; for (var i = 0; i &lt; a; i++) &#123; r += s.charAt(Math.floor(Math.random() * n)); &#125; return r;&#125;function encryptAES(str, key) &#123; var s = CryptoJS.enc.Utf8.parse(str), k = CryptoJS.enc.Utf8.parse(key), c = CryptoJS.AES.encrypt(s, k, &#123; mode: CryptoJS.mode.ECB, padding: CryptoJS.pad.Pkcs7 &#125;), // 转换为字符串 // return c.toString(); // Hex 转为十六进制 d = CryptoJS.enc.Hex.parse(c.ciphertext.toString()); // Base64 编码 return CryptoJS.enc.Base64.stringify(d);&#125;function decryptAES(str, key) &#123; var k = CryptoJS.enc.Utf8.parse(key), c = CryptoJS.AES.decrypt(str, k, &#123; mode: CryptoJS.mode.ECB, padding: CryptoJS.pad.Pkcs7 &#125;); // 转换为 UTF8 字符串 return CryptoJS.enc.Utf8.stringify(c); // return c.toString(CryptoJS.enc.Utf8);&#125; JS 版 AES 工具类测试12345678var key = getRandom();console.log('key: %o', key);var str = '法拉利_24234slfkjsl《》？：“”｛｝+——';console.log('str: %o', str);var e = encryptAES(str, key);console.log('e: %o', e);var d = decryptAES(e, key);console.log('d: %o', d);]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
        <tag>AES</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java、JS版RSA加密算法工具类]]></title>
    <url>%2Fposts%2F5314af17.html</url>
    <content type="text"><![CDATA[[TOC] 本文主要是实现RSA算法的Java版本和Javascript版本，并提供测试例子。 1、RSA算法可以用于数据加密和数字签名 2、RSA算法相对于DES/AES等对称加密算法，他的速度要慢的多 3、使用原则：公钥加密，私钥解密；私钥加密，公钥解密 Java 版 RSA 工具类要引入的 jar 包123456&lt;!-- jdk1.5 ~ jdk1.8 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.bouncycastle&lt;/groupId&gt; &lt;artifactId&gt;bcprov-jdk15on&lt;/artifactId&gt; &lt;version&gt;1.46&lt;/version&gt;&lt;/dependency&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465package top.ylonline.common.util;import org.bouncycastle.jce.provider.BouncyCastleProvider;import javax.crypto.BadPaddingException;import javax.crypto.Cipher;import javax.crypto.IllegalBlockSizeException;import javax.crypto.NoSuchPaddingException;import javax.crypto.ShortBufferException;import java.io.ByteArrayOutputStream;import java.io.IOException;import java.io.UnsupportedEncodingException;import java.math.BigInteger;import java.net.URLDecoder;import java.net.URLEncoder;import java.security.InvalidKeyException;import java.security.Key;import java.security.KeyFactory;import java.security.KeyPair;import java.security.KeyPairGenerator;import java.security.NoSuchAlgorithmException;import java.security.NoSuchProviderException;import java.security.Provider;import java.security.SecureRandom;import java.security.Security;import java.security.interfaces.RSAPrivateKey;import java.security.interfaces.RSAPublicKey;import java.security.spec.InvalidKeySpecException;import java.security.spec.RSAPrivateKeySpec;import java.security.spec.RSAPublicKeySpec;/** * RSA 加解密算法工具 * &lt;pre&gt; * 依赖第三方jar包：bcprov-jdk16-1.46.jar 或者 bcprov-jdk15on-1.46.jar * 记录： * 1、Java Sun 的 security provider 默认：RSA/None/PKCS1Padding * 2、Android 的 security provider 是 Bouncycastle Security provider，默认：RSA/None/NoPadding * 3、Cipher.getInstance("RSA/ECB/NoPadding")，有一个缺点就是解密后的明文比加密之前多了很多空格 * 推荐： * Cipher.getInstance("RSA"，"BC") * &lt;/pre&gt; * &lt;pre&gt; * 一般用法： * 1、私钥加密，公钥解密（服务端加密，客户端解密） * 2、公钥加密，私钥解密（客户端加密，服务端解密） * 注意：私钥不要泄漏出去，客户端一般使用公钥 * &lt;/pre&gt; * * @author Created by YL on 2018/2/9 */public class RSAUtils &#123; // /** // * RSA 最大加密明文大小 // */ // private static final int MAX_ENCRYPT_BLOCK = 117; // // /** // * RSA 最大解密密文大小 // */ // private static final int MAX_DECRYPT_BLOCK = 128; /** * 编码 */ private static final String CHARSET = "UTF-8"; /** * 加密算法 RSA */ private static final String ALGORITHM = "RSA"; /** * 这个值关系到块加密的大小，可以更改，但是不要太大，否则效率会低 */ private static final int KEY_SIZE = 1024; // private static byte[] hexStringToBytes(String hexString) &#123; // if (hexString == null || hexString.equals("")) &#123; // return null; // &#125; // hexString = hexString.toUpperCase(); // int length = hexString.length() / 2; // char[] hexChars = hexString.toCharArray(); // byte[] d = new byte[length]; // for (int i = 0; i &lt; length; i++) &#123; // int pos = i * 2; // d[i] = (byte) (charToByte(hexChars[pos]) &lt;&lt; 4 | charToByte(hexChars[pos + 1])); // &#125; // return d; // &#125; // // /** // * Convert char to byte * @param c char * @return byte // */ // private static byte charToByte(char c) &#123; // return (byte) "0123456789ABCDEF".indexOf(c); // &#125; /** * 把 byte 数组变换为16进制的字符串 * * @param bytes byte 数组 * * @return 16进制的字符串 */ private static String byteToString(byte[] bytes) &#123; StringBuilder sb = new StringBuilder(); for (byte by : bytes) &#123; int d = by; if (d &lt; 0) &#123; d += 256; &#125; if (d &lt; 16) &#123; sb.append("0"); &#125; sb.append(Integer.toString(d, 16)); &#125; return sb.toString(); &#125; /** * 默认的安全服务提供者 */ private static final Provider BC_PROVIDER = new BouncyCastleProvider(); private static final String BC = BouncyCastleProvider.PROVIDER_NAME; private static void addProvider() &#123; String bc = Security.getProperty(BC); if (bc == null || "".equals(bc.trim())) &#123; Security.addProvider(BC_PROVIDER); &#125; &#125; /** * 初始化 RSA，生成密钥对：KeyPair * &lt;pre&gt; * 生成密钥对是非常耗时的，一般要 2s 左右，所以最好缓存密钥对起来，定期去做更新，不用每次都初始化 * &lt;/pre&gt; */ public static KeyPair generateKeyPair() &#123; try &#123; addProvider(); KeyPairGenerator keyPairGen = KeyPairGenerator.getInstance(ALGORITHM, BC); // keysize 这个值关系到块加密的大小，可以更改，但是不要太大，否则效率会低 keyPairGen.initialize(KEY_SIZE, new SecureRandom()); KeyPair keyPair = keyPairGen.generateKeyPair(); System.out.println("init："); System.out.println(keyPair.getPrivate()); System.out.println(keyPair.getPublic()); return keyPair; &#125; catch (NoSuchAlgorithmException e) &#123; throw new RuntimeException("RSA 初始化失败。无此算法", e); &#125; catch (NoSuchProviderException e) &#123; throw new RuntimeException("RSA 初始化失败。无此安全服务提供者", e); &#125; &#125; /** * 使用模（n）、公钥指数（e），还原公钥 * * @param modulus 模（n） * @param publicExponent 公钥指数（e） * * @return RSAPublicKey */ public static RSAPublicKey generatePublicKey(String modulus, String publicExponent) &#123; try &#123; addProvider(); KeyFactory keyFac = KeyFactory.getInstance(ALGORITHM, BC); BigInteger bi1 = new BigInteger(modulus, 16); BigInteger bi2 = new BigInteger(publicExponent, 16); RSAPublicKeySpec pubKeySpec = new RSAPublicKeySpec(bi1, bi2); return (RSAPublicKey) keyFac.generatePublic(pubKeySpec); &#125; catch (InvalidKeySpecException e) &#123; throw new RuntimeException("无效的密钥", e); &#125; catch (NoSuchAlgorithmException e) &#123; throw new RuntimeException("无此算法", e); &#125; catch (NoSuchProviderException e) &#123; throw new RuntimeException("无此安全服务提供者", e); &#125; &#125; /** * * 使用模（n）、私钥指数（d），还原私钥 * * @param modulus 模（n） * @param privateExponent 私钥指数（d） * * @return RSAPrivateKey */ public static RSAPrivateKey generatePrivateKey(String modulus, String privateExponent) &#123; try &#123; addProvider(); KeyFactory keyFac = KeyFactory.getInstance(ALGORITHM, BC); BigInteger bi1 = new BigInteger(modulus, 16); BigInteger bi2 = new BigInteger(privateExponent, 16); RSAPrivateKeySpec priKeySpec = new RSAPrivateKeySpec(bi1, bi2); return (RSAPrivateKey) keyFac.generatePrivate(priKeySpec); &#125; catch (InvalidKeySpecException e) &#123; throw new RuntimeException("无效的密钥", e); &#125; catch (NoSuchAlgorithmException e) &#123; throw new RuntimeException("无此算法", e); &#125; catch (NoSuchProviderException e) &#123; throw new RuntimeException("无此安全服务提供者", e); &#125; &#125; /** * 返回模值n */ public static String getModulus(RSAPublicKey publicKey) &#123; return publicKey.getModulus().toString(16); &#125; /** * 返回模值n */ public static String getModulus(RSAPrivateKey privateKey) &#123; return privateKey.getModulus().toString(16); &#125; /** * 返回公钥指数e */ public static String getPublicExponent(RSAPublicKey publicKey) &#123; return publicKey.getPublicExponent().toString(16); &#125; /** * 返回私钥指数d */ public static String getPrivateExponent(RSAPrivateKey privateKey) &#123; return privateKey.getPrivateExponent().toString(16); &#125; /** * 加密 * * @param key 密钥（公钥、私钥） * @param data 要被加密的明文 * * @return 加密后的数据 */ private static byte[] encrypt(Key key, byte[] data) &#123; try &#123; addProvider(); Cipher cipher = Cipher.getInstance(ALGORITHM, BC); cipher.init(Cipher.ENCRYPT_MODE, key); // 127 int blockSize = cipher.getBlockSize();// 获得加密块大小，如：加密前数据为128个byte，而key_size=1024 // 加密块大小为127 // byte,加密后为128个byte;因此共有2个加密块，第一个127 // byte第二个为1个byte int length = data.length; int outputSize = cipher.getOutputSize(length);// 获得加密块加密后块大小 int leavedSize = length % blockSize; int blocksSize = leavedSize != 0 ? length / blockSize + 1 : length / blockSize; byte[] raw = new byte[outputSize * blocksSize]; int i = 0; while (length - i * blockSize &gt; 0) &#123; /* * 这里面doUpdate方法不可用，查看源代码后发现每次doUpdate后并没有什么实际动作除了把byte[]放到 * ByteArrayOutputStream中，而最后doFinal的时候才将所有的byte[]进行加密，可是到了此时加密块大小很可能已经超出了 * OutputSize所以只好用dofinal方法。 */ if (length - i * blockSize &gt; blockSize) &#123; cipher.doFinal(data, i * blockSize, blockSize, raw, i * outputSize); &#125; else &#123; cipher.doFinal(data, i * blockSize, length - i * blockSize, raw, i * outputSize); &#125; i++; &#125; return raw; &#125; catch (NoSuchAlgorithmException e) &#123; throw new RuntimeException("无此算法", e); &#125; catch (InvalidKeyException e) &#123; throw new RuntimeException("无效的密钥", e); &#125; catch (ShortBufferException e) &#123; throw new RuntimeException("缓冲区异常", e); &#125; catch (NoSuchPaddingException e) &#123; throw new RuntimeException("无此填充方式", e); &#125; catch (BadPaddingException e) &#123; throw new RuntimeException("错误的填充", e); &#125; catch (NoSuchProviderException e) &#123; throw new RuntimeException("无此安全服务提供者", e); &#125; catch (IllegalBlockSizeException e) &#123; throw new RuntimeException("非法的块大小", e); &#125; &#125; /** * 解密 * * @param key 密钥（公钥、私钥） * @param data 要被解密的密文 * * @return 解密后的明文 */ private static byte[] decrypt(Key key, byte[] data) &#123; ByteArrayOutputStream bout = null; try &#123; addProvider(); Cipher cipher = Cipher.getInstance(ALGORITHM, BC); cipher.init(Cipher.DECRYPT_MODE, key); // 128 int blockSize = cipher.getBlockSize(); bout = new ByteArrayOutputStream(64); int i = 0; int length = data.length; while (length - i * blockSize &gt; 0) &#123; bout.write(cipher.doFinal(data, i * blockSize, blockSize)); i++; &#125; return bout.toByteArray(); &#125; catch (BadPaddingException e) &#123; throw new RuntimeException("错误的填充", e); &#125; catch (IOException e) &#123; throw new RuntimeException("IO操作异常", e); &#125; catch (NoSuchAlgorithmException e) &#123; throw new RuntimeException("无此算法", e); &#125; catch (InvalidKeyException e) &#123; throw new RuntimeException("无效的密钥", e); &#125; catch (NoSuchPaddingException e) &#123; throw new RuntimeException("无此填充方式", e); &#125; catch (NoSuchProviderException e) &#123; throw new RuntimeException("无此安全服务提供者", e); &#125; catch (IllegalBlockSizeException e) &#123; throw new RuntimeException("非法的块大小", e); &#125; finally &#123; if (bout != null) &#123; try &#123; bout.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; private static String encrypt(Key pk, String data) &#123; try &#123; data = URLEncoder.encode(data, CHARSET); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; // 处理空格问题：URLEncoder.encode 后，会把空格变成“+”号 if (data.contains("+")) &#123; data = data.replace("+", "%20"); &#125; byte[] b1; try &#123; b1 = data.getBytes(CHARSET); &#125; catch (UnsupportedEncodingException e) &#123; throw new RuntimeException(String.format("不支持的编码格式：%s", CHARSET), e); &#125; byte[] b2 = encrypt(pk, b1); return byteToString(b2); &#125; private static String decrypt(Key pk, String data) &#123; // byte[] b1 = hexStringToBytes(data); byte[] b1 = org.bouncycastle.util.encoders.Hex.decode(data); // 使用 new BigInteger(data, 16).toByteArray() 解密 js 加密的密文有问题，但是解密 java 端的密文确正常 // byte[] b1 = new BigInteger(data, 16).toByteArray(); byte[] b2 = decrypt(pk, b1); String str = new String(b2); // str = new StringBuffer(str).reverse().toString(); if (str.contains("%")) &#123; str = str.replaceAll("%(?![0-9a-fA-F]&#123;2&#125;)", "%25"); &#125; try &#123; return URLDecoder.decode(str, "UTF-8"); &#125; catch (UnsupportedEncodingException e) &#123; throw new RuntimeException(String.format("不支持的编码格式：%s", CHARSET), e); &#125; &#125; /** * 用公钥加密 * * @param pk 公钥 * @param str 要加密的明文 */ public static String encryptPublic(RSAPublicKey pk, String str) &#123; return encrypt(pk, str); &#125; /** * 用公钥加密 * * @param modulus 模 * @param publicExponent 公钥指数 * @param str 要加密的明文 */ public static String encryptPublic(String modulus, String publicExponent, String str) &#123; RSAPublicKey publicKey = generatePublicKey(modulus, publicExponent); return encrypt(publicKey, str); &#125; /** * 用公钥解密 * * @param pk 公钥 * @param str 要解密的密文 */ public static String decryptPublic(RSAPublicKey pk, String str) &#123; return decrypt(pk, str); &#125; /** * 用公钥解密 * * @param modulus 模 * @param publicExponent 公钥指数 * @param str 要解密的密文 */ public static String decryptPublic(String modulus, String publicExponent, String str) &#123; RSAPublicKey publicKey = generatePublicKey(modulus, publicExponent); return decrypt(publicKey, str); &#125; /** * 用私钥加密 * * @param pk 私钥 * @param str 要加密的明文 */ public static String encryptPrivate(RSAPrivateKey pk, String str) &#123; return encrypt(pk, str); &#125; /** * 用私钥加密 * * @param modulus 模 * @param privateExponent 私钥指数 * @param str 要加密的明文 */ public static String encryptPrivate(String modulus, String privateExponent, String str) &#123; RSAPrivateKey privateKey = generatePrivateKey(modulus, privateExponent); return encrypt(privateKey, str); &#125; /** * 用私钥解密 * * @param pk 私钥 * @param str 要解密的密文 */ public static String decryptPrivate(RSAPrivateKey pk, String str) &#123; return decrypt(pk, str); &#125; /** * 用私钥解密 * * @param modulus 模 * @param privateExponent 私钥指数 * @param str 要解密的密文 */ public static String decryptPrivate(String modulus, String privateExponent, String str) &#123; RSAPrivateKey privateKey = generatePrivateKey(modulus, privateExponent); return decrypt(privateKey, str); &#125;&#125; Java 版 RSA 工具类测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146package top.ylonline.common.util;import org.junit.Assert;import org.junit.Before;import org.junit.Test;import java.security.KeyPair;import java.security.interfaces.RSAPrivateKey;import java.security.interfaces.RSAPublicKey;/** * @author Created by YL on 2018/2/11 */public class RSAUtilsTest &#123; private RSAPublicKey publicKey; private RSAPrivateKey privateKey; private RSAPublicKey generatePublicKey; private RSAPrivateKey generatePrivateKey; private static final String str = "test_三地警方随即_1222——《》？“”："; @Before public void init() &#123; KeyPair keyPair = RSAUtils.generateKeyPair(); publicKey = (RSAPublicKey) keyPair.getPublic(); privateKey = (RSAPrivateKey) keyPair.getPrivate(); String modulus = RSAUtils.getModulus(publicKey); String publicExponent = RSAUtils.getPublicExponent(publicKey); String privateExponent = RSAUtils.getPrivateExponent(privateKey); System.out.println("n ---&gt; " + modulus); System.out.println("e ---&gt; " + publicExponent); System.out.println("d ---&gt; " + privateExponent); // 恢复密钥 long time = System.currentTimeMillis(); generatePublicKey = RSAUtils.generatePublicKey(modulus, publicExponent); System.out.println("恢复公钥 ---&gt; " + (System.currentTimeMillis() - time)); time = System.currentTimeMillis(); generatePrivateKey = RSAUtils.generatePrivateKey(modulus, privateExponent); System.out.println("恢复私钥 ---&gt; " + (System.currentTimeMillis() - time)); modulus = RSAUtils.getModulus(generatePublicKey); publicExponent = RSAUtils.getPublicExponent(generatePublicKey); privateExponent = RSAUtils.getPrivateExponent(generatePrivateKey); System.out.println("n ---&gt; " + modulus); System.out.println("e ---&gt; " + publicExponent); System.out.println("d ---&gt; " + privateExponent); &#125; @Test public void all() &#123; String modulus = RSAUtils.getModulus(publicKey); String publicExponent = RSAUtils.getPublicExponent(publicKey); String privateExponent = RSAUtils.getPrivateExponent(privateKey); System.out.println("modulus ---&gt; " + modulus); System.out.println("publicExponent ---&gt; " + publicExponent); System.out.println("privateExponent ---&gt; " + privateExponent); // 私钥加密，公钥解密 System.out.println("-----------------------------------私钥加密，公钥解密-----------------------------------"); String s = RSAUtils.encryptPrivate(privateKey, str); System.out.println("RSA私匙加密：" + s); String s1 = RSAUtils.decryptPublic(publicKey, s); System.out.println("RSA公匙解密：" + s1); Assert.assertEquals(str, s1); System.out.println("--------------------------------------------------------------------------------------"); String ss = RSAUtils.encryptPrivate(modulus, privateExponent, str); System.out.println("RSA私匙加密：" + ss); String ss1 = RSAUtils.decryptPublic(modulus, publicExponent, ss); System.out.println("RSA公匙解密：" + ss1); Assert.assertEquals(str, ss1); // 公钥加密，私钥解密 System.out.println("-----------------------------------私钥加密，私钥解密-----------------------------------"); String s2 = RSAUtils.encryptPublic(publicKey, str); System.out.println("RSA公钥加密：" + s2); String s3 = RSAUtils.decryptPrivate(privateKey, s2); System.out.println("RSA私钥解密：" + s3); Assert.assertEquals(str, s3); System.out.println("--------------------------------------------------------------------------------------"); String ss2 = RSAUtils.encryptPublic(modulus, publicExponent, str); System.out.println("RSA公钥加密：" + ss2); String ss3 = RSAUtils.decryptPrivate(modulus, privateExponent, ss2); System.out.println("RSA私钥解密：" + ss3); Assert.assertEquals(str, ss3); &#125; @Test public void getModulus() &#123; String modulus = RSAUtils.getModulus(publicKey); String modulus1 = RSAUtils.getModulus(generatePublicKey); Assert.assertEquals(modulus, modulus1); String modulus2 = RSAUtils.getModulus(privateKey); String modulus3 = RSAUtils.getModulus(generatePrivateKey); Assert.assertEquals(modulus2, modulus3); &#125; @Test public void getPublicExponent() &#123; String publicExponent = RSAUtils.getPublicExponent(publicKey); String publicExponent1 = RSAUtils.getPublicExponent(generatePublicKey); Assert.assertEquals(publicExponent, publicExponent1); &#125; @Test public void getPrivateExponent() &#123; String privateExponent = RSAUtils.getPrivateExponent(privateKey); String privateExponent1 = RSAUtils.getPrivateExponent(generatePrivateKey); Assert.assertEquals(privateExponent, privateExponent1); &#125; @Test public void encryptPublic() &#123; String s = RSAUtils.encryptPublic(publicKey, str); String s1 = RSAUtils.encryptPublic(generatePublicKey, str); Assert.assertEquals(s, s1); &#125; @Test public void decryptPublic() &#123; String s = RSAUtils.encryptPrivate(privateKey, str); String s1 = RSAUtils.decryptPublic(publicKey, s); String s2 = RSAUtils.decryptPublic(generatePublicKey, s); Assert.assertEquals(s1, s2); &#125; @Test public void encryptPrivate() &#123; String s = RSAUtils.encryptPrivate(privateKey, str); String s1 = RSAUtils.encryptPrivate(generatePrivateKey, str); Assert.assertEquals(s, s1); &#125; @Test public void decryptPrivate() &#123; String s = RSAUtils.encryptPublic(publicKey, str); String s1 = RSAUtils.decryptPrivate(privateKey, s); String s2 = RSAUtils.decryptPrivate(generatePrivateKey, s); Assert.assertEquals(s1, s2); &#125;&#125; JS 版 RSA 工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694/* * RSA, a suite of routines for performing RSA public-key computations in JavaScript. * Copyright 1998-2005 David Shapiro. * Dave Shapiro * dave@ohdave.com * changed by Fuchun, 2010-05-06 * fcrpg2005@gmail.com */;(function($w) &#123; if (typeof $w.RSAUtils === 'undefined') var RSAUtils = $w.RSAUtils = &#123;&#125;; var biRadixBase = 2; var biRadixBits = 16; var bitsPerDigit = biRadixBits; var biRadix = 1 &lt;&lt; 16; // = 2^16 = 65536 var biHalfRadix = biRadix &gt;&gt;&gt; 1; var biRadixSquared = biRadix * biRadix; var maxDigitVal = biRadix - 1; var maxInteger = 9999999999999998; //maxDigits: //Change this to accommodate your largest number size. Use setMaxDigits() //to change it! // //In general, if you're working with numbers of size N bits, you'll need 2*N //bits of storage. Each digit holds 16 bits. So, a 1024-bit key will need // //1024 * 2 / 16 = 128 digits of storage. // var maxDigits; var ZERO_ARRAY; var bigZero, bigOne; var BigInt = $w.BigInt = function(flag) &#123; if (typeof flag == "boolean" &amp;&amp; flag == true) &#123; this.digits = null; &#125; else &#123; this.digits = ZERO_ARRAY.slice(0); &#125; this.isNeg = false; &#125;; RSAUtils.setMaxDigits = function(value) &#123; maxDigits = value; ZERO_ARRAY = new Array(maxDigits); for (var iza = 0; iza &lt; ZERO_ARRAY.length; iza++) ZERO_ARRAY[iza] = 0; bigZero = new BigInt(); bigOne = new BigInt(); bigOne.digits[0] = 1; &#125;; RSAUtils.setMaxDigits(20); //The maximum number of digits in base 10 you can convert to an //integer without JavaScript throwing up on you. var dpl10 = 15; RSAUtils.biFromNumber = function(i) &#123; var result = new BigInt(); result.isNeg = i &lt; 0; i = Math.abs(i); var j = 0; while (i &gt; 0) &#123; result.digits[j++] = i &amp; maxDigitVal; i = Math.floor(i / biRadix); &#125; return result; &#125;; //lr10 = 10 ^ dpl10 var lr10 = RSAUtils.biFromNumber(1000000000000000); RSAUtils.biFromDecimal = function(s) &#123; var isNeg = s.charAt(0) == '-'; var i = isNeg ? 1 : 0; var result; // Skip leading zeros. while (i &lt; s.length &amp;&amp; s.charAt(i) == '0') ++i; if (i == s.length) &#123; result = new BigInt(); &#125; else &#123; var digitCount = s.length - i; var fgl = digitCount % dpl10; if (fgl == 0) fgl = dpl10; result = RSAUtils.biFromNumber(Number(s.substr(i, fgl))); i += fgl; while (i &lt; s.length) &#123; result = RSAUtils.biAdd(RSAUtils.biMultiply(result, lr10), RSAUtils.biFromNumber(Number(s.substr(i, dpl10)))); i += dpl10; &#125; result.isNeg = isNeg; &#125; return result; &#125;; RSAUtils.biCopy = function(bi) &#123; var result = new BigInt(true); result.digits = bi.digits.slice(0); result.isNeg = bi.isNeg; return result; &#125;; RSAUtils.reverseStr = function(s) &#123; var result = ""; for (var i = s.length - 1; i &gt; -1; --i) &#123; result += s.charAt(i); &#125; return result; &#125;; var hexatrigesimalToChar = [ '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z' ]; RSAUtils.biToString = function(x, radix) &#123; // 2 &lt;= radix &lt;= 36 var b = new BigInt(); b.digits[0] = radix; var qr = RSAUtils.biDivideModulo(x, b); var result = hexatrigesimalToChar[qr[1].digits[0]]; while (RSAUtils.biCompare(qr[0], bigZero) == 1) &#123; qr = RSAUtils.biDivideModulo(qr[0], b); digit = qr[1].digits[0]; result += hexatrigesimalToChar[qr[1].digits[0]]; &#125; return (x.isNeg ? "-" : "") + RSAUtils.reverseStr(result); &#125;; RSAUtils.biToDecimal = function(x) &#123; var b = new BigInt(); b.digits[0] = 10; var qr = RSAUtils.biDivideModulo(x, b); var result = String(qr[1].digits[0]); while (RSAUtils.biCompare(qr[0], bigZero) == 1) &#123; qr = RSAUtils.biDivideModulo(qr[0], b); result += String(qr[1].digits[0]); &#125; return (x.isNeg ? "-" : "") + RSAUtils.reverseStr(result); &#125;; var hexToChar = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f' ]; RSAUtils.digitToHex = function(n) &#123; var mask = 0xf; var result = ""; for (i = 0; i &lt; 4; ++i) &#123; result += hexToChar[n &amp; mask]; n &gt;&gt;&gt;= 4; &#125; return RSAUtils.reverseStr(result); &#125;; RSAUtils.biToHex = function(x) &#123; var result = ""; var n = RSAUtils.biHighIndex(x); for (var i = RSAUtils.biHighIndex(x); i &gt; -1; --i) &#123; result += RSAUtils.digitToHex(x.digits[i]); &#125; return result; &#125;; RSAUtils.charToHex = function(c) &#123; var ZERO = 48; var NINE = ZERO + 9; var littleA = 97; var littleZ = littleA + 25; var bigA = 65; var bigZ = 65 + 25; var result; if (c &gt;= ZERO &amp;&amp; c &lt;= NINE) &#123; result = c - ZERO; &#125; else if (c &gt;= bigA &amp;&amp; c &lt;= bigZ) &#123; result = 10 + c - bigA; &#125; else if (c &gt;= littleA &amp;&amp; c &lt;= littleZ) &#123; result = 10 + c - littleA; &#125; else &#123; result = 0; &#125; return result; &#125;; RSAUtils.hexToDigit = function(s) &#123; var result = 0; var sl = Math.min(s.length, 4); for (var i = 0; i &lt; sl; ++i) &#123; result &lt;&lt;= 4; result |= RSAUtils.charToHex(s.charCodeAt(i)); &#125; return result; &#125;; RSAUtils.biFromHex = function(s) &#123; var result = new BigInt(); var sl = s.length; for (var i = sl, j = 0; i &gt; 0; i -= 4, ++j) &#123; result.digits[j] = RSAUtils.hexToDigit(s.substr(Math.max(i - 4, 0), Math.min(i, 4))); &#125; return result; &#125;; RSAUtils.biFromString = function(s, radix) &#123; var isNeg = s.charAt(0) == '-'; var istop = isNeg ? 1 : 0; var result = new BigInt(); var place = new BigInt(); place.digits[0] = 1; // radix^0 for (var i = s.length - 1; i &gt;= istop; i--) &#123; var c = s.charCodeAt(i); var digit = RSAUtils.charToHex(c); var biDigit = RSAUtils.biMultiplyDigit(place, digit); result = RSAUtils.biAdd(result, biDigit); place = RSAUtils.biMultiplyDigit(place, radix); &#125; result.isNeg = isNeg; return result; &#125;; RSAUtils.biDump = function(b) &#123; return (b.isNeg ? "-" : "") + b.digits.join(" "); &#125;; RSAUtils.biAdd = function(x, y) &#123; var result; if (x.isNeg != y.isNeg) &#123; y.isNeg = !y.isNeg; result = RSAUtils.biSubtract(x, y); y.isNeg = !y.isNeg; &#125; else &#123; result = new BigInt(); var c = 0; var n; for (var i = 0; i &lt; x.digits.length; ++i) &#123; n = x.digits[i] + y.digits[i] + c; result.digits[i] = n % biRadix; c = Number(n &gt;= biRadix); &#125; result.isNeg = x.isNeg; &#125; return result; &#125;; RSAUtils.biSubtract = function(x, y) &#123; var result; if (x.isNeg != y.isNeg) &#123; y.isNeg = !y.isNeg; result = RSAUtils.biAdd(x, y); y.isNeg = !y.isNeg; &#125; else &#123; result = new BigInt(); var n, c; c = 0; for (var i = 0; i &lt; x.digits.length; ++i) &#123; n = x.digits[i] - y.digits[i] + c; result.digits[i] = n % biRadix; // Stupid non-conforming modulus operation. if (result.digits[i] &lt; 0) result.digits[i] += biRadix; c = 0 - Number(n &lt; 0); &#125; // Fix up the negative sign, if any. if (c == -1) &#123; c = 0; for (var i = 0; i &lt; x.digits.length; ++i) &#123; n = 0 - result.digits[i] + c; result.digits[i] = n % biRadix; // Stupid non-conforming modulus operation. if (result.digits[i] &lt; 0) result.digits[i] += biRadix; c = 0 - Number(n &lt; 0); &#125; // Result is opposite sign of arguments. result.isNeg = !x.isNeg; &#125; else &#123; // Result is same sign. result.isNeg = x.isNeg; &#125; &#125; return result; &#125;; RSAUtils.biHighIndex = function(x) &#123; var result = x.digits.length - 1; while (result &gt; 0 &amp;&amp; x.digits[result] == 0) --result; return result; &#125;; RSAUtils.biNumBits = function(x) &#123; var n = RSAUtils.biHighIndex(x); var d = x.digits[n]; var m = (n + 1) * bitsPerDigit; var result; for (result = m; result &gt; m - bitsPerDigit; --result) &#123; if ((d &amp; 0x8000) != 0) break; d &lt;&lt;= 1; &#125; return result; &#125;; RSAUtils.biMultiply = function(x, y) &#123; var result = new BigInt(); var c; var n = RSAUtils.biHighIndex(x); var t = RSAUtils.biHighIndex(y); var u, uv, k; for (var i = 0; i &lt;= t; ++i) &#123; c = 0; k = i; for (j = 0; j &lt;= n; ++j, ++k) &#123; uv = result.digits[k] + x.digits[j] * y.digits[i] + c; result.digits[k] = uv &amp; maxDigitVal; c = uv &gt;&gt;&gt; biRadixBits; //c = Math.floor(uv / biRadix); &#125; result.digits[i + n + 1] = c; &#125; // Someone give me a logical xor, please. result.isNeg = x.isNeg != y.isNeg; return result; &#125;; RSAUtils.biMultiplyDigit = function(x, y) &#123; var n, c, uv; result = new BigInt(); n = RSAUtils.biHighIndex(x); c = 0; for (var j = 0; j &lt;= n; ++j) &#123; uv = result.digits[j] + x.digits[j] * y + c; result.digits[j] = uv &amp; maxDigitVal; c = uv &gt;&gt;&gt; biRadixBits; //c = Math.floor(uv / biRadix); &#125; result.digits[1 + n] = c; return result; &#125;; RSAUtils.arrayCopy = function(src, srcStart, dest, destStart, n) &#123; var m = Math.min(srcStart + n, src.length); for (var i = srcStart, j = destStart; i &lt; m; ++i, ++j) &#123; dest[j] = src[i]; &#125; &#125;; var highBitMasks = [0x0000, 0x8000, 0xC000, 0xE000, 0xF000, 0xF800, 0xFC00, 0xFE00, 0xFF00, 0xFF80, 0xFFC0, 0xFFE0, 0xFFF0, 0xFFF8, 0xFFFC, 0xFFFE, 0xFFFF ]; RSAUtils.biShiftLeft = function(x, n) &#123; var digitCount = Math.floor(n / bitsPerDigit); var result = new BigInt(); RSAUtils.arrayCopy(x.digits, 0, result.digits, digitCount, result.digits.length - digitCount); var bits = n % bitsPerDigit; var rightBits = bitsPerDigit - bits; for (var i = result.digits.length - 1, i1 = i - 1; i &gt; 0; --i, --i1) &#123; result.digits[i] = ((result.digits[i] &lt;&lt; bits) &amp; maxDigitVal) | ((result.digits[i1] &amp; highBitMasks[bits]) &gt;&gt;&gt; (rightBits)); &#125; result.digits[0] = ((result.digits[i] &lt;&lt; bits) &amp; maxDigitVal); result.isNeg = x.isNeg; return result; &#125;; var lowBitMasks = [0x0000, 0x0001, 0x0003, 0x0007, 0x000F, 0x001F, 0x003F, 0x007F, 0x00FF, 0x01FF, 0x03FF, 0x07FF, 0x0FFF, 0x1FFF, 0x3FFF, 0x7FFF, 0xFFFF ]; RSAUtils.biShiftRight = function(x, n) &#123; var digitCount = Math.floor(n / bitsPerDigit); var result = new BigInt(); RSAUtils.arrayCopy(x.digits, digitCount, result.digits, 0, x.digits.length - digitCount); var bits = n % bitsPerDigit; var leftBits = bitsPerDigit - bits; for (var i = 0, i1 = i + 1; i &lt; result.digits.length - 1; ++i, ++i1) &#123; result.digits[i] = (result.digits[i] &gt;&gt;&gt; bits) | ((result.digits[i1] &amp; lowBitMasks[bits]) &lt;&lt; leftBits); &#125; result.digits[result.digits.length - 1] &gt;&gt;&gt;= bits; result.isNeg = x.isNeg; return result; &#125;; RSAUtils.biMultiplyByRadixPower = function(x, n) &#123; var result = new BigInt(); RSAUtils.arrayCopy(x.digits, 0, result.digits, n, result.digits.length - n); return result; &#125;; RSAUtils.biDivideByRadixPower = function(x, n) &#123; var result = new BigInt(); RSAUtils.arrayCopy(x.digits, n, result.digits, 0, result.digits.length - n); return result; &#125;; RSAUtils.biModuloByRadixPower = function(x, n) &#123; var result = new BigInt(); RSAUtils.arrayCopy(x.digits, 0, result.digits, 0, n); return result; &#125;; RSAUtils.biCompare = function(x, y) &#123; if (x.isNeg != y.isNeg) &#123; return 1 - 2 * Number(x.isNeg); &#125; for (var i = x.digits.length - 1; i &gt;= 0; --i) &#123; if (x.digits[i] != y.digits[i]) &#123; if (x.isNeg) &#123; return 1 - 2 * Number(x.digits[i] &gt; y.digits[i]); &#125; else &#123; return 1 - 2 * Number(x.digits[i] &lt; y.digits[i]); &#125; &#125; &#125; return 0; &#125;; RSAUtils.biDivideModulo = function(x, y) &#123; var nb = RSAUtils.biNumBits(x); var tb = RSAUtils.biNumBits(y); var origYIsNeg = y.isNeg; var q, r; if (nb &lt; tb) &#123; // |x| &lt; |y| if (x.isNeg) &#123; q = RSAUtils.biCopy(bigOne); q.isNeg = !y.isNeg; x.isNeg = false; y.isNeg = false; r = biSubtract(y, x); // Restore signs, 'cause they're references. x.isNeg = true; y.isNeg = origYIsNeg; &#125; else &#123; q = new BigInt(); r = RSAUtils.biCopy(x); &#125; return [q, r]; &#125; q = new BigInt(); r = x; // Normalize Y. var t = Math.ceil(tb / bitsPerDigit) - 1; var lambda = 0; while (y.digits[t] &lt; biHalfRadix) &#123; y = RSAUtils.biShiftLeft(y, 1); ++lambda; ++tb; t = Math.ceil(tb / bitsPerDigit) - 1; &#125; // Shift r over to keep the quotient constant. We'll shift the // remainder back at the end. r = RSAUtils.biShiftLeft(r, lambda); nb += lambda; // Update the bit count for x. var n = Math.ceil(nb / bitsPerDigit) - 1; var b = RSAUtils.biMultiplyByRadixPower(y, n - t); while (RSAUtils.biCompare(r, b) != -1) &#123; ++q.digits[n - t]; r = RSAUtils.biSubtract(r, b); &#125; for (var i = n; i &gt; t; --i) &#123; var ri = (i &gt;= r.digits.length) ? 0 : r.digits[i]; var ri1 = (i - 1 &gt;= r.digits.length) ? 0 : r.digits[i - 1]; var ri2 = (i - 2 &gt;= r.digits.length) ? 0 : r.digits[i - 2]; var yt = (t &gt;= y.digits.length) ? 0 : y.digits[t]; var yt1 = (t - 1 &gt;= y.digits.length) ? 0 : y.digits[t - 1]; if (ri == yt) &#123; q.digits[i - t - 1] = maxDigitVal; &#125; else &#123; q.digits[i - t - 1] = Math.floor((ri * biRadix + ri1) / yt); &#125; var c1 = q.digits[i - t - 1] * ((yt * biRadix) + yt1); var c2 = (ri * biRadixSquared) + ((ri1 * biRadix) + ri2); while (c1 &gt; c2) &#123; --q.digits[i - t - 1]; c1 = q.digits[i - t - 1] * ((yt * biRadix) | yt1); c2 = (ri * biRadix * biRadix) + ((ri1 * biRadix) + ri2); &#125; b = RSAUtils.biMultiplyByRadixPower(y, i - t - 1); r = RSAUtils.biSubtract(r, RSAUtils.biMultiplyDigit(b, q.digits[i - t - 1])); if (r.isNeg) &#123; r = RSAUtils.biAdd(r, b); --q.digits[i - t - 1]; &#125; &#125; r = RSAUtils.biShiftRight(r, lambda); // Fiddle with the signs and stuff to make sure that 0 &lt;= r &lt; y. q.isNeg = x.isNeg != origYIsNeg; if (x.isNeg) &#123; if (origYIsNeg) &#123; q = RSAUtils.biAdd(q, bigOne); &#125; else &#123; q = RSAUtils.biSubtract(q, bigOne); &#125; y = RSAUtils.biShiftRight(y, lambda); r = RSAUtils.biSubtract(y, r); &#125; // Check for the unbelievably stupid degenerate case of r == -0. if (r.digits[0] == 0 &amp;&amp; RSAUtils.biHighIndex(r) == 0) r.isNeg = false; return [q, r]; &#125;; RSAUtils.biDivide = function(x, y) &#123; return RSAUtils.biDivideModulo(x, y)[0]; &#125;; RSAUtils.biModulo = function(x, y) &#123; return RSAUtils.biDivideModulo(x, y)[1]; &#125;; RSAUtils.biMultiplyMod = function(x, y, m) &#123; return RSAUtils.biModulo(RSAUtils.biMultiply(x, y), m); &#125;; RSAUtils.biPow = function(x, y) &#123; var result = bigOne; var a = x; while (true) &#123; if ((y &amp; 1) != 0) result = RSAUtils.biMultiply(result, a); y &gt;&gt;= 1; if (y == 0) break; a = RSAUtils.biMultiply(a, a); &#125; return result; &#125;; RSAUtils.biPowMod = function(x, y, m) &#123; var result = bigOne; var a = x; var k = y; while (true) &#123; if ((k.digits[0] &amp; 1) != 0) result = RSAUtils.biMultiplyMod(result, a, m); k = RSAUtils.biShiftRight(k, 1); if (k.digits[0] == 0 &amp;&amp; RSAUtils.biHighIndex(k) == 0) break; a = RSAUtils.biMultiplyMod(a, a, m); &#125; return result; &#125;; $w.BarrettMu = function(m) &#123; this.modulus = RSAUtils.biCopy(m); this.k = RSAUtils.biHighIndex(this.modulus) + 1; var b2k = new BigInt(); b2k.digits[2 * this.k] = 1; // b2k = b^(2k) this.mu = RSAUtils.biDivide(b2k, this.modulus); this.bkplus1 = new BigInt(); this.bkplus1.digits[this.k + 1] = 1; // bkplus1 = b^(k+1) this.modulo = BarrettMu_modulo; this.multiplyMod = BarrettMu_multiplyMod; this.powMod = BarrettMu_powMod; &#125;; function BarrettMu_modulo(x) &#123; var $dmath = RSAUtils; var q1 = $dmath.biDivideByRadixPower(x, this.k - 1); var q2 = $dmath.biMultiply(q1, this.mu); var q3 = $dmath.biDivideByRadixPower(q2, this.k + 1); var r1 = $dmath.biModuloByRadixPower(x, this.k + 1); var r2term = $dmath.biMultiply(q3, this.modulus); var r2 = $dmath.biModuloByRadixPower(r2term, this.k + 1); var r = $dmath.biSubtract(r1, r2); if (r.isNeg) &#123; r = $dmath.biAdd(r, this.bkplus1); &#125; var rgtem = $dmath.biCompare(r, this.modulus) &gt;= 0; while (rgtem) &#123; r = $dmath.biSubtract(r, this.modulus); rgtem = $dmath.biCompare(r, this.modulus) &gt;= 0; &#125; return r; &#125; function BarrettMu_multiplyMod(x, y) &#123; /* x = this.modulo(x); y = this.modulo(y); */ var xy = RSAUtils.biMultiply(x, y); return this.modulo(xy); &#125; function BarrettMu_powMod(x, y) &#123; var result = new BigInt(); result.digits[0] = 1; var a = x; var k = y; while (true) &#123; if ((k.digits[0] &amp; 1) != 0) result = this.multiplyMod(result, a); k = RSAUtils.biShiftRight(k, 1); if (k.digits[0] == 0 &amp;&amp; RSAUtils.biHighIndex(k) == 0) break; a = this.multiplyMod(a, a); &#125; return result; &#125; var RSAKeyPair = function(encryptionExponent, decryptionExponent, modulus) &#123; var $dmath = RSAUtils; this.e = $dmath.biFromHex(encryptionExponent); this.d = $dmath.biFromHex(decryptionExponent); this.m = $dmath.biFromHex(modulus); // We can do two bytes per digit, so // chunkSize = 2 * (number of digits in modulus - 1). // Since biHighIndex returns the high index, not the number of digits, 1 has // already been subtracted. this.chunkSize = 2 * $dmath.biHighIndex(this.m); this.radix = 16; this.barrett = new $w.BarrettMu(this.m); &#125;; RSAUtils.getKeyPair = function(encryptionExponent, decryptionExponent, modulus) &#123; return new RSAKeyPair(encryptionExponent, decryptionExponent, modulus); &#125;; if (typeof $w.twoDigit === 'undefined') &#123; $w.twoDigit = function(n) &#123; return (n &lt; 10 ? "0" : "") + String(n); &#125;; &#125; // Altered by Rob Saunders (rob@robsaunders.net). New routine pads the // string after it has been converted to an array. This fixes an // incompatibility with Flash MX's ActionScript. RSAUtils.encryptedString = function(key, s) &#123; var a = []; var sl = s.length; var i = 0; while (i &lt; sl) &#123; a[i] = s.charCodeAt(i); i++; &#125; while (a.length % key.chunkSize != 0) &#123; a[i++] = 0; &#125; var al = a.length; var result = ""; var j, k, block; for (i = 0; i &lt; al; i += key.chunkSize) &#123; block = new BigInt(); j = 0; for (k = i; k &lt; i + key.chunkSize; ++j) &#123; block.digits[j] = a[k++]; block.digits[j] += a[k++] &lt;&lt; 8; &#125; var crypt = key.barrett.powMod(block, key.e); var text = key.radix == 16 ? RSAUtils.biToHex(crypt) : RSAUtils.biToString(crypt, key.radix); result += text + " "; &#125; return result.substring(0, result.length - 1); // Remove last space. &#125;; RSAUtils.decryptedString = function(key, s) &#123; var blocks = s.split(" "); var result = ""; var i, j, block; for (i = 0; i &lt; blocks.length; ++i) &#123; var bi; if (key.radix == 16) &#123; bi = RSAUtils.biFromHex(blocks[i]); &#125; else &#123; bi = RSAUtils.biFromString(blocks[i], key.radix); &#125; block = key.barrett.powMod(bi, key.d); for (j = 0; j &lt;= RSAUtils.biHighIndex(block); ++j) &#123; result += String.fromCharCode(block.digits[j] &amp; 255, block.digits[j] &gt;&gt; 8); &#125; &#125; // Remove trailing null, if any. if (result.charCodeAt(result.length - 1) == 0) &#123; result = result.substring(0, result.length - 1); &#125; return result; &#125;; RSAUtils.setMaxDigits(130);&#125;)(window); JS 版 RSA 工具类扩展12345678910111213141516171819202122232425262728293031/** * RSA 加密数据：返回加密后的字符串 * &lt;p&gt;e 公匙 * &lt;p&gt;n 模 * &lt;p&gt;s 要加密的字符串 */function encryptRSA(e, n, s) &#123; RSAUtils.setMaxDigits(130); var keyPair = RSAUtils.getKeyPair(e, '', n); // URI 编码 s = window.encodeURIComponent(s); // 反转 s = s.split("").reverse().join(""); return RSAUtils.encryptedString(keyPair, s);&#125;/** * RSA 解密数据：返回解密后的字符串 * &lt;p&gt;e 公匙 * &lt;p&gt;n 模 * &lt;p&gt;s 要解密的字符串 */function decryptRSA(e, n, s) &#123; RSAUtils.setMaxDigits(130); var keyPair = RSAUtils.getKeyPair('', e, n); s = RSAUtils.decryptedString(keyPair, s); // 反转 s = s.split("").reverse().join(""); // URI 解码 return window.decodeURIComponent(s);&#125; JS 版 RSA 工具类测试1234567891011121314151617181920212223var n = 'e1eb7ab440eb2b3413146dc64c66b4047c7d035712201f944dc092d6d65fb6496c27bb6984477e9d4d683cfe28f06e03efdbe28e92134071f5867adb5789d3b076b79bba167a710197ef7f47894f1d3737e4bf5dd33a7db4de67eebbd85f72f7fd681f17f03a30575d613df6ed682fd324e12ec14bd17cc2b667f7536d8db137';var e = '10001';// 一般客户端不要传私钥，这里是为了测试var d = '9316ca9c034c59a39cec87103d7bfca6931a9d8b1a0cfa228780e2d9a757478a8435562abbea04808bfe5affab4de682ffaeacd1e03f528d1faaffe0411d4649fb2e691f0eea759f609b26e04e86419e4e2c628da8ea54168999d744fd611aa1f3c67ceba4a87a289e251dc1dbdd91448d996971dd6daf5804843fe4d0776091';var encrypt = '651e45bc3f35e766cb2397eef719401a88b6177fc1e566f97d24bf22398aad87b00e82a55cd70520172abd7e8d70a452ef22ce0c5a2477ea61f9430fa94c0913753f18781868bdb730fb78b812461884db72a2211ec681780bd7143d7fd0dddff81be42b887cf6fd70c2cad7a845f93bd79563dc60bb94b85610230cbb327c55';console.log('------------- 服务端私钥加密，客户端公钥解密 -------------');decryptR = decryptRSA(e, n, encrypt);console.log('decryptR: %o', decryptR);console.log('------------- 公钥加密，私钥解密 -------------');var str = '客户端 - 法拉利_123_abc_《》';console.log('str: %o', str);var encryptR = encryptRSA(e, n, str);console.log('encryptR: %o', encryptR);var decryptR = decryptRSA(d, n, encryptR);console.log('decryptR: %o', decryptR);console.log('------------- 私钥加密，公钥解密 -------------');console.log('str: %o', str);encryptR = encryptRSA(d, n, str);console.log('encryptR: %o', encryptR);decryptR = decryptRSA(e, n, encryptR);console.log('decryptR: %o', decryptR);]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
        <tag>RSA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo github ignorecase]]></title>
    <url>%2Fposts%2F18219b06.html</url>
    <content type="text"><![CDATA[Hexo 部署到 Github Pages 文件夹大小写问题问题使用 Hexo 部署博客到 Github Pages 时经常会遇到文件夹大小写问题导致的 404问题。 例如 Hexo 生成了一个 javasccript Category文件夹，但是我后来把它改成了 Javasccript，即 javasccript 的首字母大写了。Hexo会生成正确，但部署到 Github 上却老是不正确。 原因git 默认忽略文件名大小写，所以即使文件夹大小写变更，git 也检测不到。 解决办法1、进入到博客项目中 .deploy_git文件夹，修改 .git 下的 config 文件，将 ignorecase=true 改为 ignorecase=false12cd ./deploy_git/.gitvi config 2、删除博客项目中 .deploy_git 文件夹下的所有文件，并 push 到 Github 上, 这一步是清空你的 github.io 项目中所有文件。1234cd ./deploy_git/git rm -rf *git commit -m 'clean'git push 3、使用 Hexo 再次生成及部署123cd ..hexo clean &amp;&amp; hexo d -g# hexo clean &amp;&amp; hexo g &amp;&amp; hexo d]]></content>
      <categories>
        <category>hexo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[zookeeper stop脚本]]></title>
    <url>%2Fposts%2F7bd064dc.html</url>
    <content type="text"><![CDATA[stop12345678910#!/usr/bin/env bash# @Author: YL# @Date: 2017-06-29 09:00:00# @Last Modified by: YL# @Last Modified time: 2017-11-01 09:37:49# 此文件放到 zookeeper 的 bin 目录下cd `dirname $0`./zkServer.sh stop]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux lsof 命令]]></title>
    <url>%2Fposts%2Ffc091577.html</url>
    <content type="text"><![CDATA[lsof检测端口未被占用1lsof -i:&lt;port&gt; 指定进程号，可以查看该进程打开的文件 1lsof -p &lt;pid&gt;]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>lsof</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux sed 命令]]></title>
    <url>%2Fposts%2Fb8ec468d.html</url>
    <content type="text"><![CDATA[sed打印指定行数1sed -n '12457431, 12457440p' tomcat/logs/catalina.out]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>sed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux tail 命令]]></title>
    <url>%2Fposts%2F29bd046e.html</url>
    <content type="text"><![CDATA[tail]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>tail</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux tar 命令]]></title>
    <url>%2Fposts%2Fbd083454.html</url>
    <content type="text"><![CDATA[tar 解压 1tar -zxvf xxx.tar.gz 打包 1tar -zcvf xxx.tar.gz 待压缩的文件名 解压 tar zxvf 文件名.tar.gz 压缩 tar zcvf 文件名.tar.gz 待压缩的文件名 tar -zcvf tomcat.tar.gz –exclude=.log –exclude=.log. –exclude=.out –exclude=.out. –exclude=.tgz.bak –exclude=.war tomcat/ 排除文件夹（注意排除的文件夹最后不能加/） tar -zcvf gitlab.source.tar.gz –exclude=node_modules –exclude=target gitlab/]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>tar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux ls 命令]]></title>
    <url>%2Fposts%2F53b5960c.html</url>
    <content type="text"><![CDATA[ls12# 统计文件夹中文件数ls -l |grep "^-"|wc -l 保留最新的1个文件夹，删除其他文件夹（使用-d）1ls -t -d /home/yl/api-web-open/logs/undertow-* | tail -n +2 | xargs rm -rf]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>ls</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper 启动脚本]]></title>
    <url>%2Fposts%2Faf01b9a2.html</url>
    <content type="text"><![CDATA[start12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#!/usr/bin/env bash# @Author: YL# @Date: 2017-06-28 10:23:20# @Last Modified by: YL# @Last Modified time: 2017-11-01 09:37:41# 此文件放到 zookeeper 的 bin 目录下cd `dirname $0`NODE_BIN_DIR=`pwd`NODE_LIB_DIR=$NODE_BIN_DIR/../lib/cd ..NODE_HOME=`pwd`# mkdir logs dirNODE_DATA_LOG_DIR=`sed '/dataLogDir/!d;s/.*=//' conf/zoo.cfg | tr -d '\r'`NODE_LOGS_DIR=""if [ -n "$NODE_DATA_LOG_DIR" ]; then NODE_LOGS_DIR=$NODE_DATA_LOG_DIRelse NODE_LOGS_DIR=$NODE_HOME/logsfiif [ ! -d $NODE_LOGS_DIR ]; then mkdir $NODE_LOGS_DIRfiSTDOUT_FILE=$NODE_LOGS_DIR/stdout.logecho "[$(date '+%Y-%m-%d %H:%M:%S')] NODE_BIN_DIR: $NODE_BIN_DIR" | tee -a $STDOUT_FILE# pidNODE_PID=`ps -ef | grep "$NODE_LIB_DIR" | grep -v grep | awk '&#123;print $2&#125;'`if [ -n "$NODE_PID" ]; then echo "[$(date '+%Y-%m-%d %H:%M:%S')] ERROR: The $NODE_LIB_DIR already started! pid: $NODE_PID" | tee -a $STDOUT_FILE exit 1fi# portNODE_PORT=`sed '/clientPort/!d;s/.*=//' conf/zoo.cfg | tr -d '\r'`if [ -n "$NODE_PORT" ]; then NODE_PORT_COUNT=`netstat -tln | grep $NODE_PORT | wc -l` if [ $NODE_PORT_COUNT -gt 0 ]; then echo "[$(date '+%Y-%m-%d %H:%M:%S')] ERROR: The $NODE_LIB_DIR port $NODE_PORT already used!" | tee -a $STDOUT_FILE exit 1 fifi# startingcd $NODE_BIN_DIR./zkServer.sh startNODE_PID=`ps -ef | grep "$NODE_LIB_DIR" | grep -v grep | awk '&#123;print $2&#125;'`echo "[$(date '+%Y-%m-%d %H:%M:%S')] The $NODE_LIB_DIR started OK! pid: $NODE_PID" | tee -a $STDOUT_FILE]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux unzip 命令]]></title>
    <url>%2Fposts%2F64f75729.html</url>
    <content type="text"><![CDATA[unzip解压war、jar、zip、rar等文件1unzip -oq /opt/xxx.war -d /opt/ddd]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>unzip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux grep 命令]]></title>
    <url>%2Fposts%2F1f104b3f.html</url>
    <content type="text"><![CDATA[grep统计出现次数1grep 'sign.*time.*openid' access_p80_weixinv3.log | awk '&#123;a[$1]++&#125;END&#123;for(i in a)print a[i]"\t"i&#125;' | sort -n 4 183.3.234.4510 183.3.234.5720 183.3.234.58 查询前后日志grep -5 ‘parttern’ inputfile //打印匹配行的前后5行grep -C 5 ‘parttern’ inputfile //打印匹配行的前后5行grep -A 5 ‘parttern’ inputfile //打印匹配行的后5行grep -B 5 ‘parttern’ inputfile //打印匹配行的前5行 正则：数字12# 正则匹配1802****269的手机号码grep '1802[0-9]\&#123;4\&#125;269' info.log]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>grep</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux vi 命令]]></title>
    <url>%2Fposts%2F87207300.html</url>
    <content type="text"><![CDATA[vilinux文件格式的问题（使用unix格式）123456789# 查看文件格式vi 文件名:set ff # :set fileencoding# 设置文件格式为unix:set ff=unix# 保存退出:wq# 也可以直接使用dos2unix 文件名]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>vi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux cat 命令]]></title>
    <url>%2Fposts%2Fbe15a742.html</url>
    <content type="text"><![CDATA[cat统计出现次数12# linux统计某一文件中字符串“sent ip”出现的次数：cat nohup.log |grep "sent ip" |wc -l 清空默认文件中的内容1cat /dev/null &gt; filename]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>cat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux netstat 命令]]></title>
    <url>%2Fposts%2F6c05ba39.html</url>
    <content type="text"><![CDATA[netstat netstat 通过进程查看占用端口12# netstat -nap | grep 9836netstat -anp | grep &lt;pid&gt;]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>netstat</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat 启动脚本]]></title>
    <url>%2Fposts%2Fe22f47ab.html</url>
    <content type="text"><![CDATA[Tomcat 启动脚本主 Tomcat + 应用部署 Tomcat 应用部署方式 12345678910111213141516171819[txrd@host-148 /data/]$ tree -af .├── ./apache-tomcat-8.5.57│ └── ./bin│ └── ./conf│ └── ./lib│ └── ./temp│ └── ./webapps│ └── ./work├── ./szim│ └── ./project │ └── ./szim.war │ └── ./tomcat │ └── ./conf│ └── ./temp│ └── ./webapps│ └── ./work│ └── ./logs.sh │ └── ./restart.sh restart.sh 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109#!/usr/bin/env bash# @Author: YL# @Date: 2020-08-17 09:33:43# @Last Modified by: YL# @Last Modified time: 2020-08-17 14:50:43export LANG=en_US.UTF-8# Tomcat 主目录export CATALINA_HOME=/data/apache-tomcat-8.5.57cd `dirname $0`PROJECT_HOME=`pwd`# Tomcat 应用部署目录TC_HOME="$PROJECT_HOME/tomcat"# Tomcat 应用部署目录export CATALINA_BASE=$TC_HOME# crontab 检测日记文件TC_STDOUT_FILE="$TC_HOME/logs/stdout.out"# 检测 Tomcat 是否启动（进程ID）PIDS=`ps -ef | grep $TC_HOME | grep -v grep | awk '&#123;print $2&#125;'`# 执行检测的用户IP地址WHO_AM_I=`who am i | awk '&#123;print $5&#125;' | sed 's/(//g' | sed 's/)//g'`#===========================================================================================# JVM Configuration#===========================================================================================# export JAVA_HOME=/usr/java/jdk1.8.0_251# export PATH=$JAVA_HOME/bin:$PATH# export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$CLASSPATHJVM_OPTS="$JVM_OPTS -server -Xms1g -Xmx1g -Xss256k"JVM_OPTS="$JVM_OPTS -XX:+DisableExplicitGC -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:+ParallelRefProcEnabled"JVM_OPTS="$JVM_OPTS -Xloggc:$TC_HOME/logs/gc.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M"JVM_OPTS="$JVM_OPTS -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=$TC_HOME/logs/dump-`date +"%Y-%m-%d"`.hprof"JVM_OPTS="$JVM_OPTS -Dspring.profiles.active=pro"# Tomcat 启动参数配置export JAVA_OPTS="$JVM_OPTS"#===========================================================================================# log file delete#===========================================================================================function cleanLog()&#123; ls -d -t $TC_HOME/logs/catalina.*.log | tail -n +3 | xargs rm -rf ls -d -t $TC_HOME/logs/host-manager.*.log | tail -n +3 | xargs rm -rf ls -d -t $TC_HOME/logs/localhost.*.log | tail -n +3 | xargs rm -rf ls -d -t $TC_HOME/logs/manager.*.log | tail -n +3 | xargs rm -rf ls -d -t $TC_HOME/logs/*.hprof | tail -n +3 | xargs rm -rf&#125;cleanLog# 优雅停机function gracefulShutdown()&#123; if [ -z "$PIDS" ]; then echo "[$(date '+%Y-%m-%d %H:%M:%S')]-[$1]-[$WHO_AM_I] $TC_HOME does not started!" | tee -a $STDOUT_FILE else echo "[$(date '+%Y-%m-%d %H:%M:%S')]-[$1]-[$WHO_AM_I] $TC_HOME kill $PIDS begining" | tee -a $STDOUT_FILE for PID in $PIDS ; do kill $PID &gt; /dev/null 2&gt;&amp;1 echo "[$(date '+%Y-%m-%d %H:%M:%S')]-[$1]-[$WHO_AM_I] $TC_HOME kill $PID success" | tee -a $STDOUT_FILE done # 检测是否停机成功 COUNT=0 while [ $COUNT -lt 1 ]; do sleep 1 COUNT=1 for PID in $PIDS ; do PID_EXIST=`ps -f -p $PID | grep java` if [ -n "$PID_EXIST" ]; then COUNT=0 break fi done done fi&#125;function operate()&#123; if [[ "$1" = "kill" ]] ; then gracefulShutdown elif [[ "$1" = "start" ]]; then cd $CATALINA_HOME/bin sh startup.sh else echo "[$(date '+%Y-%m-%d %H:%M:%S')]-[$1]-[$WHO_AM_I] $TC_HOME is not support $1" | tee -a $TC_STDOUT_FILE fi&#125;if [[ "$1" = "" || "$1" = "restart" || "$1" = "start" ]] ; then operate kill echo "[$(date '+%Y-%m-%d %H:%M:%S')]-[$1]-[$WHO_AM_I] $TC_HOME starting" | tee -a $TC_STDOUT_FILE operate startelif [[ "$1" = "kill" ]] ; then operate killelif [[ "$1" = "check" ]] ; then if [[ "$PIDS" = "" ]] ; then echo "[$(date '+%Y-%m-%d %H:%M:%S')]-[$1]-[$WHO_AM_I] $TC_HOME starting" &gt;&gt; $TC_STDOUT_FILE operate start else echo "[$(date '+%Y-%m-%d %H:%M:%S')]-[$1]-[$WHO_AM_I] $TC_HOME pid $PIDS" &gt;&gt; $TC_STDOUT_FILE fielse echo "[$(date '+%Y-%m-%d %H:%M:%S')]-[$1]-[$WHO_AM_I] $TC_HOME is not support $1" | tee -a $TC_STDOUT_FILEfi 单应用部署 Tomcat 应用部署方式 12345678910111213[txrd@host-148 /data/szim]$ tree -af .├── ./project │ └── ./szim.war └── ./tomcat │ └── ./bin│ └── ./conf│ └── ./lib│ └── ./temp│ └── ./webapps│ └── ./work├── ./logs.sh ├── ./restart.sh restart.sh 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109#!/usr/bin/env bash# @Author: YL# @Date: 2020-08-17 09:33:43# @Last Modified by: YL# @Last Modified time: 2020-08-17 14:50:43export LANG=en_US.UTF-8# Tomcat 主目录export CATALINA_HOME=/data/apache-tomcat-8.5.57cd `dirname $0`PROJECT_HOME=`pwd`# Tomcat 应用部署目录TC_HOME="$PROJECT_HOME/tomcat"# Tomcat 应用部署目录export CATALINA_BASE=$TC_HOME# crontab 检测日记文件TC_STDOUT_FILE="$TC_HOME/logs/stdout.out"# 检测 Tomcat 是否启动（进程ID）PIDS=`ps -ef | grep $TC_HOME | grep -v grep | awk '&#123;print $2&#125;'`# 执行检测的用户IP地址WHO_AM_I=`who am i | awk '&#123;print $5&#125;' | sed 's/(//g' | sed 's/)//g'`#===========================================================================================# JVM Configuration#===========================================================================================# export JAVA_HOME=/usr/java/jdk1.8.0_251# export PATH=$JAVA_HOME/bin:$PATH# export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$CLASSPATHJVM_OPTS="$JVM_OPTS -server -Xms1g -Xmx1g -Xss256k"JVM_OPTS="$JVM_OPTS -XX:+DisableExplicitGC -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:+ParallelRefProcEnabled"JVM_OPTS="$JVM_OPTS -Xloggc:$TC_HOME/logs/gc.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M"JVM_OPTS="$JVM_OPTS -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=$TC_HOME/logs/dump-`date +"%Y-%m-%d"`.hprof"JVM_OPTS="$JVM_OPTS -Dspring.profiles.active=pro"# Tomcat 启动参数配置export JAVA_OPTS="$JVM_OPTS"#===========================================================================================# log file delete#===========================================================================================function cleanLog()&#123; ls -d -t $TC_HOME/logs/catalina.*.log | tail -n +3 | xargs rm -rf ls -d -t $TC_HOME/logs/host-manager.*.log | tail -n +3 | xargs rm -rf ls -d -t $TC_HOME/logs/localhost.*.log | tail -n +3 | xargs rm -rf ls -d -t $TC_HOME/logs/manager.*.log | tail -n +3 | xargs rm -rf ls -d -t $TC_HOME/logs/*.hprof | tail -n +3 | xargs rm -rf&#125;cleanLog# 优雅停机function gracefulShutdown()&#123; if [ -z "$PIDS" ]; then echo "[$(date '+%Y-%m-%d %H:%M:%S')]-[$1]-[$WHO_AM_I] $TC_HOME does not started!" | tee -a $STDOUT_FILE else echo "[$(date '+%Y-%m-%d %H:%M:%S')]-[$1]-[$WHO_AM_I] $TC_HOME kill $PIDS begining" | tee -a $STDOUT_FILE for PID in $PIDS ; do kill $PID &gt; /dev/null 2&gt;&amp;1 echo "[$(date '+%Y-%m-%d %H:%M:%S')]-[$1]-[$WHO_AM_I] $TC_HOME kill $PID success" | tee -a $STDOUT_FILE done # 检测是否停机成功 COUNT=0 while [ $COUNT -lt 1 ]; do sleep 1 COUNT=1 for PID in $PIDS ; do PID_EXIST=`ps -f -p $PID | grep java` if [ -n "$PID_EXIST" ]; then COUNT=0 break fi done done fi&#125;function operate()&#123; if [[ "$1" = "kill" ]] ; then gracefulShutdown elif [[ "$1" = "start" ]]; then cd $CATALINA_HOME/bin sh startup.sh else echo "[$(date '+%Y-%m-%d %H:%M:%S')]-[$1]-[$WHO_AM_I] $TC_HOME is not support $1" | tee -a $TC_STDOUT_FILE fi&#125;if [[ "$1" = "" || "$1" = "restart" || "$1" = "start" ]] ; then operate kill echo "[$(date '+%Y-%m-%d %H:%M:%S')]-[$1]-[$WHO_AM_I] $TC_HOME starting" | tee -a $TC_STDOUT_FILE operate startelif [[ "$1" = "kill" ]] ; then operate killelif [[ "$1" = "check" ]] ; then if [[ "$PIDS" = "" ]] ; then echo "[$(date '+%Y-%m-%d %H:%M:%S')]-[$1]-[$WHO_AM_I] $TC_HOME starting" &gt;&gt; $TC_STDOUT_FILE operate start else echo "[$(date '+%Y-%m-%d %H:%M:%S')]-[$1]-[$WHO_AM_I] $TC_HOME pid $PIDS" &gt;&gt; $TC_STDOUT_FILE fielse echo "[$(date '+%Y-%m-%d %H:%M:%S')]-[$1]-[$WHO_AM_I] $TC_HOME is not support $1" | tee -a $TC_STDOUT_FILEfi 使用说明12345sh restart.sh start # 重启sh restart.sh # 重启sh restart.sh restart # 重启sh restart.sh check # 检测服务是否启动，没有启动，则启动之，否则不做其他操作sh restart.sh kill # kill掉已启动的服务进程]]></content>
      <categories>
        <category>Tomcat</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux cp 命令]]></title>
    <url>%2Fposts%2F2835e3e.html</url>
    <content type="text"><![CDATA[cp复制文件夹1234cp -r [old source] -d [new source]# -p 保持原有文件权限cp -r -p [old source] -d [new source]]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>cp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jar启动脚本]]></title>
    <url>%2Fposts%2F6d838077.html</url>
    <content type="text"><![CDATA[-Djava.ext.dirs和-Dloader.path区别 -Djava.ext.dirs 使用-Djava.ext.dirs配置外部jar包引用时，会覆盖jdk默认的lib/ext下的扩展包 -Dloader.path jar启动脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#!/usr/bin/env bash# @Author: YL# @Date: 2017-08-31 15:52:30# @Last Modified by: YL# @Last Modified time: 2017-12-18 14:12:45export LANG=en_US.UTF-8export JAVA_HOME=/usr/java/jdk1.8.0_144export PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$CLASSPATHcd `dirname $0`PROJECT_HOME=`pwd`PROJECT_LIB=$PROJECT_HOME/libPROJECT_LOGS=$PROJECT_HOME/logsSTDOUT_FILE=$PROJECT_HOME/logs/stdout.logPROJECT_JAR=$PROJECT_HOME/yl-ftp.jar# 执行检测的用户IP地址WHO_AM_I=`who am i | awk '&#123;print $5&#125;' | sed 's/(//g' | sed 's/)//g'`# date patternDATE_PATTERN="[$(date '+%Y-%m-%d %H:%M:%S')]-[$1]-[$WHO_AM_I] $PROJECT_JAR"# pidPROJECT_PID=`ps -ef | grep "$PROJECT_JAR" | grep -v grep | awk '&#123;print $2&#125;'`function operate()&#123; if [[ "$1" = "kill" ]]; then if [ -n "$PROJECT_PID" ]; then echo "$DATE_PATTERN kill $PROJECT_PID begining" | tee -a $STDOUT_FILE kill -9 $PROJECT_PID echo "$DATE_PATTERN kill $PROJECT_PID success" | tee -a $STDOUT_FILE else echo "$DATE_PATTERN is not alive" | tee -a $STDOUT_FILE fi elif [[ "$1" = "start" ]] ; then # cd $PROJECT_HOME # starting nohup java -server -Xms512m -Xmx512m -Xss256k -Dloader.path=$PROJECT_LIB -Djava.io.tmpdir=$PROJECT_LOGS -XX:+DisableExplicitGC -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection -XX:LargePageSizeInBytes=128m -XX:+UseFastAccessorMethods -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=70 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=$PROJECT_LOGS/$PROJECT_PID.hprof -jar $PROJECT_JAR &gt;&gt; $STDOUT_FILE 2&gt;&amp;1 &amp; PROJECT_PID=`ps -ef | grep "$PROJECT_JAR" | grep -v grep | awk '&#123;print $2&#125;'` echo "$DATE_PATTERN The $PROJECT_JAR started OK! pid: $PROJECT_PID" | tee -a $STDOUT_FILE else echo "$DATE_PATTERN is not support $1" | tee -a $STDOUT_FILE fi&#125;if [[ "$1" = "start" || "$1" = "check" ]]; then if [ -n "$PROJECT_PID" ]; then echo "$DATE_PATTERN already started! pid: $PROJECT_PID" &gt;&gt; $STDOUT_FILE exit 1 fi operate startelif [[ "$1" = "" || "$1" = "restart" ]]; then operate kill echo "$DATE_PATTERN starting" | tee -a $STDOUT_FILE operate startelif [[ "$1" = "kill" ]]; then operate killelse echo "$DATE_PATTERN is not support $1" | tee -a $STDOUT_FILEfi]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>jar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper evn 环境变量配置脚本]]></title>
    <url>%2Fposts%2F57428144.html</url>
    <content type="text"><![CDATA[zookeeper-env1234567891011121314151617181920#!/usr/bin/env bash# @Author: YL# @Date: 2017-10-31 10:27:16# @Last Modified by: YL# @Last Modified time: 2017-11-01 09:36:43# 此文件放到 zookeeper 的 conf 目录下# java envexport JAVA_HOME=/usr/java/jdk1.8.0_131export PATH=$JAVA_HOME/bin:$PATHexport JVMFLAGS="-Xms1536m -Xmx1536m $JVMFLAGS"cd `dirname $0`cd ..NODE_HOME=`pwd`# zookeeper envZOO_LOG_DIR=$NODE_HOME/logsZOO_LOG4J_PROP="INFO,ROLLINGFILE"]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[zookeeper 清理日志文件]]></title>
    <url>%2Fposts%2Fc0bbcacd.html</url>
    <content type="text"><![CDATA[clear123456789101112131415161718192021222324252627282930#!/usr/bin/env bash# @Author: YL# @Date: 2017-11-01 08:59:34# @Last Modified by: YL# @Last Modified time: 2017-11-01 09:36:09# 此文件放到 zookeeper 的 bin 目录下cd `dirname $0`cd ..NODE_HOME=`pwd`# snapshotNODE_DATA_DIR=$NODE_HOME/data/version-2# snapshot logNODE_LOG_DIR=$NODE_HOME/logs/version-2# zk logNODE_LOGS=$NODE_HOME/logs# 定义了删除对应目录中的文件，保留最新的 count 个文件，可以将他写到 crontab 中count=3count=$[$count+1]ls -t $NODE_LOG_DIR/log.* | tail -n +$count | xargs rm -fls -t $NODE_DATA_DIR/snapshot.* | tail -n +$count | xargs rm -fls -t $NODE_LOGS/zookeeper.log.* | tail -n +$count | xargs rm -f# date patternDATE_PATTERN="[$(date '+%Y-%m-%d %H:%M:%S')]"STDOUT_FILE=$NODE_LOGS/stdout.logecho "$DATE_PATTERN clear logs success" | tee -a $STDOUT_FILE]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux crontab 命令]]></title>
    <url>%2Fposts%2Fb0b79272.html</url>
    <content type="text"><![CDATA[crontab 使用注意事项如果通过 crontab 执行1、crontab 无法获取 jdk 变量，要在 java 命令之前写入jdk绝对路径2、要把路径切换到要执行的 sh 路径下注意：二者缺一不可 查找 jdk 路径的方法 1 12$ echo $JAVA_HOME/usr/java/jdk1.6.0_45/bin/java 2 123456$ which java/usr/bin/java$ ls -lrt /usr/bin/java #/usr/bin/java是which java查出来的路径lrwxrwxrwx. 1 root root 22 Sep 16 2015 /usr/bin/java -&gt; /etc/alternatives/java$ ls -lrt /etc/alternatives/java #/etc/alternatives/java是ls -lrt /usr/bin/java查出来的路径 lrwxrwxrwx. 1 root root 46 Sep 16 2015 /etc/alternatives/java -&gt; /usr/lib/jvm/jre-1.6.0-openjdk.x86_64/bin/java 查询 crontab 定时器配置情况1crontab -l 编辑 crontab 定时器1234567891011crontab -e# 当 crontab 调用时，错误和标准输出会写成 mail 通知你* * * * * /opt/restart.sh# 标准输出重定向到 /dev/null，输出到这里就找不回来了* * * * * /opt/restart.sh &gt; /dev/null# 标准输出和错误输出都重定向到 /dev/null* * * * * /opt/restart.sh &gt; /dev/null 2&gt;&amp;1# 覆盖输出到指定日志文件* * * * * /opt/restart.sh &gt;/opt/logs/xxxxlog 2&gt;&amp;1# 追加输出到指定日志文件* * * * * /opt/restart.sh &gt;&gt;/opt/logs/xxxxlog 2&gt;&amp;1]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>crontab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux du 命令]]></title>
    <url>%2Fposts%2F2e023d93.html</url>
    <content type="text"><![CDATA[du计算当前文件夹下占用空间，排序1du -sh * | sort -nr]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>du</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux find 命令]]></title>
    <url>%2Fposts%2F7b744fec.html</url>
    <content type="text"><![CDATA[查找文件并删除123456789101112# 删除指定时间前的 jpg 文件find /opt/upload/ -mtime +30 -type f -name *.jpg -exec rm -f &#123;&#125; \;# 删除隐藏文件（-fr）find /opt/upload/ -type d -name .svn -exec rm -fr &#123;&#125; \;# 删除30天前的文件find /opt/upload -mtime +30 -type f -name "*.jpg" -exec rm -rf &#123;&#125; \;# find: 路径必须在表达式之前，在*前加\find /opt/upload/ -mtime +15 -type f -name \*.log -exec rm -f &#123;&#125; \; 打印指定时间前的文件1find project/upload/ -mtime +30 -type f -print]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>find</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux curl 命令]]></title>
    <url>%2Fposts%2Faea02818.html</url>
    <content type="text"><![CDATA[查询出口IP1curl icanhazip.com GET 请求1curl https://www.baidu.com?q=xxxx POST 请求1curl http://ip:port/api/add_user -XPOST -d "send message..." 发送 POST JSON 请求1curl -H "Content-Type: application/json" -X POST --data '&#123;"data":"1"&#125;' http://127.0.0.1/ 使用代理1curl -x 192.168.2.5:3128 https://www.baidu.com?q=xxxx 输出请求信息12345678# http_code# time_connect# time_starttransfer# time_total# size_download# speed_download# 参考地址：curl http://www.baidu.com?q=xxxx -so /dev/null -w "%&#123;http_code&#125;\t%&#123;time_connect&#125;\t%&#123;time_starttransfer&#125;\t%&#123;time_total&#125;\t%&#123;size_download&#125;\t%&#123;speed_download&#125;\t" 下载文件并重命名12# culr -L &lt;url&gt; -o &lt;filename&gt;curl -L http://mirrors.aliyun.com/repo/Centos-7.repo -o /etc/yum.repos.d/CentOS-Base.repo \]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>curl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zookeeper重启脚本]]></title>
    <url>%2Fposts%2F6c1ad93d.html</url>
    <content type="text"><![CDATA[restart12345678910111213#!/usr/bin/env bash# @Author: YL# @Date: 2017-06-29 09:00:10# @Last Modified by: YL# @Last Modified time: 2017-11-01 09:37:30# 此文件放到 zookeeper 的 bin 目录下cd `dirname $0`./zkServer.sh stopsleep 3./zkServer.sh start]]></content>
      <categories>
        <category>zookeeper</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring Data JPA 使用]]></title>
    <url>%2Fposts%2F6cc2492a.html</url>
    <content type="text"><![CDATA[Spring Data JPA 常用注解 @Entity 标识实体类是JPA实体，告诉JPA在程序运行时生成实体类对应表 @Table 设置实体类在数据库所对应的表名 12345@Entity@Table(name = "t_user")public class User implements java.io.Serializable &#123; private static final long serialVersionUID = 4579521515899728869L;&#125; @Id 标识类里所在变量为主键 @GeneratedValue 设置主键生成策略，此方式依赖于具体的数据库 12345678910111213141516171819// 使用序列@Id@SequenceGenerator(name = "sq_name", sequenceName = "SQ_USER", allocationSize = 1)@GeneratedValue(generator = "sq_name", strategy = GenerationType.SEQUENCE)private Long id;// 使用分布式 Id 生成/** * 唯一主键：GenericGenerator 注解的 strategy 属性，使用非默认策略的时候，需要使用全类名 */@Id@GenericGenerator( name = "SnowflakeId_BaseEntityId", // 这里需要使用全限类名 strategy = "top.ylonline.hibernate.id.SnowflakeIdentifierGenerator")@GeneratedValue(generator = "SnowflakeId_BaseEntityId")@Column(name = "id", updatable = false, nullable = false)private Long id; @Column表示属性所对应字段名进行个性化设置 @Transient表示属性并非数据库表字段的映射，ORM框架将忽略该属性 12@Transientprivate String zq; @Temporal 当我们使用到java.util包中的时间日期类型时，需要此注释来说明转化成java.util包中的类型。 注入数据库的类型有三种： TemporalType.DATE（yyyy-MM-dd） TemporalType.TIME（HH:mm:ss） TemporalType.TIMESTAMP（yyyy-MM-dd HH:mm:ss.SSS） 12@Temporal(TemporalType.TIMESTAMP)private Date createdAt; @Enumerated 使用此注解映射枚举字段，以String类型存入数据库 注入数据库的类型有两种： EnumType.ORDINAL（Interger） EnumType.STRING（String） @Embedded、@Embeddable 当一个实体类要在多个不同的实体类中进行使用，而其不需要生成数据库表 @Embeddable：注解在类上，表示此类是可以被其他类嵌套 @Embedded：注解在属性上，表示嵌套被@Embeddable注解的同类型类 @CreatedDate、@CreatedBy、@LastModifiedDate、@LastModifiedBy 分别表示创建时间（insert）、创建用户（insert）、最后修改时间（update）、最后修改用户（update） 用法： 1、@EntityListeners(AuditingEntityListener.class)：申明实体类并加注解 2 、实现AuditorAware类 3、springboot 启动类加上注解@EnableJpaAuditing 4、在实体类中属性中加上面四种注解 @MappedSuperclass 实现将实体类的多个属性分别封装到不同的非实体类中 注解的类不是完整的实体类，不会映射到数据库表，但其属性将映射到子类的数据库字段 注解的类不能再标注@Entity或@Table注解，也无需实现序列化接口 Page 函数 描述 备注 getTotalElements 总记录数 getTotalPages 总页数 getContent 查询记录列表 getNumber 当前页数，从0开始 getNumberOfElements 当前页码中的记录数 getSize 每页记录数 EntityListeners注解 使用在实体类，或者mapped superclass上 主要是配置PrePersist、PreRemove、PostPersist、PostRemove、PreUpdate、PostUpdate、PostLoad等监听回调 配置JPA审计使用 1234注意：如果需要自动填充createdBy、createdAt、modifiedBy、modifiedAt1、需要开启JPA审计（启用@EnableJpaAuditing）2、新建一个类实现AuditorAware接口，返回createdBy、modifiedBy的值，然后通过@Configuration注册成bean3、在实体类，或者mapped superclass上@EntityListeners(org.springframework.data.jpa.domain.support.AuditingEntityListener.class) Modifying注解（1）可以通过自定义的 JPQL 完成 UPDATE 和 DELETE 操作。 注意： JPQL 不支持使用 INSERT （2）在 @Query 注解中编写 JPQL 语句， 但必须使用 @Modifying 进行修饰. 以通知 Spring Data， 这是一个 UPDATE 或 DELETE 操作 （3）UPDATE 或 DELETE 操作需要使用事务，此时需要定义 Service 层，在 Service 层的方法上添加事务操作 （4）默认情况下， Spring Data 的每个方法上有事务， 但都是一个只读事务。 他们不能完成修改操作 批量插入、更新配置12345678910111213spring: jpa: # show-sql: true database: ORACLE properties: hibernate: # format_sql: false dialect: org.hibernate.dialect.Oracle10gDialect jdbc: batch_size: 500 batch_versioned_data: true order_inserts: true order_updates: true 参考 https://vladmihalcea.com/how-to-batch-insert-and-update-statements-with-hibernate/ https://docs.jboss.org/hibernate/orm/4.3/manual/en-US/html/ch03.html#configuration-jdbc-properties]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
        <tag>jpa</tag>
        <tag>hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot 使用注意事项]]></title>
    <url>%2Fposts%2F47aa1712.html</url>
    <content type="text"><![CDATA[兼容问题spring-boot-starter-parent切换回1.5.2.RELEASE版本 因为1.5.4.RELEASE、1.5.5.RELEASE、1.5.6.RELEASE、1.5.7.RELEASE、2.0.0.M1、2.0.0.M2、2.0.0.M3都存在使用spring-boot-starter-data-redis时，会出现异常 java.lang.NoSuchMethodError: org.springframework.data.repository.config.AnnotationRepositoryConfigurationSource.&lt;init&gt;异常 请查看https://github.com/spring-projects/spring-boot/issues/9606 外部 Tomcat 容器部署 外部 Tomcat 等容器部署war，要继承 SpringBootServletInitializer 类 war部署要重写SpringBootServletInitializer的configure方法，可以不要main方法，main方法是jar部署时候会执行的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.boot.web.servlet.support.SpringBootServletInitializer;import org.springframework.context.annotation.Bean;/** * 启动器 * * @author YL */@SpringBootApplication( excludeName = &#123; "org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration", // 数据库相关 "org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration", "org.springframework.boot.autoconfigure.jdbc.XADataSourceAutoConfiguration", "org.springframework.boot.autoconfigure.jdbc.JndiDataSourceAutoConfiguration", "org.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration", // jmx 相关 "org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration", // websocket 相关 "org.springframework.boot.autoconfigure.websocket.reactive.WebSocketReactiveAutoConfiguration", "org.springframework.boot.autoconfigure.websocket.servlet.WebSocketMessagingAutoConfiguration", "org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration", // mail相关 "org.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration", "org.springframework.boot.autoconfigure.mail.MailSenderValidatorAutoConfiguration", // 模版引擎 "org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration", "org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration", // actuate trace：保存最近100次请求记录在内容，没什么卵用 "org.springframework.boot.actuate.autoconfigure.TraceRepositoryAutoConfiguration", "org.springframework.boot.actuate.autoconfigure.TraceWebFilterAutoConfiguration", "org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration", // 其他 "org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration" &#125;)public class App extends SpringBootServletInitializer &#123; /** * Common */ private static SpringApplicationBuilder configureSpringBuilder(SpringApplicationBuilder builder) &#123; // 自定义事件监听器，实现 ApplicationListener -- builder.listeners(new EnvironmentPreparedEventListener()); return builder.sources(App.class); &#125; /** * for WAR deploy */ @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; return configureSpringBuilder(builder); &#125; /** * for JAR deploy */ public static void main(String[] args) &#123; configureSpringBuilder(new SpringApplicationBuilder()) .run(args); &#125;&#125; attach=false123456789101112131415&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;layout&gt;ZIP&lt;/layout&gt; &lt;includes&gt; &lt;include&gt; &lt;groupId&gt;nothing&lt;/groupId&gt; &lt;artifactId&gt;nothing&lt;/artifactId&gt; &lt;/include&gt; &lt;/includes&gt; &lt;!-- 将原始的包作为 install 和 deploy 的对象，而不是包含了依赖的包 --&gt; &lt;attach&gt;false&lt;/attach&gt; &lt;/configuration&gt;&lt;/plugin&gt; spring-boot升级到2.0 弃用WebMvcConfigurerAdapter，替换成WebMvcConfigurer 12345678910@Configuratiionpublic class WebAdapter extends WebMvcConfigurerAdapter &#123; @Override public void addCorsMappings(CorsRegistry registry) &#123; registry.addMapping("/**") .allowedHeaders("*") .allowedOrigins("*") .allowedMethods("GET", "POST", "PUT"); &#125;&#125; 在 spring-boot 2.0 中需要注意，因为使用的是 spring 5，原先的方法是继承WebMvcConfigurerAdapter抽象类，现在是直接扩展 WebMvcConfigurer 这个接口。原先的方式很能生效，不过已经被 spring 5弃用了（@Deprecated） 12345678910111213141516171819@Configuratiionpublic class MyConfiguration &#123; @Bean public WebMvcConfigurer webMvcConfigurer() &#123; return new WebMvcConfigurer() &#123; // 跨域配置 @Override public void addCorsMappings(CorsRegistry registry) &#123; registry.addMapping("/api/**"); &#125; // 拦截器配置 @Override public void addInterceptors(InterceptorRegistry registry) &#123; &#125; // ... &#125;; &#125;&#125; 其他 @RequestBody 使用 @RequestBody 注解时，如果注解的参数没有传入，则会抛出org.springframework.http.converter.HttpMessageNotReadableException异常 配合hibernate-validator不起作用的问题 在参数前面使用org.springframework.validation.annotation.Validated注解，或者javax.validation.Valid注解均可 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;import org.hibernate.validator.constraints.Length;import org.hibernate.validator.constraints.NotBlank;import java.io.Serializable;/** * @author Created by YL on 2017/10/19 */@Data@AllArgsConstructor@NoArgsConstructorpublic class MarketRebateDTO implements Serializable &#123; @NotBlank(message = "营销活动 Id 不能为空") @Length(min = 5, max = 8, message = "营销活动 Id[$&#123;validatedValue&#125;] 长度必须在 &#123;min&#125; 和 &#123;max&#125; 之间") private String marketCfgId; private String productNo; private String rebateAmt; private String tradeType;&#125;import com.alibaba.dubbo.config.annotation.Reference;import org.springframework.validation.annotation.Validated;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RequestBody;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import javax.validation.Valid;/** * 广东省营销接口 * * @author Created by YL on 2017/10/18 */@RestController@RequestMapping("/api/market")public class MarketController extends BaseRestController &#123; @Reference private MarketService marketService; @PostMapping("/rebate") public BaseResponse rebate(@RequestBody @Valid MarketRebateDTO rebate) throws CoreException, OkHttpException &#123; return marketService.doRebate(rebate); &#125;&#125; @RequestParam 使用 @RequestParam 注解时，如果注解的参数没有传入，则会抛出org.springframework.web.bind.MissingServletRequestParameterException异常 配合hibernate-validator不起作用的问题 要注册 MethodValidationPostProcessor Bean，并且在类上面使用org.springframework.validation.annotation.Validated注解 注意：使用javax.validation.Valid注解对RequestParam对应的参数进行注解，是无效的，需要使用@Validated注解来使得验证生效 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Beanpublic Validator validator() &#123; ValidatorFactory factory = Validation.byProvider(HibernateValidator.class) .configure() // 1、普通模式（默认是这个模式） // 普通模式(会校验完所有的属性，然后返回所有的验证失败信息) // 2、快速失败返回模式 // 快速失败返回模式(只要有一个验证失败，则返回) // .addProperty("hibernate.validator.fail_fast", "true") .failFast(true) .buildValidatorFactory(); return factory.getValidator();&#125;@Beanpublic MethodValidationPostProcessor methodValidationPostProcessor() &#123; MethodValidationPostProcessor postProcessor = new MethodValidationPostProcessor(); // 设置validator模式为快速失败返回 postProcessor.setValidator(validator()); return postProcessor;&#125;import com.alibaba.dubbo.config.annotation.Reference;import org.hibernate.validator.constraints.NotBlank;import org.springframework.validation.annotation.Validated;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;/** * csp 平台接口封装 * * @author Created by YL on 2017/9/19 */@RestController@RequestMapping("/api/csp")@Validatedpublic class CspController extends BaseRestController &#123; @Reference private CspService cspService; @GetMapping public BaseResponse get(@RequestParam @NotBlank(message = "组件名不能为空") String func, @RequestParam @NotBlank(message = "参数值不能为空") String param) throws OkHttpException, OpenApiException &#123; return new BaseResponse(cspService.get(func, param)); &#125;&#125; 至此，Bean Validator 和 hibernate-validator的@Size、@Min、@Max、@Length、@NotBlank等注解就生效了]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bootstrap-table 的使用问题]]></title>
    <url>%2Fposts%2Fb2990e54.html</url>
    <content type="text"><![CDATA[自定义分页、排序等参数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// bootstrap table初始化$table.bootstrapTable(&#123; url: '$&#123;ctx&#125;/manage/log/list', height: getHeight(), striped: true, search: true, showRefresh: true, showColumns: true, minimumCountColumns: 2, clickToSelect: true, // -------------------------------------------------------- // 自定义分页、排序等参数 // 如果配置'limit'，则 queryParams 默认参数是 offset、limit、order、search、sort /* queryParamsType: 'limit', queryParams: function (params) &#123; return &#123; page: params.pageNumber, size: params.pageSize, search: params.search, sort: params.sort, order: params.order &#125;; &#125;, */ // 这里配置成''，则 queryParams 参数是 pageNumber、pageSize、searchText、sortName、sortOrder queryParamsType: '', queryParams: function (params) &#123; return &#123; page: params.pageNumber, size: params.pageSize, search: params.searchText, sort: params.sortName, order: params.sortOrder &#125;; &#125;, // -------------------------------------------------------- detailView: true, detailFormatter: 'detailFormatter', pagination: true, paginationLoop: false, sidePagination: 'server', silentSort: false, smartDisplay: false, escape: true, searchOnEnterKey: true, idField: 'id', maintainSelected: true, toolbar: '#toolbar', columns: [ &#123;field: 'ck', checkbox: true&#125;, &#123;field: 'id', title: '编号', sortable: true, align: 'right'&#125;, &#123;field: 'description', title: '操作'&#125;, &#123;field: 'username', title: '操作用户', align: 'right'&#125; ]&#125;);]]></content>
      <categories>
        <category>Javascript</category>
      </categories>
      <tags>
        <tag>bootstrap</tag>
        <tag>bootstrap-table</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IntelliJ IDEA 插件]]></title>
    <url>%2Fposts%2Fb7ca9e0f.html</url>
    <content type="text"><![CDATA[windows环境下，Intellij idea12中maven操作时，控制台中文乱码问题（编译报错或者clean install时出现的其他错误描述乱码） 在cmd中mvn中文正常显示,log4j打印日志也是ok的。 解决方法： Setting -&gt; maven -&gt; runnerVMoptions: -Dfile.encoding=UTF-8 在idea的vm.propertis加入-Dfile.encoding=UTF-8]]></content>
      <categories>
        <category>Intellij</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL中inner join、outer join和cross join的区别]]></title>
    <url>%2Fposts%2F8b243174.html</url>
    <content type="text"><![CDATA[SQL中inner join、outer join和cross join的区别INNER JOIN 产生的结果是AB的交集SELECT * FROM TableA INNER JOIN TableB ON TableA.name = TableB.name LEFT [OUTER] JOIN 产生表A的完全集，而B表中匹配的则有值，没有匹配的则以null值取代SELECT * FROM TableA LEFT OUTER JOIN TableB ON TableA.name = TableB.name RIGHT [OUTER] JOIN 产生表B的完全集，而A表中匹配的则有值，没有匹配的则以null值取代SELECT * FROM TableA RIGHT OUTER JOIN TableB ON TableA.name = TableB.name FULL [OUTER] JOIN 产生A和B的并集。对于没有匹配的记录，则会以null做为值SELECT FROM TableA FULL OUTER JOIN TableB ON TableA.name = TableB.name你可以通过is NULL将没有匹配的值找出来：SELECT FROM TableA FULL OUTER JOIN TableB ON TableA.name = TableB.nameWHERE TableA.id IS null OR TableB.id IS null CROSS JOIN 把表A和表B的数据进行一个NM的组合，即笛卡尔积。如本例会产生44=16条记录，在开发过程中我们肯定是要过滤数据，所以这种很少用SELECT * FROM TableA CROSS JOIN TableB]]></content>
      <categories>
        <category>sql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-data-jpa 使用笔记]]></title>
    <url>%2Fposts%2F43f916ea.html</url>
    <content type="text"><![CDATA[主要是记录一些在使用spring-data-jpa + Hibernate过程中遇到的一些问题，和要注意的知识点 Pageable 和 PageRequest 分页在Mysql、Oracle中分页从0开始1Pageable pageable = new PageRequest(0, 10); 查看org.springframework.data.domain.PageRequest源码可知，分页从0开始 123public Pageable first() &#123; return new PageRequest(0, this.getPageSize(), this.getSort());&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Hibernate</tag>
        <tag>spring-data-jpa</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pagehelper 使用笔记]]></title>
    <url>%2Fposts%2F4f0d5500.html</url>
    <content type="text"><![CDATA[主要是记录一些在使用mybatis + pagehelper过程中遇到的一些问题，和要注意的知识点 PageHelper 分页12345// 获取第1页，10条内容，默认查询总数countPageHelper.startPage(1, 10);// 获取第1页，10条内容，不查询总数countPageHelper.startPage(1, 10, false);]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>pagehelper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JPA Criteria 查询]]></title>
    <url>%2Fposts%2F6202485a.html</url>
    <content type="text"><![CDATA[构建 CriteriaQuery 实例API说明CriteriaBuilder 安全查询创建工厂CriteriaBuilder是一个工厂对象，可以从EntityManager或EntityManagerFactory类中获得。可以用于创建CriteriaQuery、Predicate等1CriteriaBuilder builder = entityManager.getCriteriaBuilder(); CriteriaQuery 安全查询主语句CriteriaQuery对象必须在实体类型或嵌入式类型上的Criteria查询上起作用。它通过调用 CriteriaBuilder.createQuery或CriteriaBuilder.createTupleQuery等获得。1CriteriaQuery&lt;User&gt; query = builder.createQuery(User.class); Root 定义查询的 From 子句中能出现的类型12// 获取 User 实体查询的根对象Root&lt;User&gt; root = query.from(User.class); Predicate 过滤条件过滤条件应用到SQL语句的FROM子句中。 在Criteria查询中，查询条件通过Predicate或Expression实例应用到CriteriaQuery 对象上。这些条件使用CriteriaQuery.where方法应用到CriteriaQuery对象上。 Predicate对象通过调用CriteriaBuilder的equal、notEqual、gt、ge、lt、le、between、like等方法创建。 Predicate实例也可以用Expression实例的isNull、isNotNull和in方法获得，复合的Predicate语句可以使用CriteriaBuilder的and、or方法构建。123// 查询 id 大于10的用户Predicate predicate = builder.gt(root.get("id"), 10);query.where(predicate); ExpressionExpression对象用在查询语句的select、where和having子句中，该接口有isNull、isNotNull和in方法123456789101112131415// 第一种CriteriaQuery&lt;User&gt; query = builder.createQuery(User.class);Root&lt;User&gt; root = query.from(User.class);query.where(root.get("id").in(1, 5));entityManager.createQuery(query).getResultList();// select * from user where id in (1, 5)// 第二种Expression&lt;String&gt; exp = root.get("id");List&lt;Integer&gt; list = new ArrayList&lt;&gt;();list.add(1);list.add(5);predicates.add(exp.in(list));query.where(predicates.toArray(new Predicate[predicates.size()]));// select * from user where id in (1, 5) 高级用法复合查询12345678910111213141516// 使用 CriteriaQuery，查询年龄为10，且名字以 ts 开头的用户Path&lt;String&gt; name = root.get("name");query.where( builder.and( builder.equal(root.get("age"), 10), builder.like(name, "ts%") ));entityManager.createQuery(query).getResultList();// 使用 CriteriaBuilder，查询年龄为10，名字以 ts 开头的用户Path&lt;String&gt; name = root.get("name");Predicate and = builder.and( builder.equal(root.get("age"), 10), builder.like(name, "ts%")); 1234567891011SELECT user0_.id AS id1_1_, user0_.age AS age2_1_, user0_.create_date AS create_d3_1_, user0_. NAME AS name4_1_, user0_. STATUS AS status5_1_FROM USER user0_WHERE user0_.age = 10AND (user0_. NAME LIKE ?)]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hibernate的DynamicInsert、DynamicUpdate介绍]]></title>
    <url>%2Fposts%2F2ed26d9a.html</url>
    <content type="text"><![CDATA[作用 使用 Dynamic Update 如果使用了 Dynamic Update，需要注意的是，当select后，显式的把某些字段set为NULL，hibernate 会认为你修改了该字段，会生成到 update 语句中。一般先 select 实体出来，再 save 的话，只会 update 该实体被修改的字段。否则会 update 所有表字段。添加Dynamic Update配置可以减少被 update 的字段。 使用 Dynamic Insert 如果使用了 Dynamic Insert，并且数据库配置了默认值，当 insert，并且new 实体时，该属性没有 set 值的话，会使用数据库默认值，否则会使用实体的值。 配置方式 第一种：使用注解配置12345678910111213@Entiry(name = "t_user")@DynamicInsert@DynamicUpdatepublic class User &#123; @Id @GeneratedValue private Long id; private Strin name; private Integer age; private Integer status; // getter setter&#125; 第二种：使用.hbm.xml配置12345&lt;hibernate-mapping&gt; &lt;class name="xxx.User" table="t_user" dynamic-insert="true" dynamic-update="true"&gt; &lt;!-- 省略配置 --&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt; 效果主要比较一下insert、update语句的区别，其中update一个已有的实体对象时，hibernate会再执行一次select操作再去update123456789101112131415161718192021222324252627282930@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTestpublic class ApplicationTests &#123; @Autowired private UserRepository repository; @Test public void test() throws Exception &#123; // 1、插入新记录 // 配置 dynamic insert // insert into user (name) values (?) // 未配置 dynamic insert // insert into user (age, name, status) values (?, ?, ?) User user = new User("AAA"); User save = repository.save(user); // 2、更新记录 // 配置 dynamic update // select user0_.id as id1_1_0_, user0_.age as age2_1_0_, user0_.name as name3_1_0_, user0_.status as status4_1_0_ from user user0_ where user0_.id=? // update user set name=? where id=? // 未配置 dynamic update // select user0_.id as id1_1_0_, user0_.age as age2_1_0_, user0_.name as name3_1_0_, user0_.status as status4_1_0_ from user user0_ where user0_.id=? // update user set age=?, name=?, status=? where id=? save.setName("BBB"); repository.save(save); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hibernate格式化输出sql语句（spring-data-jpa）]]></title>
    <url>%2Fposts%2F723691b5.html</url>
    <content type="text"><![CDATA[以下配置是基于spring-boot的application.yml配置 123456789spring: jpa:# hibernate:# ddl-auto: create show-sql: true# database: mysql properties: hibernate: format_sql: true]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Hibernate</tag>
        <tag>spring-data-jpa</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hibernate显示sql中的参数值（logback）]]></title>
    <url>%2Fposts%2F9eea8fb4.html</url>
    <content type="text"><![CDATA[以下是 logback 的日志输出配置，只要是在 logback 的配置文件中添加以下配置 12&lt;!-- show parameters for hibernate sql 专为 Hibernate 定制 --&gt;&lt;logger name="org.hibernate.type.descriptor.sql.BasicBinder" level="TRACE"/&gt; 完整的 logback 配置如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration scan="true" scanPeriod="60 seconds" debug="false"&gt; &lt;property name="logger.charset" value="UTF-8"/&gt; &lt;property name="logger.path" value="$&#123;catalina.home&#125;/logs"/&gt; &lt;property name="logger.pattern" value="[%d&#123;yyyy-MM-dd HH:mm:ss&#125; %highlight(%-5p)] %yellow(%t) %cyan(%c.%M\\(%L\\)) | %m%n"/&gt; &lt;property name="logger.maxHistory" value="15"/&gt; &lt;springProfile name="dev, local"&gt; &lt;appender name="stdout" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder charset="$&#123;logger.charset&#125;"&gt; &lt;pattern&gt;$&#123;logger.pattern&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- show parameters for hibernate sql 专为 Hibernate 定制 --&gt; &lt;logger name="org.hibernate.type.descriptor.sql.BasicBinder" level="TRACE"/&gt; &lt;!--&lt;logger name="org.hibernate.type.descriptor.sql.BasicExtractor" level="DEBUG"/&gt; &lt;logger name="org.hibernate.SQL" level="DEBUG"/&gt; &lt;logger name="org.hibernate.type" level="INFO"/&gt; &lt;logger name="org.hibernate.engine.QueryParameters" level="DEBUG"/&gt; &lt;logger name="org.hibernate.engine.query.HQLQueryPlan" level="DEBUG"/&gt;--&gt; &lt;!--&lt;logger name="org.apache.ibatis" level="debug"/&gt; &lt;logger name="java.sql.Connection" level="debug"/&gt; &lt;logger name="java.sql.Statement" level="debug"/&gt; &lt;logger name="java.sql.PreparedStatement" level="debug"/&gt;--&gt; &lt;root level="info"&gt; &lt;appender-ref ref="stdout"/&gt; &lt;/root&gt; &lt;/springProfile&gt; &lt;springProfile name="prod"&gt; &lt;!--See http://logback.qos.ch/manual/appenders.html#RollingFileAppender --&gt; &lt;!--and http://logback.qos.ch/manual/appenders.html#TimeBasedRollingPolicy --&gt; &lt;!--for further documentation --&gt; &lt;appender name="stdout" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;File&gt;$&#123;logger.path&#125;/info.log&lt;/File&gt; &lt;encoder charset="$&#123;logger.charset&#125;"&gt; &lt;pattern&gt;$&#123;logger.pattern&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt; $&#123;logger.path&#125;/info.log.%d&#123;yyyy.MM.dd&#125; &lt;/fileNamePattern&gt; &lt;maxHistory&gt;$&#123;logger.maxHistory&#125;&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;appender name="warn" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;encoder charset="$&#123;logger.charset&#125;"&gt; &lt;pattern&gt;$&#123;logger.pattern&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;File&gt;$&#123;logger.path&#125;/warn.log&lt;/File&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;WARN&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt; $&#123;logger.path&#125;/warn.log.%d&#123;yyyy.MM.dd&#125; &lt;/fileNamePattern&gt; &lt;maxHistory&gt;$&#123;logger.maxHistory&#125;&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;appender name="error" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;encoder charset="$&#123;logger.charset&#125;"&gt; &lt;pattern&gt;$&#123;logger.pattern&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;File&gt;$&#123;logger.path&#125;/error.log&lt;/File&gt; &lt;filter class="ch.qos.logback.classic.filter.LevelFilter"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt; $&#123;logger.path&#125;/error.log.%d&#123;yyyy.MM.dd&#125; &lt;/fileNamePattern&gt; &lt;maxHistory&gt;$&#123;logger.maxHistory&#125;&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;logger name="warn" level="WARN"/&gt; &lt;logger name="error" level="ERROR"/&gt; &lt;root level="info"&gt; &lt;appender-ref ref="warn"/&gt; &lt;appender-ref ref="error"/&gt; &lt;appender-ref ref="stdout"/&gt; &lt;/root&gt; &lt;/springProfile&gt;&lt;/configuration&gt;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>logback</tag>
        <tag>Hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[身份证号验证]]></title>
    <url>%2Fposts%2F1af78879.html</url>
    <content type="text"><![CDATA[java 身份证校验，代码中年份判断不够完善，其他编程方式不做考究 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219public class IdUtils &#123; private static final int[] weight = new int[] &#123; 7, 9, 10, 5, 8, 4, 2, 1, 6, 3, 7, 9, 10, 5, 8, 4, 2 &#125;; // 十七位数字本体码权重 private static final char[] verify = new char[] &#123; '1', '0', 'X', '9', '8', '7', '6', '5', '4', '3', '2' &#125;; // mod11,对应校验码字符值 // /** // * 保存地区编码 // */ // private static final Map&lt;String, String&gt; map = new HashMap&lt;String, // String&gt;(); // static &#123; // map.put("11", "北京"); // map.put("12", "天津"); // map.put("13", "河北"); // map.put("14", "山西"); // map.put("15", "内蒙古"); // map.put("21", "辽宁"); // map.put("22", "吉林"); // map.put("23", "黑龙江"); // map.put("31", "上海"); // map.put("32", "江苏"); // map.put("33", "浙江"); // map.put("34", "安徽"); // map.put("35", "福建"); // map.put("36", "江西"); // map.put("37", "山东"); // map.put("41", "河南"); // map.put("42", "湖北"); // map.put("43", "湖南"); // map.put("44", "广东"); // map.put("45", "广西"); // map.put("46", "海南"); // map.put("50", "重庆"); // map.put("51", "四川"); // map.put("52", "贵州"); // map.put("53", "云南"); // map.put("54", "西藏"); // map.put("61", "陕西"); // map.put("62", "甘肃"); // map.put("63", "青海"); // map.put("64", "宁夏"); // map.put("65", "新疆"); // map.put("71", "台湾"); // map.put("81", "香港"); // map.put("82", "澳门"); // map.put("91", "国外"); // &#125; /** * 验证身份证 */ public static MyObj verifyIdcard(String idstr) &#123; MyObj rt = new MyObj(); try &#123; // 1、校验是否为空 if (idstr == null || idstr == "") &#123; throw new MyException(50001, "校验的身份证不能为空！"); &#125; // 2、校验长度 String idstr17 = ""; int length = idstr.length(); if (length == 15) &#123; idstr17 = idstr.substring(0, 6) + "19" + idstr.substring(6, length); &#125; else if (length == 18) &#123; idstr17 = idstr.substring(0, 17); &#125; else &#123; throw new MyException(50002, "校验的身份证长度不符合，校验的身份证长度只能是15位或者18位"); &#125; // 3、校验地区编码 // verifyAreacode(idstr17); // 4、校验数字 verifyNumeric(idstr17); // 5、校验日期有效性 verifyDate(idstr17); // 6、获取身份证校验码，比较2个身份证号码是否一致 char verifyCode = getVerifyCode(idstr17); String verifyStr = idstr17 + verifyCode; // 通过校验得到的身份证号码 if (!verifyStr.equals(idstr)) &#123; throw new MyException(50006, "身份证无效，不是合法的身份证号码"); &#125; &#125; catch (MyException e) &#123; rt.setErrcode(e.getErrcode()); rt.setErrmsg(e.getErrmsg()); &#125; return rt; &#125; // /** // * 校验地区编码：身份证前2位 // * // * @param idstr17 // * 身份证前17位 // */ // private static void verifyAreacode(String idstr17) // throws ErrException &#123; // String acode = idstr17.substring(6, 10);// 年份 // if (map.get(acode) == null) &#123; // throw new ErrException(50003, "身份证地区编码错误（" + acode + "）"); // &#125; // &#125; /** * 校验身份证前17位是否有效数字 * * @param idtstr17 * 身份证前17位 * @return 数字-true，非数字-false */ private static void verifyNumeric(String idtstr17) throws MyException &#123; if (!idtstr17.matches("^\\d&#123;17&#125;$")) &#123; throw new MyException(50004, "身份证15位号码，18位号码除最后一位外，都应为数字。"); &#125; &#125; /** * 身份证校验码 * * @param idstr17 * 身份证前17位 * @return 返回最后一位效验码 */ private static char getVerifyCode(String idstr17) &#123; int sum = 0; int mode = 0; for (int i = 0; i &lt; idstr17.length(); i++) &#123; sum += ((int) (idstr17.charAt(i) - 0x30)) * weight[i]; // 0x30：16进制的0 &#125; mode = sum % 11; return verify[mode]; &#125; /** * 校验生日日期是否正确 * * @param idstr17 * 身份证前17位 * @return 返回最后一位效验码 */ private static void verifyDate(String idstr17) throws MyException &#123; String year = idstr17.substring(6, 10);// 年份 String month = idstr17.substring(10, 12);// 月份 String day = idstr17.substring(12, 14);// 月份 String str = year + "-" + month + "-" + day; // TODO 用“(19|2\\d)\\d&#123;2&#125;”来验证年份，有欠完善性 if (!str.matches("^(19|2\\d)\\d&#123;2&#125;-((0[1-9])|(1[012]))-((0[1-9])|(1\\d)|(2\\d)|(3[01]))$")) &#123; throw new MyException(50005, "身份证生日无效（" + str + "）！"); &#125; &#125; public static void main(String[] args) throws Exception &#123; String str = ""; // System.out.println("身份证校验码：" + IdUtils.getVerifyCode(str.substring(0, // 17))); System.out.println("身份证校验：" + IdUtils.verifyIdcard(str)); &#125;&#125;class MyObj &#123; private int errcode = 0; private String errmsg = "ok"; public MyObj() &#123; &#125; public MyObj(int errcode, String errmsg) &#123; this.errcode = errcode; this.errmsg = errmsg; &#125; public int getErrcode() &#123; return errcode; &#125; public void setErrcode(int errcode) &#123; this.errcode = errcode; &#125; public String getErrmsg() &#123; return errmsg; &#125; public void setErrmsg(String errmsg) &#123; this.errmsg = errmsg; &#125; @Override public String toString() &#123; return "MyObj [errcode=" + errcode + ", errmsg=" + errmsg + "]"; &#125;&#125;class MyException extends Exception &#123; private static final long serialVersionUID = -1756360434352093459L; private int errcode = 0; private String errmsg = "ok"; public MyException() &#123; super(); &#125; public MyException(Throwable cause) &#123; super(cause); &#125; public MyException(int errcode, String errmsg) &#123; super(errmsg); this.errcode = errcode; this.errmsg = errmsg; &#125; public MyException(int errcode, Throwable cause) &#123; super(cause); this.errcode = errcode; &#125; public MyException(String errmsg, Throwable cause) &#123; super(errmsg, cause); this.errmsg = errmsg; &#125; public MyException(int errcode, String errmsg, Throwable cause) &#123; super(errmsg, cause); this.errcode = errcode; this.errmsg = errmsg; &#125; public int getErrcode() &#123; return errcode; &#125; public void setErrcode(int errcode) &#123; this.errcode = errcode; &#125; public String getErrmsg() &#123; return errmsg; &#125; public void setErrmsg(String errmsg) &#123; this.errmsg = errmsg; &#125; @Override public String toString() &#123; return "MyException [errcode=" + errcode + ", errmsg=" + errmsg + "]"; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Brendan Gregg 的 FlameGraph 火焰图]]></title>
    <url>%2Fposts%2Ff2d475dc.html</url>
    <content type="text"><![CDATA[下载 lightweight-java-profiler 采样栈信息https://code.google.com/archive/p/lightweight-java-profiler/source/default/source 下载 lightweight-java-profiler 工具 修改1234# 第4行 BITS?=32 改成BITS?=64# 第49行 INCLUDES=-I$(JAVA_HOME)/$(HEADERS) -I$(JAVA_HOME)/$(HEADERS)/$(UNAME) 改成INCLUDES=-I$(JAVA_HOME)/$(HEADERS) -I$(JAVA_HOME)/$(HEADERS)/$(UNAME) -I/usr/include/x86_64-linux-gnu 编译1234make all# yum -y update gcc# yum -y install gcc+ gcc-c++# 报错的话，要修改display.cc 第 22 行，fprintf(file_, "%" PRIdPTR" ", traces[i].count); 下载 FlameGraph 火焰图生成工具1git clone http://github.com/brendangregg/FlameGraph 使用 Profiler 工具生成 trace.txt 文件12345# tomcat 中JAVA_OPTS="-server -agentpath:/home/yl/lightweight-java-profiler/build-64/liblagent.so"# java jarjava -agentpath:/home/yl/lightweight-java-profiler/build-64/liblagent.so -jar xxx.jar 注意：trace 不是实时写入，而是在应用 shutdown 的时候才写入的，别 kill 应用，否则 trace 里面什么都没有 另外有几个参数可在编译时修改，都在global.h文件中。首先是采样的频率，缺省是100次 每秒；另外是最大采样的线程栈，缺省3000，超过3000就忽略（对于复杂的应用明显不够） ；最后是栈的深度，缺省是128（对于调用层次深的应用调大）。 将 trace.txt 文件转换为 trace.svg 格式的火焰图123456789101112131415161718192021222324cd FlameGraph./stackcollapse-ljp.awk &lt; ../traces.txt | ./flamegraph.pl --colors=java --title="traces title" &gt; ../traces.svg# yum install perl# 一些参数说明--title # change title text--width # width of image (default 1200)--height # height of each frame (default 16)--minwidth # omit smaller functions (default 0.1 pixels)--fonttype # font type (default "Verdana")--fontsize # font size (default 12)--countname # count type label (default "samples")--nametype # name type label (default "Function:")--colors # set color palette. choices are: hot (default), mem, io, # wakeup, chain, java, js, perl, red, green, blue, aqua, # yellow, purple, orange--hash # colors are keyed by function name hash--cp # use consistent palette (palette.map)--reverse # generate stack-reversed flame graph--inverted # icicle graph--negate # switch differential hues (blue&lt;-&gt;red)--help # this messageeg,./flamegraph.pl --title="Flame Graph: malloc()" trace.txt &gt; graph.svg 用浏览器打开生成的 traces.svg 火焰图文件 默认：samples–countname=pages1 pages = 4 kbyte–countname=bytes]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>lightweight-java-profiler</tag>
        <tag>FlameGraph</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VirtualBox 虚拟机安装 CentOS]]></title>
    <url>%2Fposts%2Fa45b124.html</url>
    <content type="text"><![CDATA[VirtualBox 安装 CentOS 7安装 虚拟机安装CentOS步骤省略。推荐安装minimal版本 配置网络 CentOS7 中已经取消了 ifconfig，用 nmcli 进行了代替，服务管理也升级为 systemd。所以之前在6.x版本上的网络配置操作在7.x上行不通了。下面介绍一下在CentOS7.x上进行网络配置的方法。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>VirtualBox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux many open file问题排查]]></title>
    <url>%2Fposts%2F5618a78c.html</url>
    <content type="text"><![CDATA[lsof查询many open file等问题1、netstat显示的tcp连接数正常12345[imhtp@im2-wx-kf2 ~]$ netstat -n | awk '/^tcp/ &#123;++state[$NF]&#125; END &#123;for(key in state) print key,"\t",state[key]&#125;'TIME_WAIT 8481CLOSE_WAIT 322FIN_WAIT2 43ESTABLISHED 144 2、ss -s显示大量的closed连接1234567891011[imhtp@im2-wx-kf2 ~]$ ss -sTotal: 707 (kernel 766)TCP: 8483 (estab 130, closed 7910, orphaned 0, synrecv 0, timewait 7896/0), ports 685Transport Total IP IPv6* 766 - -RAW 0 0 0UDP 10 6 4TCP 573 13 560INET 583 19 564FRAG 0 0 0 上面信息说明存在socket fd泄漏，那么用lsof命令检查系统sock的文件句柄。closed 7910，很多socket是处于closed状态。 3、lsof | grep sock12345678910111213141516171819202122232425262728293031323334[imhtp@im2-wx-kf2 ~]$ lsof | grep sockjava 1029 imhtp 36u sock 0,6 0t0 7121949 can't identify protocoljava 1773 imhtp 36u sock 0,6 0t0 13282 can't identify protocoljava 2747 imhtp 36u sock 0,6 0t0 129765023 can't identify protocoljava 7070 imhtp 36u sock 0,6 0t0 9465828 can't identify protocoljava 7681 imhtp 36u sock 0,6 0t0 268478565 can't identify protocoljava 7681 imhtp 192u unix 0xffff88004ac89080 0t0 268479492 socketjava 12545 imhtp 38u sock 0,6 0t0 187396984 can't identify protocoljava 12545 imhtp 190u unix 0xffff880233f7b3c0 0t0 187400250 socketjava 14216 imhtp 36u sock 0,6 0t0 106323858 can't identify protocoljava 14216 imhtp 130u unix 0xffff880235e539c0 0t0 106324660 socketjava 16615 imhtp 36u sock 0,6 0t0 34219267 can't identify protocoljava 16615 imhtp 145u unix 0xffff88023924e080 0t0 34219975 socketjava 16870 imhtp 38u sock 0,6 0t0 198357475 can't identify protocoljava 16870 imhtp 56u unix 0xffff8802392c7c80 0t0 198358088 socketjava 16870 imhtp 65u unix 0xffff8802392c7c80 0t0 198358088 socketjava 16870 imhtp 66u unix 0xffff8802392c7c80 0t0 198358088 socketjava 17021 imhtp 36u sock 0,6 0t0 213679956 can't identify protocoljava 19405 imhtp 36u sock 0,6 0t0 177291674 can't identify protocoljava 22165 imhtp 36u sock 0,6 0t0 271476844 can't identify protocoljava 22165 imhtp 40u unix 0xffff88004aea26c0 0t0 271477354 socketjava 30738 imhtp 36u sock 0,6 0t0 269955359 can't identify protocoljava 30738 imhtp 41u sock 0,6 0t0 271839241 can't identify protocoljava 30738 imhtp 42u sock 0,6 0t0 271839255 can't identify protocoljava 30738 imhtp 43u sock 0,6 0t0 271839242 can't identify protocoljava 30738 imhtp 44u sock 0,6 0t0 271839253 can't identify protocoljava 30738 imhtp 46u sock 0,6 0t0 271839257 can't identify protocoljava 30738 imhtp 47u sock 0,6 0t0 271839256 can't identify protocoljava 30738 imhtp 51u sock 0,6 0t0 271839258 can't identify protocoljava 30738 imhtp 53u sock 0,6 0t0 271839259 can't identify protocoljava 30738 imhtp 60u sock 0,6 0t0 271839248 can't identify protocoljava 30738 imhtp 61u sock 0,6 0t0 271839260 can't identify protocoljava 30738 imhtp 124u unix 0xffff88004aea2cc0 0t0 270139880 socketjava 31781 imhtp 36u sock 0,6 0t0 207958180 can't identify protocol 可以发现，Name列的值为“an’t identify protocol”，socket找不到打开的文件。 1234567891011121314151617181920212223242526272829303132333435363738[2017-03-02 22:19:18 ERROR]-[TcpServer - LogicWork0] XiaoZCallback.getXiaoZView(292) | openid: oBBmBjh7sOne_Ay19Lkym1-L307sjava.net.MalformedURLException: Illegal character in URL at sun.net.www.http.HttpClient.getURLFile(HttpClient.java:588) at sun.net.www.protocol.http.HttpURLConnection.writeRequests(HttpURLConnection.java:464) at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1216) at cn.network.http.HttpTool.httpContentGet(HttpTool.java:269) at cn.network.http.HttpTool.httpContentGet(HttpTool.java:252) at com.chinanet.callback.XiaoZCallback.getXiaoZView(XiaoZCallback.java:213) at com.chinanet.callback.XiaoZCallback.getXiaoZhiContent(XiaoZCallback.java:65) at com.chinanet.mng.XiaoIMng.process(XiaoIMng.java:93)[2017-03-02 22:20:03 ERROR]-[TcpServer - LogicWork0] XiaoZCallback.getXiaoZView(292) | openid: oBBmBjueL7mCFFyDdZkNchqqgvX4net.sf.json.JSONException: Unterminated string at character 736 of &#123;"startTime":"2017-03-02 22:15:00","errCode":0,"answers":[&#123;"menuItemsIDs":["CUSTOMER_KBDATAID_1565330","CUSTOMER_KBDATAID_1473994","CUSTOMER_KBDATAID_1567944"],"menuItemsAnswers":["您好！感谢您使用中国电信业务。中国电信天翼手机、固定电话和小灵通用户开通七彩铃音业务后，可以为呼叫自己电话的其他主叫用户预先设置时尚歌曲、幽默言语、佳节问候或企业欢迎语等个性化回铃音，不再是单调的“嘟…嘟…”提示音，为拨打电话的人带来独特的音乐和语音感受。功能包括：基础功能、赠送功能、铃音盒功能、铃音群组功能、指定铃音功能、111120自听铃音功能、七彩铃音“1#复制”功能、短信一键订购功能。适用于中国电信天翼手机、固定电话和小灵通用户。月租费：七彩铃音5元/月，铃音盒0元/月-5元/月，111120自听铃音0元/月，七彩铃音“1#复制”0元/月。可以通过短信、爱音乐官方网站、118100/118101电话自助办理或通过10000号、营业厅办理。七彩铃音短信指令：1、开通方式：发送“6042”或“KTQCLY”至10001开通七彩铃音。2、取消方式：发送“6043”或“QXQCLY”至10001取消七彩铃音。铃音盒短信指令：1、订购铃音盒：编辑“M”发送至118100或10659100。2、退订铃音盒：编辑“YYH”发送至118100或10659100退。了解更多点击：http://gd.zhidao.189.cn/ckb/knowledge_detail/jy/20130326/29691"],"menuItems":["想知道你的彩铃业务是什么样的,给我介绍一下呗.","作为一个联通用户,我要办理彩铃,你们有什么好介绍的吗?","我是老联通用户,我要办理彩铃,你们有什么好介绍的吗?"],"answerPat":"您好,为您找到以下信息：&lt;@菜单选项&gt;谢谢！","answerType":"FAQ菜单","channel":"WX","userNumberType":"","userNumber":"waJjIHP2qVkf_Z_h","userID":"QricyzdVQtVF_z_Hjw8ovjEYcrF_z_HsGeu0Zgjw5PLG/0cj0D4f_Z_h","date":"2017-03-02"&#125;],"answersCount":1,"endTime":"2017-03-02 22:15:01"&#125; at net.sf.json.util.JSONTokener.syntaxError(JSONTokener.java:512) at net.sf.json.util.JSONTokener.nextString(JSONTokener.java:244) at net.sf.json.util.JSONTokener.nextValue(JSONTokener.java:352) at net.sf.json.JSONArray._fromJSONTokener(JSONArray.java:1158) at net.sf.json.JSONArray.fromObject(JSONArray.java:147) at net.sf.json.util.JSONTokener.nextValue(JSONTokener.java:358) at net.sf.json.JSONObject._fromJSONTokener(JSONObject.java:1128) at net.sf.json.JSONObject.fromObject(JSONObject.java:179) at net.sf.json.util.JSONTokener.nextValue(JSONTokener.java:355) at net.sf.json.JSONArray._fromJSONTokener(JSONArray.java:1158) at net.sf.json.JSONArray.fromObject(JSONArray.java:147) at net.sf.json.util.JSONTokener.nextValue(JSONTokener.java:358) at net.sf.json.JSONObject._fromJSONTokener(JSONObject.java:1128) at net.sf.json.JSONObject._fromString(JSONObject.java:1317) at net.sf.json.JSONObject.fromObject(JSONObject.java:185) at net.sf.json.JSONObject.fromObject(JSONObject.java:154) at com.chinanet.callback.XiaoZCallback.getXiaoZView(XiaoZCallback.java:216) at com.chinanet.callback.XiaoZCallback.getXiaoZhiContent(XiaoZCallback.java:67) at com.chinanet.mng.XiaoIMng.process(XiaoIMng.java:93) at com.chinanet.handle.ServerHandler.defaultProcess(ServerHandler.java:700) at com.chinanet.handle.ServerHandler.internalHandle(ServerHandler.java:322) at com.chinanet.handle.ServerHandler.handle(ServerHandler.java:139)]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[linux dump内存快照等]]></title>
    <url>%2Fposts%2F880a8e7e.html</url>
    <content type="text"><![CDATA[kill之前先dump每次线上环境一出问题，大家就慌了， 通常最直接的办法回滚重启，以减少故障时间， 这样现场就被破坏了，要想事后查问题就麻烦了， 有些问题必须在线上的大压力下才会发生， 线下测试环境很难重现， 不太可能让开发或Appops在重启前， 先手工将出错现场所有数据备份一下， 所以最好在kill脚本之前调用dump， 进行自动备份，这样就不会有人为疏忽。 dump脚本示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172JAVA_HOME=/usr/javaOUTPUT_HOME=~/outputDEPLOY_HOME=`dirname $0`HOST_NAME=`hostname`DUMP_PIDS=`ps --no-heading -C java -f --width 1000 | grep "$DEPLOY_HOME" |awk '&#123;print $2&#125;'`if [ -z "$DUMP_PIDS" ]; then echo "The server $HOST_NAME is not started!" exit 1;fiDUMP_ROOT=$OUTPUT_HOME/dumpif [ ! -d $DUMP_ROOT ]; then mkdir $DUMP_ROOTfiDUMP_DATE=`date +%Y%m%d%H%M%S`DUMP_DIR=$DUMP_ROOT/dump-$DUMP_DATEif [ ! -d $DUMP_DIR ]; then mkdir $DUMP_DIRfiecho -e "Dumping the server $HOST_NAME ...\c"for PID in $DUMP_PIDS ; do $JAVA_HOME/bin/jstack $PID &gt; $DUMP_DIR/jstack-$PID.dump 2&gt;&amp;1 echo -e ".\c" $JAVA_HOME/bin/jinfo $PID &gt; $DUMP_DIR/jinfo-$PID.dump 2&gt;&amp;1 echo -e ".\c" $JAVA_HOME/bin/jstat -gcutil $PID &gt; $DUMP_DIR/jstat-gcutil-$PID.dump 2&gt;&amp;1 echo -e ".\c" $JAVA_HOME/bin/jstat -gccapacity $PID &gt; $DUMP_DIR/jstat-gccapacity-$PID.dump 2&gt;&amp;1 echo -e ".\c" $JAVA_HOME/bin/jmap $PID &gt; $DUMP_DIR/jmap-$PID.dump 2&gt;&amp;1 echo -e ".\c" $JAVA_HOME/bin/jmap -heap $PID &gt; $DUMP_DIR/jmap-heap-$PID.dump 2&gt;&amp;1 echo -e ".\c" $JAVA_HOME/bin/jmap -histo $PID &gt; $DUMP_DIR/jmap-histo-$PID.dump 2&gt;&amp;1 echo -e ".\c" if [ -r /usr/sbin/lsof ]; then /usr/sbin/lsof -p $PID &gt; $DUMP_DIR/lsof-$PID.dump echo -e ".\c" fidoneif [ -r /usr/bin/sar ]; then/usr/bin/sar &gt; $DUMP_DIR/sar.dumpecho -e ".\c"fiif [ -r /usr/bin/uptime ]; then/usr/bin/uptime &gt; $DUMP_DIR/uptime.dumpecho -e ".\c"fiif [ -r /usr/bin/free ]; then/usr/bin/free -t &gt; $DUMP_DIR/free.dumpecho -e ".\c"fiif [ -r /usr/bin/vmstat ]; then/usr/bin/vmstat &gt; $DUMP_DIR/vmstat.dumpecho -e ".\c"fiif [ -r /usr/bin/mpstat ]; then/usr/bin/mpstat &gt; $DUMP_DIR/mpstat.dumpecho -e ".\c"fiif [ -r /usr/bin/iostat ]; then/usr/bin/iostat &gt; $DUMP_DIR/iostat.dumpecho -e ".\c"fiif [ -r /bin/netstat ]; then/bin/netstat &gt; $DUMP_DIR/netstat.dumpecho -e ".\c"fiecho "OK!" 具体语句示例12345678910###########################################################################################/usr/java/jdk1.6.0_45/bin/jstack 30965 &gt; /opt/wxOpenServer/jstack-30965.dump 2&gt;&amp;1;/usr/java/jdk1.6.0_45/bin/jinfo 30965 &gt; /opt/wxOpenServer/jinfo-30965.dump 2&gt;&amp;1;/usr/java/jdk1.6.0_45/bin/jstat -gcutil 30965 &gt; /opt/wxOpenServer/jstat-gcutil-30965.dump 2&gt;&amp;1;/usr/java/jdk1.6.0_45/bin/jstat -gccapacity 30965 &gt; /opt/wxOpenServer/jstat-gccapacity-30965.dump 2&gt;&amp;1;/usr/java/jdk1.6.0_45/bin/jmap 30965 &gt; /opt/wxOpenServer/jmap-30965.dump 2&gt;&amp;1;/usr/java/jdk1.6.0_45/bin/jmap -heap 30965 &gt; /opt/wxOpenServer/jmap-heap-30965.dump 2&gt;&amp;1;/usr/java/jdk1.6.0_45/bin/jmap -histo 30965 &gt; /opt/wxOpenServer/jmap-histo-30965.dump 2&gt;&amp;1;/usr/sbin/lsof -p 30965 &gt; /opt/wxOpenServer/lsof-30965.dump;########################################################################################### lsof输出各列信息的意义如下：COMMAND：进程的名称 PID：进程标识符 USER：进程所有者 FD：文件描述符，应用程序通过文件描述符识别该文件。如cwd、txt等 TYPE：文件类型，如DIR、REG等 DEVICE：指定磁盘的名称 SIZE：文件的大小 NODE：索引节点（文件在磁盘上的标识） NAME：打开文件的确切名称 lsof which httpd //那个进程在使用apache的可执行文件 lsof /etc/passwd //那个进程在占用/etc/passwd lsof /dev/hda6 //那个进程在占用hda6 lsof /dev/cdrom //那个进程在占用光驱 lsof -c sendmail //查看sendmail进程的文件使用情况 lsof -c courier -u ^zahn //显示出那些文件被以courier打头的进程打开，但是并不属于用户zahn lsof -p 30297 //显示那些文件被pid为30297的进程打开 lsof -D /tmp 显示所有在/tmp文件夹中打开的instance和文件的进程。但是symbol文件并不在列 lsof -u1000 //查看uid是100的用户的进程的文件使用情况 lsof -utony //查看用户tony的进程的文件使用情况 lsof -u^tony //查看不是用户tony的进程的文件使用情况(^是取反的意思) lsof -i //显示所有打开的端口 lsof -i:80 //显示所有打开80端口的进程 lsof -i -U //显示所有打开的端口和UNIX domain文件 lsof -i UDP@[url]www.akadia.com:123 //显示那些进程打开了到www.akadia.com的UDP的123(ntp)端口的链接 lsof -i tcp@ohaha.ks.edu.tw:ftp -r //不断查看目前ftp连接的情况(-r，lsof会永远不断的执行，直到收到中断信号,+r，lsof会一直执行，直到没有档案被显示,缺省是15s刷新) lsof -i tcp@ohaha.ks.edu.tw:ftp -n //lsof -n 不将IP转换为hostname，缺省是不加上-n参数]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sublime Text 的一些快捷键]]></title>
    <url>%2Fposts%2F78ee2138.html</url>
    <content type="text"><![CDATA[Sublime Text 的一些快捷键 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869Ctrl+D 选词 （反复按快捷键，即可继续向下同时选中下一个相同的文本进行同时编辑）Ctrl+G 跳转到相应的行Ctrl+J 合并行（已选择需要合并的多行时）Ctrl+L 选择整行（按住-继续选择下行）Ctrl+M 光标移动至括号内开始或结束的位置Ctrl+T 词互换Ctrl+U 软撤销Ctrl+P 查找当前项目中的文件和快速搜索；输入 @ 查找文件主标题/函数；或者输入 : 跳转到文件某行；Ctrl+R 快速列出/跳转到某个函数Ctrl+K Backspace 从光标处删除至行首Ctrl+K+B 开启/关闭侧边栏Ctrl+KK 从光标处删除至行尾Ctrl+K+T 折叠属性Ctrl+K+U 改为大写Ctrl+K+L 改为小写Ctrl+K+0 展开所有Ctrl+Enter 插入行后（快速换行）Ctrl+Tab 当前窗口中的标签页切换Ctrl+Shift+A 选择光标位置父标签对儿Ctrl+Shift+D 复制光标所在整行，插入在该行之前ctrl+shift+F 在文件夹内查找，与普通编辑器不同的地方是sublime允许添加多个文件夹进行查找Ctrl+Shift+K 删除整行Ctrl+Shift+L 鼠标选中多行（按下快捷键），即可同时编辑这些行Ctrl+Shift+M 选择括号内的内容（按住-继续选择父括号）Ctrl+Shift+P 打开命令面板Ctrl+Shift+/ 注释已选择内容Ctrl+Shift+↑可以移动此行代码，与上行互换Ctrl+Shift+↓可以移动此行代码，与下行互换Ctrl+Shift+[ 折叠代码Ctrl+Shift+] 展开代码Ctrl+Shift+Enter 光标前插入行Ctrl+PageDown 、Ctrl+PageUp 文件按开启的前后顺序切换Ctrl+Z 撤销Ctrl+Y 恢复撤销Ctrl+F2 设置/取消书签Ctrl+/ 注释整行（如已选择内容，同“Ctrl+Shift+/”效果）Ctrl+鼠标左键 可以同时选择要编辑的多处文本Shift+鼠标右键（或使用鼠标中键）可以用鼠标进行竖向多行选择Shift+F2 上一个书签Shift+Tab 去除缩进Alt+Shift+1（非小键盘）窗口分屏，恢复默认1屏Alt+Shift+2 左右分屏-2列Alt+Shift+3 左右分屏-3列Alt+Shift+4 左右分屏-4列Alt+Shift+5 等分4屏Alt+Shift+8 垂直分屏-2屏Alt+Shift+9 垂直分屏-3屏Ctrl+Shift+分屏序号 将当前焦点页分配到分屏序号页Alt+. 闭合当前标签Alt+F3 选中文本按下快捷键，即可一次性选择全部的相同文本进行同时编辑Tab 缩进 自动完成F2 下一个书签F6 检测语法错误F9 行排序(按a-z)F11 全屏模式]]></content>
      <categories>
        <category>Sublime Text</category>
      </categories>
      <tags>
        <tag>key</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sublime Text 3 的一些常用插件]]></title>
    <url>%2Fposts%2F9b6062f9.html</url>
    <content type="text"><![CDATA[Sublime Text 3 的一些常用插件[TOC] AdministrativeThese plugins are kind of ‘meta’ because they are not concerned with writing code. Package ControlThis package enables you to install other packages. Since build 3124, you can install it within Sublime via Tools ➡ Install Package Control. AdvancedNewFileA better way to create new files. For instance, it automatically creates a folder when needed. SideBarEnhacementsAdds features such as renaming to the sidebar. A File IconAdd icons to the files in the sidebar. ProjectManagerOrganizing project files by putting them in a central location. TodoReviewScans files for TODOs and more. FindKeyConflictsKey conflicts are inevitably when you use a lot of plugins. Editor ConfigMaintain consistent coding styles between different editors. Sync SettingsKeep settings in sync via Github-Gist. GeneralUseful for all languages. All CompleteIndexes all open files for auto-completion. BracketHighlighterImproves the already built-in highlighting. TerminalOpen Terminal with current working directory set to the directory of the open file on a hot key. AlignTabAlign your code by :, =, =&gt;, %, ,,| or your own RegEx. GitGutterDisplays changes in the gutter (left to the line numbers). GitIncludes some git commands into Sublime. GitSavvyFull git and GitHub integration. GitignoreFetches templates for the .gitignore provided by Github. DashDocOpen current selection in Dash on a hot key. Local HistoryKeep a local history of your files. Even though I use git on almost every project, I still don’t commit every change. It gives a better feeling to have the possibility to go back to every change. Javascript Tern for SublimeStatic Javascript code analyzer with auto-completion, function argument hints, ‘go to definition’ and more. The installation and configuration can be a little bit tricky but it’s worth it. Choose Tern over SublimeCodeIntel (unmaintained) and JavaScript Completions (buggy). JavaScript &amp; NodeJS Snippets Console WrapFast way to log to console. JsPrettierIntegration of Prettier, the opinionated JavaScript formatter. BabelSyntax definitions for ES6 JavaScript with React JSX extensions. TypeScript Elm Language Support HTML &amp; CSS SassSass is a preprocessor extending CSS and this plugins adds the language support. SassSolutionsAuto-complete variables/mixins from your ‘settings.scss’ file. CSS3Replaces the built-in CSS support with a more up-to-date information. Includes cssnext support. Follow the instructions to reduce misbehaviour with other plugins. EmmetAllows you to write HTML very fast. You have to learn their way though. Color Highlighter Linter SublimeLinter SublimeLinter-HTML-tidy SublimeLinter-contrib-stylelintFor CSS. Choose stylelint over SublimeLinter-CSSlint. SublimeLinter-contrib-SCSS-lint SublimeLinter-contrib-ESLint SublimeLinter-flow SublimeLinter-contrib-elm-make SublimeLinter-JSON Other omniMarkupPreviewer使用 ctrl+alt+o打开浏览器实时预览]]></content>
      <categories>
        <category>Sublime Text</category>
      </categories>
      <tags>
        <tag>plugins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nodejs 使用]]></title>
    <url>%2Fposts%2F8d0f4649.html</url>
    <content type="text"><![CDATA[nvm：node 和 npm 多版本管理 windows 安装包下载：https://github.com/coreybutler/nvm-windows/releases 配置环境变量 1234567891011121314# window 下配置## 假设 nvm 安装目录是D:\nvm，则配置：NVM_HOME=D:\nvmNVM_SYMLINK=D:\nvm\nodejs# D:\nvm\nodejs\bin\node## PATH 配置，新增%NVM_HOME%%NVM_SYMLINK%# mac 在export NVM_DIR=&quot;$HOME/.nvm&quot;export NVM_SYMLINK_CURRENT=true# ~/.nvm/current/bin/node 更换下载源 123456789# 1、进入 nvm 安装目录，编辑 setting.txt，追加两行代码node_mirror: https://npm.taobao.org/mirrors/node/# 配置npm_mirror可能会导致npm、cnpm等安装依赖时各种错误# npm_mirror: https://npm.taobao.org/mirrors/npm/# 2、通过命令行配置nvm node_mirror https://npm.taobao.org/mirrors/node/# 配置npm_mirror可能会导致npm、cnpm等安装依赖时各种错误# nvm npm_mirror https://npm.taobao.org/mirrors/npm/ 使用 nvm 管理版本 12345678910# 安装最新版本nodenvm install latest# 安装某一个版本 nodenvm install 10.22.0# 使用某一具体版本nvm use 14.3.0# 列出当前已安装的所有版本nvm list# 卸载某一具体版本nvm uninstall 14.2.0 使用nvm管理node、npm，不需要配置npm下载包路径 yarn123456789# 查询源地址yarn config get registry# 配置taobao源加速yarn config set registry &apos;https://registry.npm.taobao.org&apos;# 安装组件、插件yarn add ant-design-vueyarn add --dev hard-source-webpack-plugin npm配置国内访问外网是很慢的，安装NodeJS是自带的npm地址默认是：http://registry.npmjs.org，访问很慢，所以一般换成国内镜像地址。 用户目录下：.npmrc 1234# 使用 NVM 安装node、npm不需要配置prefix、cache# prefix=D:\nvm\node_global# cache=D:\nvm\node_cacheregistry=https://registry.npm.taobao.org/ 通过config命令 123npm config set registry https://registry.npm.taobao.org/ npm info underscore#（如果配置成功，这个命令会有字符串response）npm --registry=https://registry.npm.taobao.org 命令行指定 1npm --registry https://registry.npm.taobao.org/ info underscore 编辑node_modules/npm/.npmrc加入下面内容 1registry = https://registry.npm.taobao.org/ 如果上面的npm地址不行的话，可以试试淘宝的npmhttps://registry.npm.taobao.org或者https://r.npm.taobao.org/ 123npm set registry https://registry.npm.taobao.org/# 或者npm --registry https://registry.npm.taobao.org/ info underscore npm下载包路径在安装完nodejs后，npm install -g jshint是被安装在默认路径（C:\Users\用户名\AppData\Roaming\npm）下的 可以通过修改nodejs安装路径下的node_modules/npm/.npmrc文件prefix=D:\MyTools\nodejs\node_global （修改全局路径）cache=D:\MyTools\nodejs\node_cache （修改全局路径） 请注意prefix、cache不能设置成一样的路径，否则通过npm安装模块时，会报错 npm 使用123456789101112# -S 是--save 的缩写，它可以让你安装的模块记录到package.json文件当中npm install -S xxx# 这是删除模块，也可以删除全局模块npm uninstall xxxnpm uninstall -g xxx# -D就是--save-dev 这样安装的包的名称及版本号就会存在package.json的devDependencies这个里面，而--save会将包的名称及版本号放在dependencies里面npm install -D xxx# 显示 webpack 配置npm run eject nrm：npm registry 设置 使用 nrm 进行多 registry 切换 1234567891011121314$ npm install -g nrm$ nrm lsD:\Workspace\vuejs-project&gt;nrm ls* npm ---- https://registry.npmjs.org/ cnpm --- http://r.cnpmjs.org/ taobao - https://registry.npm.taobao.org/ nj ----- https://registry.nodejitsu.com/ rednpm - http://registry.mirror.cqupt.edu.cn/ npmMirror https://skimdb.npmjs.com/registry/ edunpm - http://registry.enpmjs.org/# 切换源$ nrm use taobaoRegistry has been set to: https://registry.npm.taobao.org/ npm-check检查依赖包版本123456# 安装 npm-checknpm install -g npm-check# 检查 npm 包版本npm-check -u -gnpm-check -u -Snpm-check -u -D]]></content>
      <categories>
        <category>nodejs</category>
      </categories>
      <tags>
        <tag>npm</tag>
        <tag>cnpm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xampp 安装 memcache 监控]]></title>
    <url>%2Fposts%2Fd01399d3.html</url>
    <content type="text"><![CDATA[xampp安装memcache监控现在 memadmin下载memadmin，解压到xampp/htdocs下 查看 php 版本信息123&lt;?php echo phpinfo();?&gt; 下载 php-memcache.dll根据查看到的php的信息，在php-memcache下载对应本版的Thread Safe，里面包含了php-memcache.dll。 解压下载包，然后把php-memcache.dll拷贝到xampp/php/ext下 在xampp/php/php.ini最后添加以下内容12345678;php-memcachedextension=php_memcache.dll[Memcache]memcache.allow_failover = 1memcache.max_failover_attempts=20memcache.chunk_size =8192memcache.default_port = 11211 访问 memadminhttp://host:port/memadmin]]></content>
      <categories>
        <category>memcache</category>
      </categories>
      <tags>
        <tag>xampp</tag>
        <tag>memcache</tag>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo初体验]]></title>
    <url>%2Fposts%2F2dba5ee9.html</url>
    <content type="text"><![CDATA[node.js安装node.js去官网现在并安装，这里安装路径选到D:\nodejs 改变原有的环境变量我们要先配置npm的全局模块的存放路径以及cache的路径，例如我希望将以上两个文件夹放在NodeJS的主目录下，便在NodeJs下建立”node_global”及”node_cache”两个文件夹，输入以下命令改变npm配置12npm config set prefix &quot;D:\nodejs\node_global&quot;npm config set cache &quot;D:\nodejs\node_cache&quot; 这个不配置也可以？（在系统环境变量添加系统变量NODE_PATH，输入路径D:\nodejs\node_global\node_modules）此后所安装的模块都会安装到改路径下 安装淘宝npm（cnpm）输入以下命令1npm install -g cnpm --registry=https://registry.npm.taobao.org 输入cnpm -v输入是否正常1cnpm -v 安装部署hexo + github page初体验1npm install -g hexo-cli 本地目录 hexo 文件夹，进去这个文件夹，依次执行下面的命令1234cd hexohexo init# Hexo随后会自动在目标文件夹建立网站所需要的文件npm install 启动本地Hexo服务1hexo server Create a new post1hexo new 'blog name' 在hexo new文章时，需要stop server，否则会出现2次这个文章 执行下面的命令，将markdown文件生成静态网页1hexo generate 更换主题12cd themesgit clone https://github.com/litten/hexo-theme-yilia.git 配置主题 _config.yml 文件，修改里面的 theme 为 hexo-theme-yilia 配置github仓库在_config.yml 文件最后添加如下内容12345678# Deployment## Docs: http://hexo.io/docs/deployment.htmldeploy: type: git repository: https://github.com/xxx/xxx.github.io.git # ssh模式 #repository: https://github.com/xxx/xxx.github.io.git branch: master 配置好后，依次执行123hexo cleanhexo ghexo d 出现 Deploy done: git 说明配置成功 如果提示 ERROR Deployer not found: git，则要安装 hexo-deployer-git 插件12cd hexonpm install hexo-deployer-git --save 部署到github，每次部署可以执行一下命令123hexo cleanhexo generatehexo deploy 绑定域名在你本地的 hexo 项目根目录的 source 目录下创建 CNAME 文件，并在 CNAME 中输入绑定的域名 使用问题hexo d出现错误执行hexo clean &amp;&amp; hexo g &amp;&amp; hexo d出现一下错误，多试几次又成功了，之后没有继续追查问题123456789101112131415161718fatal: TaskCanceledException encountered. ▒▒ȡ▒▒һ▒▒▒▒▒▒bash: /dev/tty: No such device or addresserror: failed to execute prompt script (exit code 1)fatal: could not read Username for &apos;https://github.com&apos;: No errorFATAL Something&apos;s wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.htmlError: fatal: TaskCanceledException encountered. ��ȡ��һ��������bash: /dev/tty: No such device or addresserror: failed to execute prompt script (exit code 1)fatal: could not read Username for &apos;https://github.com&apos;: No error at ChildProcess.&lt;anonymous&gt; (D:\Workspace\foreveryang321.github.io\node_modules\hexo-util\lib\spawn.js:37:17) at emitTwo (events.js:106:13) at ChildProcess.emit (events.js:191:7) at ChildProcess.cp.emit (D:\Workspace\foreveryang321.github.io\node_modules\cross-spawn\lib\enoent.js:40:29) at maybeClose (internal/child_process.js:886:16) at Process.ChildProcess._handle.onexit (internal/child_process.js:226:5) 图片显示问题使用hexo-abbrlink和`hexo-asset-image@0.0.3`会导致图片路径问题。 hexo-asset-image@0.0.5版本已经修复该问题 或者参考：https://github.com/foreveryang321/hexo-asset-image]]></content>
      <categories>
        <category>hexo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[git 使用]]></title>
    <url>%2Fposts%2F4896de77.html</url>
    <content type="text"><![CDATA[基本命令123456789git addgit commitgit pushgit statusgit rm &lt;-f&gt;git fetchgit mergegit pull fatal: remote origin already exists错误先删除远程 Git 仓库1$ git remote rm origin 再添加远程 Git 仓库12$ git remote add origin https://github.com/xxx/xxxx.git# git remote remove origin 简易的命令行入门教程: Git 全局设置:12git config --global user.name "xxxx"git config --global user.email "xxxx@qq.com" 创建 git 仓库12345678910mkdir tscd tsgit inittouch README.mdgit add README.mdgit commit -m "first commit"git remote add origin https://github.com/xxx/xxxx.git# git pull --allow-unrelated-historiesgit push -u origin master# git push --set-upstream origin master 已有项目?123cd existing_git_repogit remote add origin https://github.com/xxx/xxxx.gitgit push -u origin master git flow分支共有5种类型 1) master，最终发布版本，整个项目中有且只有一个 2) develop，项目的开发分支，原则上项目中有且只有一个 3) feature，功能分支，用于开发一个新的功能 4) release，预发布版本，介于develop和master之间的一个版本，主要用于测试 5) hotfix，修复补丁，用于修复master上的bug，直接作用于master 回滚操作123456# 查看记录git log --oneline# 回滚到上一次提交git reset HEAD^# 强制提交到远程仓库（会覆盖掉reset前的提交记录）git push origin master -f fork后同步更新12345678git remote -v git remote add upstream git@github.com:xxx/xxx.gitgit fetch upstreamgit merge upstream/master# git merge upstream/develop# 强制同步源仓库（upstream）# git fetch upstream &amp;&amp; git reset --hard upstream/master &amp;&amp; git push -fgit push 大于 50MB 的文件处理12345# 进入本地仓库目录初始化LFSgit lfs installgit lfs track "*.pdf"# 或者 git add .gitattributes，类似于.gitignore文件的编写# 接下来就可以像平时使用git那样正常使用了，可以将大文件提交到GitHub了]]></content>
      <categories>
        <category>Git</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Maven 使用]]></title>
    <url>%2Fposts%2Fe3a1de67.html</url>
    <content type="text"><![CDATA[Maven 打包 jarspring-boot插件打包123456789&lt;build&gt; &lt;finalName&gt;$&#123;project.artifactId&#125;&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;!-- 打包 --&gt;&lt;build&gt; &lt;finalName&gt;$&#123;project.artifactId&#125;&lt;/finalName&gt; &lt;resources&gt; &lt;!-- 指定 src/main/resources下所有文件及文件夹为资源文件 --&gt; &lt;resource&gt; &lt;targetPath&gt;$&#123;project.build.directory&#125;/classes&lt;/targetPath&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*&lt;/include&gt; &lt;!-- &lt;include&gt;**/*.xml&lt;/include&gt; &lt;include&gt;**/*.properties&lt;/include&gt; --&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;!-- 使用com.alibaba.dubbo.container.Main启动应用的话，要把spring配置放到/META-INF/spring下 --&gt; &lt;resource&gt; &lt;targetPath&gt;$&#123;project.build.directory&#125;/classes/META-INF/spring&lt;/targetPath&gt; &lt;directory&gt;src/main/resources/spring&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;spring-context.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;!-- more --&gt; &lt;plugins&gt; &lt;!-- 打包jar文件时，配置manifest文件，加入lib包的jar依赖 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;classesDirectory&gt;target/classes/&lt;/classesDirectory&gt; &lt;archive&gt; &lt;manifest&gt; &lt;mainClass&gt;com.alibaba.dubbo.container.Main&lt;/mainClass&gt; &lt;!-- 打包时 MANIFEST.MF文件不记录的时间戳版本 --&gt; &lt;useUniqueVersions&gt;false&lt;/useUniqueVersions&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;/manifest&gt; &lt;manifestEntries&gt; &lt;Class-Path&gt;.&lt;/Class-Path&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 打包jar时，把依赖的第三方jar包，放到lib/文件下 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-dependencies&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;type&gt;jar&lt;/type&gt; &lt;includeTypes&gt;jar&lt;/includeTypes&gt; &lt;useUniqueVersions&gt;false&lt;/useUniqueVersions&gt; &lt;outputDirectory&gt; $&#123;project.build.directory&#125;/lib &lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 配置阿里云私有库123456789101112&lt;mirror&gt; &lt;id&gt;aliyun-nexus&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt;&lt;/mirror&gt;&lt;!--&lt;mirror&gt; &lt;id&gt;aliyun-nexus-public-snapshots&lt;/id&gt; &lt;mirrorOf&gt;public-snapshots&lt;/mirrorOf&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/repositories/snapshots/&lt;/url&gt;&lt;/mirror&gt;--&gt; 发布 jar 到私有仓库Maven setting.xml 配置123456789101112131415&lt;server&gt; &lt;id&gt;maven2-weixin-public&lt;/id&gt; &lt;username&gt;weixin&lt;/username&gt; &lt;password&gt;weixin&lt;/password&gt;&lt;/server&gt;&lt;server&gt; &lt;id&gt;maven2-weixin-release&lt;/id&gt; &lt;username&gt;weixin&lt;/username&gt; &lt;password&gt;weixin&lt;/password&gt;&lt;/server&gt;&lt;server&gt; &lt;id&gt;maven2-weixin-snapshots&lt;/id&gt; &lt;username&gt;weixin&lt;/username&gt; &lt;password&gt;weixin&lt;/password&gt;&lt;/server&gt; 项目 pom.xml 配置12345678910111213&lt;!-- 发布 jar 到中央仓库 --&gt;&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;maven2-weixin-release&lt;/id&gt; &lt;name&gt;Nexus Release Repository&lt;/name&gt; &lt;url&gt;http://maven.ctim:8081/repository/maven2-weixin-release/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;maven2-weixin-snapshots&lt;/id&gt; &lt;name&gt;Nexus Snapshot Repository&lt;/name&gt; &lt;url&gt;http://maven.ctim:8081/repository/maven2-weixin-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt;&lt;/distributionManagement&gt; 注意，pom.xml中的id要和setting.xml中配置的一致 发布源码12345678910111213&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-sources&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 如果不发布源码，可以使用如下配置，只打包源码，不发布到私有仓库 123456789101112131415&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-sources&lt;/id&gt; &lt;!-- 只打包源码，不发布元源码到私有仓库 --&gt; &lt;phase&gt;none&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 执行 deploy 发布 jar 到私有仓库1mvn clean deploy -Dmaven.test.skip=true 注意：release 版本只能上传一次，SNAPSHOT 版本可以无限次上传 使用私有仓库下载 jar 在 setting.xml 配置 mirror 12345678910&lt;mirror&gt; &lt;id&gt;aliyun-nexus&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt;&lt;/mirror&gt;&lt;mirror&gt; &lt;id&gt;maven2-weixin-public&lt;/id&gt; &lt;mirrorOf&gt;maven2-weixin-public&lt;/mirrorOf&gt; &lt;url&gt;http://maven.ctim:8081/repository/maven2-weixin-public/&lt;/url&gt;&lt;/mirror&gt; 在 setting.xml 配置 profile 并激活 1234567891011121314151617&lt;profile&gt; &lt;id&gt;wechat&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;maven2-weixin-public&lt;/id&gt; &lt;name&gt;Nexus Release Repository&lt;/name&gt; &lt;url&gt;http://maven.ctim:8081/repository/maven2-weixin-public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt;&lt;/profile&gt; 激活 profile 123&lt;activeProfiles&gt; &lt;activeProfile&gt;wechat&lt;/activeProfile&gt;&lt;/activeProfiles&gt;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IntelliJ IDEA 插件]]></title>
    <url>%2Fposts%2Fb7ca9e0f.html</url>
    <content type="text"><![CDATA[IntelliJ插件篇Maven Helper 我一般用这款插件来查看maven的依赖树。在不使用此插件的情况下，要想查看maven的依赖树就要使用Maven命令maven dependency:tree来查看依赖。想要查看是否有依赖冲突也可以使用mvn dependency:tree -Dverbose -Dincludes=:只查看关心的jar包，但是这样还是需要我执行命令，并且当项目比较复杂的时候，这个过程是比较漫长的。maven helper就能很好的解决这个问题。 GsonFormat 快捷键Alt+S或者鼠标右键选择Generate&gt;GsonFormat InnerBuilder 快捷键Alt+Insert、Shift+Alt+B或者鼠标右键选择Generate-&gt;Builder，一般给实体类建立get方法，实体类的属性使用final标记，对于不能空的值，做为Builder构造方法的参数传入，最好有一个实体类做为参数的Builder的构造方法 IntelliJ Setting配置篇spelling 去掉拼写检测Setting-&gt;inspections-&gt;spelling，去掉勾 properties编码配置 Setting-&gt;Editor-&gt;File Encodings，Default encoding for properties files选择UTF-8，并勾上Transparent native-to-ascii conversion 修改注释模版 Setting-&gt;Editor-&gt;File And Code Templates，选择要修改的文件类型，然后在Includes的File Header中修改 代码快捷生成（Live Templates） 可以根据自己需求调整快捷模版，比如sout、soutv、soutm、psvm等 快捷提示（Code Completion） Case sensitive completion可选First letter（首字母匹配）、All（全部匹配）、None（不需要匹配，就是忽略大小写） 软换行 Settings-Editor-General，勾上use soft wraps in editorSettings-&gt;Code Style-&gt;General-&gt;Right margin(columns)Settings-&gt;Code Style-&gt;Java-&gt;Wrapping and Braces-&gt;Ensure rigth margin is not exceeded 虚拟空格（光标在编辑器的任意位置都可以点） Settings-Editor-General，去掉Allow placement of caret at end of line前面的勾 折叠代码 默认单行方法是折叠的，在settings-Editor-General-Code Folding，取消One-line methods就不会折叠了 自动保存文件 Settings-Appearance &amp; Behivior-System Settings，取消“Synchronize file on frame activation” 和“Save files on framedeactivation”的选择。同时我们选择”Save files automatically”, 并将其设置为30秒，这样IDEA依然可以自动保持文件,所以在每次切换时，你需要按下Ctrl+S保存文件 修改过未保存的文件，使用*号标识出来Settings-Editor-General-Editor Tabs-Mark modified tabs width asterisk 快捷键篇 Ctrl + E：最近打开的文件 Ctrl + Shift + E：最近编辑的文件 Double Shift：跳到特定文件夹 Ctrl + Shift + Enter：快速补全行末分号 Ctrl + Shift + A：Rest Client Ctrl + Shift + V：粘贴版历史 Alt + Enter：Language Injection功能，将一个字符串标记为 JSON，就可以非常方便地编写 JSON 了，再也不用担心转义的问题了；同时也可以支持简单正则测试能力 Shift + F7：Debug时可以选择进入哪个方法调试 Ctrl + Alt + L：格式化代码 ##第三方jar包篇 fastjson FastJSON序列化特殊字符BUG问题重现：JSON.toJSONString(“\u0001\u0080\u0002”);在1.1.41+的版本已经修正此问题，https://github.com/alibaba/fastjson/commit/cdf7cb253e961666e2b3c2bdd423abe73ba4324a#diff-0 其他idea maven乱码配置Maven -&gt; Runner -&gt; VM Options-Dfile.encoding=gbk]]></content>
      <categories>
        <category>Intellij</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Paging 分页器实例]]></title>
    <url>%2Fposts%2F30063ce8.html</url>
    <content type="text"><![CDATA[Java中实现一个分页器简单封装一个分页实例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173import java.io.Serializable;import java.util.ArrayList;import java.util.List;/** * 分页器 * * @author Create by YL on 2017/05/29. */public class Paging&lt;E&gt; implements Serializable &#123; private static final long serialVersionUID = -2429864663690465105L; private long page = 1; // 当前页 private long size = 10; // 每页显示记录数 private long total; // 总记录数 private long pages; // 总页数 private long start = 1; // 每页起始数（从1开始） private long end; // 每页结束数 private long prev = 1; // 上一页（从1开始） private long next; // 下一页 private boolean hasPrev; // 判断是否有上一页 private boolean hasNext; // 判断是否有下一页 private List&lt;E&gt; items = new ArrayList&lt;E&gt;(); // 查询结果集 public Paging() &#123; &#125; public Paging(long page, long size) &#123; this.page = page; this.size = size; &#125; public long getSize() &#123; return size; &#125; public void setSize(long size) &#123; this.size = size; &#125; public long getPage() &#123; if (page &gt; this.getPages()) page = this.getPages(); if (page &lt;= 0) page = 1; return page; &#125; public void setPage(long page) &#123; this.page = page; &#125; public long getTotal() &#123; return total; &#125; public void setTotal(long total) &#123; this.total = total; &#125; public long getPages() &#123; long total = this.getTotal(); long size = this.getSize(); if ((total % size) == 0) &#123; pages = total / size; &#125; else &#123; pages = total / size + 1; &#125; return pages == 0 ? 1 : pages; &#125; public void setPages(long pages) &#123; this.pages = pages; &#125; /** * 开始行，可用于Oracle、MySQL等分页 * &lt;pre&gt; * Oracle: rownum &lt;= endRow and rownum &gt; startRow * MySQL: limit startRow, pageSize * &lt;/pre&gt; */ public long getStart() &#123; start = this.getPage() &gt; 0 ? (this.getPage() - 1) * this.getSize() : 0; return start; &#125; public void setStart(long start) &#123; this.start = start; &#125; /** * 结束行，可以用于oracle分页使用 * Oracle: rownum &lt;= endRow */ public long getEnd() &#123; end = this.getStart() + this.getSize(); return end; &#125; public void setEnd(long end) &#123; this.end = end; &#125; public long getPrev() &#123; if (isHasPrev()) &#123; return getPage() - 1; &#125; else &#123; return getPage(); &#125; &#125; public void setPrev(long prev) &#123; this.prev = prev; &#125; public long getNext() &#123; if (isHasNext()) &#123; return getPage() + 1; &#125; else &#123; return getPage(); &#125; &#125; public void setNext(long next) &#123; this.next = next; &#125; public boolean isHasPrev() &#123; return this.getPage() - 1 &gt;= 1; &#125; public void setHasPrev(boolean hasPrev) &#123; this.hasPrev = hasPrev; &#125; public boolean isHasNext() &#123; return getPage() + 1 &lt;= getPages(); &#125; public void setHasNext(boolean hasNext) &#123; this.hasNext = hasNext; &#125; public List&lt;E&gt; getItems() &#123; return items; &#125; public void setItems(List&lt;E&gt; items) &#123; this.items = items; &#125; @Override public String toString() &#123; StringBuilder sb = new StringBuilder(100); sb.append(this.getClass().getSimpleName()); sb.append(" ["); sb.append("page=").append(this.getPage()); sb.append(", size=").append(this.getSize()); sb.append(", total=").append(this.getTotal()); sb.append(", pages=").append(this.getPages()); sb.append(", start=").append(this.getStart()); sb.append(", end=").append(this.getEnd()); sb.append(", prev=").append(this.getPrev()); sb.append(", next=").append(this.getNext()); sb.append(", hasPrev=").append(this.isHasPrev()); sb.append(", hasNext=").append(this.isHasNext()); sb.append(", items=").append(items); sb.append("]"); return sb.toString(); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[druid 连接池配置介绍]]></title>
    <url>%2Fposts%2Ffacb8eb2.html</url>
    <content type="text"><![CDATA[druid连接池配置 filters=stat属性类型是字符串，通过别名的方式配置扩展插件，常用的插件有：监控统计用的 filter:stat日志用的 filter:log4j防御sql注入的 filter:wall initialSize=5初始化时建立物理连接的个数。初始化发生在显示调用init方法，或者第一次getConnection时，默认：0 minIdle=5最小连接池数量 maxActive=30最大连接池数量，默认：8 maxWait=60000获取连接时最大等待时间，单位毫秒。配置了maxWait之后，缺省启用公平锁，并发效率会有所下降，如果需要可以通过配置useUnfairLock属性为true使用非公平锁。 poolPreparedStatements=true是否缓存preparedStatement，也就是PSCache。PSCache对支持游标的数据库性能提升巨大，比如说oracle。在mysql下建议关闭。默认：false maxOpenPreparedStatements=20要启用PSCache，必须配置大于0，当大于0时，poolPreparedStatements自动触发修改为true。在Druid中，不会存在Oracle下PSCache占用内存过多的问题，可以把这个数值配置大一些，比如说100。默认：-1 timeBetweenEvictionRunsMillis=90000有两个含义：1) Destroy线程会检测连接的间隔时间，如果连接空闲时间大于等于minEvictableIdleTimeMillis则关闭物理连接 2) testWhileIdle的判断依据，详细看testWhileIdle属性的说明 minEvictableIdleTimeMillis=1800000连接保持空闲而不被驱逐的最长时间（单位：ms） validationQuery=SELECT 1 FROM DUAL testWhileIdle=true建议配置为true，不影响性能，并且保证安全性。申请连接的时候检测，如果空闲时间大于timeBetweenEvictionRunsMillis，执行validationQuery检测连接是否有效。默认：false testOnBorrow=false申请连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能。默认：true testOnReturn=false归还连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能。默认：false]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>alibaba</tag>
        <tag>druid</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c3p0连接池配置介绍]]></title>
    <url>%2Fposts%2F84f9d92c.html</url>
    <content type="text"><![CDATA[com.mchange.v2.c3p0.ComboPooledDataSource 参数设置 acquireIncrement -&gt; 1当连接池中的连接耗尽的时候c3p0一次同时获取的连接数。Default: 3 acquireRetryAttempts -&gt; 30定义在从数据库获取新连接失败后重复尝试的次数。Default: 30 acquireRetryDelay -&gt; 1000两次连接中间隔时间，单位毫秒。Default: 1000 autoCommitOnClose -&gt; false连接关闭时默认将所有未提交的操作回滚。Default: false automaticTestTable -&gt; nullc3p0将建一张名为Test的空表，并使用其自带的查询语句进行测试。如果定义了这个参数那么 属性 preferredTestQuery将被忽略。你不能在这张Test表上进行任何操作，它将只供c3p0测试使用。Default: null breakAfterAcquireFailure -&gt; false获取连接失败将会引起所有等待连接池来获取连接的线程抛出异常。但是数据源仍有效保留，并在下次调用getConnection() 的时候继续尝试获取连接。如果设为true，那么在尝试获取连接失败后该数据源将申明已断开并永久关闭。Default: false checkoutTimeout -&gt; 0当连接池用完时客户端调用getConnection()后等待获取新连接的时间，超时后将抛出SQLException,如设为0则无限期等待。单位毫秒。efault: 0 connectionCustomizerClassName -&gt; null定制管理Connection的生命周期 connectionTesterClassName -&gt; com.mchange.v2.c3p0.impl.DefaultConnectionTester通过实现ConnectionTester或QueryConnectionTester的类来测试连接。类名需制定全路径。Default: com.mchange.v2.c3p0.impl.DefaultConnectionTester dataSourceName -&gt; 1hgf49x9esziub21tsqy1p|17b6178 unreturnedConnectionTimeout -&gt; 0配置debug和回收Connection：单位s debugUnreturnedConnectionStackTraces -&gt; false配置debug和回收Connection description -&gt; null driverClass -&gt; oracle.jdbc.driver.OracleDriver factoryClassLocation -&gt; null指定c3p0 libraries的路径，如果（通常都是这样）在本地即可获得那么无需设置，默认null即可。Default: null forceIgnoreUnresolvedTransactions -&gt; falseStrongly disrecommended. Setting this to true may lead to subtle and bizarre bugs. 文档原文）作者强烈建议不使用的一个属性 identityToken -&gt; 1hgf49x9esziub21tsqy1p|17b6178 idleConnectionTestPeriod -&gt; 60每60秒检查所有连接池中的空闲连接。Default: 0 initialPoolSize -&gt; 5初始化时获取三个连接，取值应在minPoolSize与maxPoolSize之间。Default: 3 jdbcUrl -&gt; jdbc:oracle:thin:@localhost:1521:orcl maxAdministrativeTaskTime -&gt; 0 maxConnectionAge -&gt; 0管理连接池的大小和连接的生存时间：单位s maxIdleTime -&gt; 60最大空闲时间,60秒内未使用则连接被丢弃。若为0则永不丢弃。Default: 0 maxIdleTimeExcessConnections -&gt; 0default : 0，单位 s 。这个配置主要是为了减轻连接池的负载，比如连接池中连接数因为某次数据访问高峰导致创建了很多数据连接，但是后面的时间段需要的数据库连接数很少，则此时连接池完全没有必要维护那么多的连接，所以有必要将断开丢弃掉一些连接来减轻负载，必须小于maxIdleTime。配置不为0，则会将连接池中的连接数量保持到minPoolSize maxPoolSize -&gt; 20连接池中保留的最大连接数。Default: 15 maxStatements -&gt; 0JDBC的标准参数，用以控制数据源内加载的PreparedStatements数量。但由于预缓存的statements属于单个 connection而不是整个连接池。所以设置这个参数需要考虑到多方面的因素。如果maxStatements与 maxStatementsPerConnection均为0，则缓存被关闭。Default: 0 maxStatementsPerConnection -&gt; 0maxStatementsPerConnection定义了连接池内单个连接所拥有的最大缓存statements数。Default: 0 minPoolSize -&gt; 5初始化时获取三个连接，取值应在minPoolSize与maxPoolSize之间。Default: 3 numHelperThreads -&gt; 3c3p0是异步操作的，缓慢的JDBC操作通过帮助进程完成。扩展这些操作可以有效的提升性能 通过多线程实现多个操作同时被执行。Default: 3 numThreadsAwaitingCheckoutDefaultUser -&gt; 0 preferredTestQuery -&gt; null定义所有连接测试都执行的测试语句。在使用连接测试的情况下这个一显著提高测试速度。注意：测试的表必须在初始数据源的时候就存在。Default: null properties -&gt; {user=** password=**} propertyCycle -&gt; 0用户修改系统配置参数执行前最多等待300秒。Default: 0 testConnectionOnCheckin -&gt; false如果设为true那么在取得连接的同时将校验连接的有效性。Default: false testConnectionOnCheckout -&gt; false因性能消耗大请只在需要的时候使用它。如果设为true那么在每个connection提交的 时候都将校验其有效性。建议使用 idleConnectionTestPeriod或automaticTestTable 等方法来提升连接测试的性能。Default: false usesTraditionalReflectiveProxies -&gt; false]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>c3p0</tag>
        <tag>DataSource</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM优化]]></title>
    <url>%2Fposts%2F1a45f578.html</url>
    <content type="text"><![CDATA[阿里巴巴Dubbo框架推荐配置参数，参数值根据情况调整 1234567891011121314-server -Xmx2g -Xms2g -Xmn256m -XX:PermSize=128m -Xss256k -XX:+DisableExplicitGC -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection -XX:LargePageSizeInBytes=128m -XX:+UseFastAccessorMethods -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=70 1234567891011121314-server # 服务器模式-Xms # JVM初始分配的堆内存，一般和Xmx配置成一样，以避免每次gc后JVM重新分配内存-Xmx # JVM最大允许分配的堆内存-Xmn # 年轻代内存大小，整个JVM内存=年轻代+年老代+持久代-XX:PermSize=128m # 持久代内存大小-Xss256k # 设置每个线程的栈内存大小-XX:+DisableExplicitGC # 忽略手动调用GC，System.gc()的调用就会变成一个空调用，完全不触发GC-XX:+UseConcMarkSweepGC # 并发标记清除（CMS）收集器-XX:+CMSParallelRemarkEnabled # 降低标记停顿-XX:+UseCMSCompactAtFullCollection # 在FULLGC的时候对年老代的压缩（CMS是不会移动内存的，因此，这个非常容易产生碎片，导致内存不够用，因此，内存的压缩这个时候就会被启用。增加这个参数是个好习惯。可能会影响性能，但是可以消除碎片）-XX:LargePageSizeInBytes=128m # 内存页的大小（内存页的大小不可设置过大，会影响Perm的大小）-XX:+UseFastAccessorMethods # 原始类型的快速优化-XX:+UseCMSInitiatingOccupancyOnly # 使用手动定义初始化定义开始CMS收集（禁止hostspot自行触发CMS GC）-XX:CMSInitiatingOccupancyFraction=70 # 使用CMS作为垃圾回收，使用70%后开始CMS收集（符合公式：CMSInitiatingOccupancyFraction &lt;=((Xmx-Xmn)-(Xmn-Xmn/(SurvivorRatior+2)))/(Xmx-Xmn)*100，否则会报promontion faild错误） OmitStackTraceInFastThrow问题描述：生产环境抛异常,但却没有将堆栈信息输出到日志12345# -XX:+OmitStackTraceInFastThrow 选项在 -server 情况下默认开启。这就不难解释为何经常在系统日志中看到很多行的java.lang.NullPointerException 苦于找不到 stacktrace 而不知道错误出在何处。 遇到这种情况，解决的方法也很简单：既然在一段时间后 jvm 才会进行重新编译优化，那么该错误在刚开始出现的时候还是会有 stacktrace 的。所以向前搜索日志，或者将程序重启，观察刚重启时候的 log 便可以找到错误的 stacktrace-XX:+OmitStackTraceInFastThrow-XX:-OmitStackTraceInFastThrow PreserveFramePointer12# 如果使用 perfj 画 Flame Graph 的话，开启这个–XX:+PreserveFramePointer]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[store.js的使用]]></title>
    <url>%2Fposts%2F78a81828.html</url>
    <content type="text"><![CDATA[基于store.js实现localStorage缓存过期策略 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246"use strict";(function(s) &#123; /** * 判断是否支持localStorage本地存储 */ if (!s.enabled) &#123; console.error('localStorage is not supported by your browser.') return; &#125; /** * 规定日期格式 * 比如：yyyy年MM月dd日 HH:mm:ss S、yyyy-MM-dd HH:mm:ss S...... */ function _checkFormat(fmt) &#123; if (!/^y+[\u5e74-]?M+[\u6708-]?(d+)[\u65e5]? H+[\u65f6:]?m+[\u5206:]?s+[\u79d2]?(( S)?)$/.test(fmt)) &#123; throw new Error('"' + fmt + '" is not supported by the format.'); return false; &#125; return true; &#125; /** * 时间格式化：时间毫秒数、Date对象 ---&gt; 时间字符串 默认格式化格式：yyyy-MM-dd HH:mm:ss */ function _date2str(str, fmt) &#123; if (fmt === undefined) &#123; fmt = 'yyyy-MM-dd HH:mm:ss'; &#125; _checkFormat(fmt); var date; if (typeof str === 'number') &#123; date = new Date(str); &#125; else if (_isValidDate(str)) &#123; date = str; &#125; var o = &#123; 'M+' : date.getMonth() + 1, // 月 'd+' : date.getDate(), // 日 'H+' : date.getHours(), // 小时（24小时制） 'm+' : date.getMinutes(), // 分 's+' : date.getSeconds(), // 秒 'S' : date.getMilliseconds() // 毫秒 &#125;; if (/(y+)/.test(fmt)) &#123; fmt = fmt.replace(RegExp.$1, (date.getFullYear() + '') .substr(4 - RegExp.$1.length)); &#125; for ( var k in o) &#123; if (new RegExp('(' + k + ')').test(fmt)) &#123; fmt = fmt.replace(RegExp.$1, (RegExp.$1.length == 1) ? (o[k]) : (('00' + o[k]).substr(('' + o[k]).length))); &#125; &#125; return fmt; &#125; /** * 时间格式化：将时间字符串 ---&gt; Date对象 默认格式化格式：yyyy-MM-dd HH:mm:ss，使用中文不能格式化 */ function _str2date(str, fmt) &#123; if (fmt === undefined) &#123; fmt = 'yyyy-MM-dd HH:mm:ss'; &#125; _checkFormat(fmt); var o = [ 'y+', // 年 'M+', // 月 'd+', // 日 'H+', // 小时（24小时制） 'm+', // 分 's+', // 秒 'S' // 毫秒 ]; var date = new Date(); for (var k = 0; k &lt; o.length; k++) &#123; var s = o[k]; if (new RegExp('(' + s + ')').test(fmt)) &#123; var r = RegExp.$1; var rl = RegExp.$1.length; var si = fmt.indexOf(RegExp.$1); var ei = si + rl; var n = 0; if (r.indexOf('S') &gt; -1) &#123; n = parseInt(str.substr(si)); date.setMilliseconds(n); // 设置 Date 对象中的毫秒 (0 ~ 999)。 &#125; else &#123; n = parseInt(str.substring(si, ei)); if (r.indexOf('y') &gt; -1) &#123; date.setFullYear(n); // 设置 Date 对象中的年份（四位数字）。 &#125; else if (r.indexOf('M') &gt; -1) &#123; date.setMonth(n - 1); // 设置 Date 对象中月份 (0 ~ 11)。 &#125; else if (r.indexOf('d') &gt; -1) &#123; date.setDate(n); // 设置 Date 对象中月的某一天 (1 ~ 31)。 &#125; else if (r.indexOf('H') &gt; -1) &#123; date.setHours(n); // 设置 Date 对象中的小时 (0 ~ 23)。 &#125; else if (r.indexOf('m') &gt; -1) &#123; date.setMinutes(n); // 设置 Date 对象中的分钟 (0 ~ 59)。 &#125; else if (r.indexOf('s') &gt; -1) &#123; date.setSeconds(n); // 设置 Date 对象中的秒钟 (0 ~ 59)。 &#125; &#125; &#125; &#125; return date; &#125; /** * 转换：毫秒 ---&gt; 天时分秒毫秒 */ function _ms2s(ms) &#123; var s = parseInt(ms / 1000);// 秒 var m = 0;// 分 var h = 0;// 小时 var d = 0;// 天 if (s &gt;= 60) &#123; m = parseInt(s / 60); s = parseInt(s % 60); if (m &gt;= 60) &#123; h = parseInt(m / 60); m = parseInt(m % 60); if (h &gt;= 24) &#123; d = parseInt(h / 24); h = parseInt(h % 24); &#125; &#125; &#125; var str = ''; if (s &gt; 0) str = '' + parseInt(s) + '\u79d2' + str; if (m &gt; 0) str = '' + parseInt(m) + '\u5206' + str; if (h &gt; 0) str = '' + parseInt(h) + '\u5c0f\u65f6' + str; if (d &gt; 0) str = '' + parseInt(d) + '\u5929' + str; return str; &#125; /** * 设置有效时间，返回对象 */ function VConstructor(val, exp) &#123; var item = &#123;&#125;; // 创建时间、有效时间 var createTime = (new Date()).getTime(), effectiveTime; if (typeof exp === 'number') &#123; effectiveTime = new Date(createTime + exp * 60000); &#125; else if (typeof exp === 'string') &#123; effectiveTime = _str2date(exp); &#125; if (effectiveTime &amp;&amp; !_isValidDate(effectiveTime)) &#123; throw new Error('effectiveTime cannot be converted to a valid Date instance'); &#125; effectiveTime = effectiveTime.getTime(); item['c'] = _date2str(createTime); item['e'] = _date2str(effectiveTime); item['t'] = _ms2s(effectiveTime - createTime); item['v'] = val; return item; &#125; /** * 判断是否是Date对象 */ function _isValidDate(date) &#123; return Object.prototype.toString.call(date) === '[object Date]' &amp;&amp; !isNaN(date.getTime()); &#125; /** * 判断是否设置了有效时间 */ function _hasEffective(item) &#123; if (item) &#123; if (typeof item === 'object' &amp;&amp; 'c' in item &amp;&amp; 'e' in item &amp;&amp; 'v' in item) &#123; return true; &#125; &#125; return false; &#125; /** * 判断是否是有效 */ function _isEffective(item) &#123; var ntime = (new Date()).getTime(); return ntime &lt; _str2date(item.e); &#125; /** * 判断key是否是字符串，如果不是，则转换成字符串 */ function _keyAsString(key) &#123; if (typeof key !== 'string') &#123; console.warn(key + ' used as a key, but it is not a string.'); key = String(key); &#125; return key; &#125; /** * exp 失效时间：默认为0（单位：分钟） */ s.setExp = function(key, val, exp) &#123; key = _keyAsString(key); if (exp === undefined) &#123; exp = 0; &#125; s.set(key, new VConstructor(val, exp)); &#125;; s.getExp = function(key) &#123; key = _keyAsString(key); var item = null; try &#123; item = s.get(key); &#125; catch (e) &#123; return null; &#125; if (_hasEffective(item)) &#123; if (_isEffective(item)) &#123; return item.v; &#125; else &#123; s.remove(key); return null; &#125; &#125; else &#123; return item; &#125; &#125;; s.getAllExp = function() &#123; var ret = &#123;&#125;; s.forEachExp(function(key, val) &#123; ret[key] = val; &#125;) return ret; &#125;; s.forEachExp = function(callback) &#123; var storage = s.getAll(); for ( var key in storage) &#123; callback(key, s.getExp(key)); &#125; &#125;;&#125;)(store);]]></content>
      <categories>
        <category>Javascript</category>
      </categories>
      <tags>
        <tag>localStorage</tag>
        <tag>store.js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用RSA注意事项]]></title>
    <url>%2Fposts%2Fef742936.html</url>
    <content type="text"><![CDATA[比较以下两种写法 第一种：这种写法会造成内存溢出 1Cipher cipher = Cipher.getInstance("RSA", new BouncyCastleProvider()); 第二种：推荐这种写法 12345// BC 可用 BouncyCastleProvider.PROVIDER_NAME 代替if (StringUtils.isNullOrEmpty(Security.getProperty("BC"))) &#123; Security.addProvider(new BouncyCastleProvider());&#125;Cipher cipher = Cipher.getInstance("RSA", "BC"); 还有一种写法是要替换jdk的jar包，不推荐 要依赖bcprov-jdk16包12345&lt;dependency&gt; &lt;groupId&gt;org.bouncycastle&lt;/groupId&gt; &lt;artifactId&gt;bcprov-jdk16&lt;/artifactId&gt; &lt;version&gt;1.46&lt;/version&gt;&lt;/dependency&gt;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>RSA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch踩坑]]></title>
    <url>%2Fposts%2F19540ce1.html</url>
    <content type="text"><![CDATA[问题一 max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]配置 /etc/sysctl.conf 12$ vi /etc/sysctl.confvm.max_map_count=262144 生效 1$ sysctl -p 验证1$ sysctl -a|grep vm.max_map_count 问题二 max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]max number of threads [1024] for user [XXX] is too low，increase to least [2048]1、修改 nofile 时候，需要在 /etc/sysctl.conf 和 /etc/security/limits.conf 配置，其中 /etc/sysctl.conf 中配置的值需要比 /etc/security/limits.conf 的值大 。 配置 /etc/sysctl.conf 12$ vi /etc/sysctl.conf fs.file-max = 512000 生效1$ sysctl -p 配置 /etc/security/limits.conf12$ vi /etc/security/limits.confelasticsearch - nofile 65536 或者1* - nofile 65536 2、修改 nofile 和 nprocCentOS 7 的 nproc 的修改在 /etc/security/limits.d/20-nproc.conf，为了方便在 /etc/security/limits.conf 和 /etc/security/limits.d/20-nproc.conf 文件里面同时都添加了 。 配置 /etc/security/limits.conf 12$ vi /etc/security/limits.conf* - nproc 65536 配置 /etc/security/limits.d/20-nproc.conf123$ vi /etc/security/limits.d/20-nproc.conf* - nofile 65536* - nproc 65536 重启系统，验证1$ ulimit -Hn 总结：1234567891011$ vi /etc/sysctl.confvm.max_map_count=262144fs.file-max=512000$ vi /etc/security/limits.confelasticsearch - nofile 65536* - nproc 65536$ vi /etc/security/limits.d/20-nproc.conf* - nofile 65536* - nproc 65536]]></content>
      <categories>
        <category>elk</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装、配置 Elasticsearch]]></title>
    <url>%2Fposts%2F4c158d.html</url>
    <content type="text"><![CDATA[安装Elasticsearch 下载并安装 .zip 包 1234wget https://artifacts.elastic.cn/downloads/elasticsearch/elasticsearch-5.0.2.zipsha1sum elasticsearch-5.0.2.zipunzip elasticsearch-5.0.2.zipcd elasticsearch-5.0.2/ 下载并安装 .tar.gz 包 1234wget https://artifacts.elastic.cn/downloads/elasticsearch/elasticsearch-5.0.2.tar.gzsha1sum elasticsearch-5.0.2.tar.gztar -zxvf elasticsearch-5.0.2.tar.gzcd elasticsearch-5.0.2/ 运行 Elasticsearch1./bin/elasticsearch Window 系统也是一样。默认的，Elasticsearch 运行在前台，并且打印日志，可以通过 ctrl+c 来停止它的运行。Windows 系统还可以通过 elasticsearch-service.bat 命令来将 Elasticsearch 注册为一个服务。你可以在浏览器打开 localhost:9200，来查看 Elasticsearch 是否运行。日志输出可以通过 -q 或者 -quiet 选项来禁止。将 Elasticsearch 当做守护进程来运行1./bin/elasticsearch -d -p pid 日志信息记录在 $ES_HOME/logs/，proces id 会记录在 pid 文件。停止 Elasticsearch 使用如下命令：1kill &apos;cat pid&apos; 配置 ElasticsearchElasticsearch 默认从 $ES_HOME/config/elasticsearch.yml 加载配置文件。配置文件中的配置都可以通过命令来设定，使用 -E 语法：1./bin/elasticsearch -d -Ecluster.name=my_cluster -Enode.name=node_1 如果值中带有空格，在值必须使用””包囊起来。一般，集群层面的配置（例如：cluster.name）应该添加到 elasticsearch.yml 文件，近点层面的设置（例如：node.name）可以通过命令来设置。 3.1 重要的系统配置启动 elasticsearch 时候遇到 nofile、nproc、jvm 等报错 3.2 设置 JVM 参数首选的设置JVM参数的方法是通过 config/jvm.options 配置文件（使用 .zip 或者 .tar.gz 安装包时），/etc/elasticsearch/jvm.options（当使用 Debian 或者 RPM 安装包时）。JVM 参数必须以 - 开始，你可以添加自定义JVM标识并且把这个配置上传到你的版本控制系统。 默认的 Elasticsearch 设置的 JVM 内存大小为2GB，当向生产环境部署时要确定 Elasticsearch 有足够的内存可用。好的规则是： 设置-Xms与-Xmx相等 注意太大的内存容易产生长的垃圾回收停顿 -Xmx不要超过你物理内存的50% 不要设置-Xmx超过JVM用来压缩对象指针的大小，精确的临界值不是固定的，但是接近于32GB。 下面是设置JVM内存大小的例子：12-Xms2g -Xmx2g 3.3 禁止内存交换大多数操作系统会用尽可能多的内存用于文件系统缓存和及早换出无用的应用内存。这可能导致一部分JVM内存被交换到硬盘上。 这种内存交换非常不利于性能和节点的稳定性。应该竭尽所能来避免这种情况。它能引起垃圾回收持续长达数分钟而不是几毫秒并且能导致节点响应缓慢甚至与集群失去联系。 这里有三种方法来禁止内存交换： 启用 bootstrap.memory_lock通过使用 Linux/Unix 系统的 mlockall 或者 Windows 系统的 VirtualLock 尝试锁定 RAM 中的进程地址空间，防止任何 Elasticsearch 内存被交换。可以通过向 config/elasticsearch.yml 文件中添加以下语句来实现：1bootstrap.memory_lock: true 警告：mlockall 如果尝试分配超过了可用的内存，可能会引起 JVM 或者 shell session 退出。在启动E lasticsearch 后，你可以检查下设置是否生效了，可以通过检查下面请求响应中的 mlockall 值：1GET _nodes?filter_path=**.mlockall 如果你看到 mlockall 是 false，那说明禁止内存交换失败了。并且日志里会看到类似下面的话：Unable to lock JVM Memory. 最可能的原因是，在Linux/Unix操作系统，用户运行的Elasticsearch没有锁定内存的权限。可以通过下面的方法来解决： 使用 .zip 和 .tar.gz 这种安装包时，在 /etc/security/limits.conf 文件中设置 memlock 为 unlimited。 其他方式就不翻译了。 RPM and DebianSet MAX_LOCKED_MEMORY to unlimited in the system configuration file (or see below for systems using systemd).Systems using systemdSet LimitMEMLOCK to infinity in the systemd configuration. 还有一种 mlockall 可能失败的情况是临时文件夹（通常是 /tmp ）挂载时设定了 noexec 选项。这种情况可以通过指定一个新的临时文件夹来解决，使用 ES_JAVA_OPTS 环境变量：12export ES_JAVA_OPTS=&quot;$ES_JAVA_OPTS -Djava.io.tmpdir=/path/to/temp/dir&quot;./bin/elasticsearch 或者在 jvm.options 配置文件里设置。 禁止所有文件交换第二种禁止内存交换的方式是完全禁止交换。通常 Elasticsearch 是一台服务器唯一运行的服务，它的内存使用被JVM控制着，所以没有必要允许交换。 在 Linux 系统你可以通过运行以下代码禁止内存交换：1sudo swapoff -a 如果要永久禁用，则需要编辑 /etc/fstab 文件，然后注释掉所有包含 swap 的行。 在 Windows 系统可以通过系统属性 → 高级系统设置 → 性能 → 高级选项卡 → 虚拟内存 然后设置为无分页文件。（Windows 7） 3.4 文件描述符这个设置只针对 Linux 和 macOS 操作系统，如果运行在 Windows 系统则可以安全的被忽略。 Elasticsearch 使用了大量的文件描述符或者文件句柄。文件描述符将要被用完时会导致灾难性的后果，并且非常可能引起数据丢失。确保增加运行 Elasticsearch 的用户打开文件描述符的数量至少为65,536或者更高。 对于 .zip 和 .tar.gz 安装包，在启动 Elasticsearch 前以root身份设置ulimit -n 65536，或者修改 /etc/security/limits.conf 文件，设置 nofile 参数为65536或更高。 RPM 和 Debian 的安装包已经设置了默认最大文件描述符数为65536，不需要额外配置。 你可以检查每个节点的 max_file_descriptors 配置情况：1GET _nodes/stats/process?filter_path=**.max_file_descriptors 3.5 虚拟内存Elasticsearch 默认使用一个 hybrid mmapfs/niofs 来存储它的索引。操作系统默认限制的内存映射数是比较低的，可能会引起内存溢出异常。 在 Linux，你可以用 root 身份通过以下命令来增加这个限制：1sysctl -w vm.max_map_count=262144 要想永久的增加 vm.max_map_count 设置，需要编辑 /etc/sysctl.conf 文件。重启后通过：1sysctl vm.max_map_count 来检验设置是否生效 RPM 和 Debian安装包将会自动设置这个配置。不需要额外的操作。 3.6 线程数Elasticsearch 使用多个线程池来进行不同类型的操作。当需要时能够创建新线程是很重要的。确保 Elasticsearch 用户能创建的线程数最少为2048个。 可以在启动前通过设置 ulimit -u 2048，或者在 /etc/security/limits.conf 文件里设置 nproc 为2048。]]></content>
      <categories>
        <category>elk</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装、配置 kibana]]></title>
    <url>%2Fposts%2F33aa0af8.html</url>
    <content type="text"><![CDATA[Kibana 是一个基于浏览器页面的 Elasticsearch 前端展示工具。Kibana 全部使用 HTML 语言和 JavaScript 编写的。Kibana 是一个为 Logstash 和 ElasticSearch 提供的日志分析的 Web 接口。可使用它对日志进行高效的搜索、可视化、分析等各种操作。 1、配置编辑1vi config/kibana.yml 按照要求修改为1elasticsearch.url: "http://192.168.56.101:9200" 其他部分参数不修改 如果只允许本机可以访问，在 kibana.yml 中加入：1host: "127.0.0.1" 2、启动kibana 5.2.1 可以单独启动，命令1bin/kibana 后台运行1nohup bin/kibana &amp; 访问http://localhost:5601]]></content>
      <categories>
        <category>elk</category>
      </categories>
      <tags>
        <tag>kibana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis整合spring boot]]></title>
    <url>%2Fposts%2Fec4f6c67.html</url>
    <content type="text"><![CDATA[在pom.xml加入如下内容12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt;&lt;/dependency&gt; mybatis-config.xml123456789101112131415161718&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;typeAliases&gt; &lt;typeAlias alias="Integer" type="java.lang.Integer"/&gt; &lt;typeAlias alias="Long" type="java.lang.Long"/&gt; &lt;typeAlias alias="HashMap" type="java.util.HashMap"/&gt; &lt;typeAlias alias="LinkedHashMap" type="java.util.LinkedHashMap"/&gt; &lt;typeAlias alias="ArrayList" type="java.util.ArrayList"/&gt; &lt;typeAlias alias="LinkedList" type="java.util.LinkedList"/&gt; &lt;/typeAliases&gt; &lt;typeAliases&gt; &lt;package name="top.ylonline.wechat.job.pojo"/&gt; &lt;/typeAliases&gt; &lt;mappers&gt; &lt;mapper resource="top/ylonline/wechat/job/mapper/UserMapper.xml"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 或者在application.yml中加入12345mybatis: config-location: classpath:mybatis/mybatis-config.xml type-aliases-package: top.ylonline.wechat.job.pojo# mapper-locations 这个配置参数仅当mapper xml与mapper class不在同一个目录下时有效。所以一般可以忽略。# mapper-locations: classpath:top/ylonline/wechat/job/mapper/*.xml 在Mapper类上面使用 @Mapper 注解1234@Mapperpublic interface UserMapper &#123; long count(User user);&#125; Mapper.xml配置123456789101112131415&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd" &gt;&lt;mapper namespace="top.ylonline.wechat.job.mapper.UserMapper"&gt; &lt;resultMap id="BaseResultMap" type="top.ylonline.wechat.job.pojo.User"&gt; &lt;constructor&gt; &lt;arg column="ID" javaType="java.math.BigDecimal" jdbcType="DECIMAL"/&gt; &lt;arg column="AGE" javaType="java.math.BigDecimal" jdbcType="DECIMAL"/&gt; &lt;arg column="CITYID" javaType="java.math.BigDecimal" jdbcType="DECIMAL"/&gt; &lt;/constructor&gt; &lt;/resultMap&gt; &lt;select id="count" parameterType="top.ylonline.wechat.job.pojo.User" resultType="java.lang.Long"&gt; select count(*) from user where cityid = #&#123;user.cityid&#125; &lt;/select&gt;&lt;/mapper&gt;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[logback 多环境配置]]></title>
    <url>%2Fposts%2F7bd4851.html</url>
    <content type="text"><![CDATA[在 logback.xml中使用:- 12&lt;!-- $&#123;变量名:-默认值&#125; --&gt;&lt;property name="logger.path" value="$&#123;catalina.home:-./..&#125;/logs"/&gt; application.yml 配置 profiles 123spring: profiles: active: dev 在使用 logback-spring.xml 中使用 springProfile 配置，使用 logback-spring.xml 可以获得更多spring boot个性化配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!-- For assistance related to logback-translator or configuration --&gt;&lt;!-- files in general, please contact the logback user mailing list --&gt;&lt;!-- at http://www.qos.ch/mailman/listinfo/logback-user --&gt;&lt;!-- --&gt;&lt;!-- For professional support please see --&gt;&lt;!-- http://www.qos.ch/shop/products/professionalSupport --&gt;&lt;!-- --&gt;&lt;configuration scan="true" scanPeriod="60 seconds" debug="false"&gt; &lt;property name="logger.charset" value="UTF-8"/&gt; &lt;property name="logger.path" value="$&#123;catalina.home&#125;/logs"/&gt; &lt;property name="logger.pattern" value="[%d&#123;yyyy-MM-dd HH:mm:ss&#125; %highlight(%-5p)] %yellow(%t) %cyan(%c.%M\\(%L\\)) | %m%n"/&gt; &lt;property name="logger.maxHistory" value="15"/&gt; &lt;!--&amp;lt;!&amp;ndash; https://logback.qos.ch/manual/layouts.html#coloring &amp;ndash;&amp;gt; &amp;lt;!&amp;ndash; 彩色日志依赖的渲染类 &amp;ndash;&amp;gt; &lt;conversionRule conversionWord="clr" converterClass="org.springframework.boot.logging.logback.ColorConverter" /&gt; &lt;conversionRule conversionWord="wex" converterClass="org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter" /&gt; &lt;conversionRule conversionWord="wEx" converterClass="org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter" /&gt; &amp;lt;!&amp;ndash; 彩色日志格式 &amp;ndash;&amp;gt; &lt;property name="logger.pattern" value="$&#123;CONSOLE_LOG_PATTERN:-%clr([%d&#123;yyyy-MM-dd HH:mm:ss&#125; %clr($&#123;LOG_LEVEL_PATTERN:-%5p&#125;)])&#123;faint&#125; %clr(%c.%M\\(%L\\))&#123;cyan&#125; | %m%n&#125;" /&gt;--&gt; &lt;springProfile name="dev"&gt; &lt;appender name="stdout" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder charset="$&#123;logger.charset&#125;"&gt; &lt;pattern&gt;$&#123;logger.pattern&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level="info"&gt; &lt;appender-ref ref="stdout"/&gt; &lt;/root&gt; &lt;/springProfile&gt; &lt;springProfile name="prod"&gt; &lt;appender name="stdout" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;File&gt;$&#123;logger.path&#125;/info.log&lt;/File&gt; &lt;encoder charset="$&#123;logger.charset&#125;"&gt; &lt;pattern&gt;$&#123;logger.pattern&#125;&lt;/pattern&gt; &lt;/encoder&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt; $&#123;logger.path&#125;/info.log.%d&#123;yyyy.MM.dd&#125; &lt;/fileNamePattern&gt; &lt;maxHistory&gt;$&#123;logger.maxHistory&#125;&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;root level="info"&gt; &lt;appender-ref ref="stdout"/&gt; &lt;/root&gt; &lt;/springProfile&gt;&lt;/configuration&gt;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>logback</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring boot 定时器]]></title>
    <url>%2Fposts%2F6710625f.html</url>
    <content type="text"><![CDATA[在pom.xml中加入 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.5.2.RELEASE&lt;/version&gt;&lt;/dependency&gt; 定时器类12345678910111213@Componentpublic class ArticleSummaryScheduled &#123; // 等同于fixedRate @Scheduled(cron = "0/15 * * * * ?") // 上一次开始执行时间点之后6s再次执行 // @Scheduled(fixedRate = 6000) // 上一次执行完毕时间点之后6s再次执行 // @Scheduled(fixedDelay = 6000) public void process() &#123; System.out.println(new Date()); &#125;&#125; 在main方法类上面使用 @EnableScheduling 注解12345678@SpringBootApplication// 定时器启动类@EnableSchedulingpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 只要上面的配置，就可以启动一个定时器了]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
        <tag>task</tag>
        <tag>schedule</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 Firewall防火墙配置]]></title>
    <url>%2Fposts%2F9af5b5dc.html</url>
    <content type="text"><![CDATA[一、firewall介绍CentOS 7中防火墙是一个非常的强大的功能，对CentOS 6.5中的iptables防火墙进行了升级了。 二、firewall配置1、系统配置目录1/usr/lib/firewalld/services 目录中存放定义好的网络服务和端口参数，系统参数，不能修改。 2、用户配置目录1/etc/firewalld/ 3、如何自定义添加端口用户可以通过修改配置文件的方式添加端口，也可以通过命令的方式添加端口，注意，修改的内容会在/etc/firewalld/目录下的配置文件中还体现。 3.1、命令的方式123456firewall-cmd --permanent --add-port=9527/tcpfirewall-cmd --permanent --add-port=8080-9000/tcp# 删除规则firewall-cmd --permanent --remove-port=9527/tcpfirewall-cmd --permanent --remove-port=8080-9000/tcp 参数介绍：1、firewall-cmd：是Linux提供的操作firewall的一个工具2、–permanent：表示设置为持久3、–add-port：标识添加的端口 另外，firewall 中有 Zone 的概念，可以将具体的端口制定到具体的 zone 配置文件中。 例如：添加 8010 端口1firewall-cmd --zone=public --permanent --add-port=8010/tcp --zone=public指定的zone为public 添加规则12345$ firewall-cmd --permanent \ --zone=public \ --add-rich-rule="rule family="ipv4" source \ address="192.168.0.4/24" \ service name="http" accept" 删除上面配置的规则12345$ firewall-cmd --permanent \ --zone=public \ --remove-rich-rule="rule family="ipv4" source \ address="192.168.0.4/24" \ service name="http" accept" You can check if the port has actually be opened by runningfirewall-cmd –zone= –query-port=80/tcpfirewall-cmd –zone= –query-service=http 3.2、文件的方式123456789101112131415161718192021&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;zone&gt; &lt;short&gt;Public&lt;/short&gt; &lt;description&gt;For use in public areas. You do not trust the other computers on networks to not harm your computer. Only selected incoming connections are accepted.&lt;/description&gt; &lt;!-- 放通指定ip，指定端口、协议 --&gt; &lt;rule family="ipv4"&gt; &lt;source address="192.168.56.101"/&gt; &lt;port protocol="udp" port="555"/&gt; &lt;accept/&gt; &lt;/rule&gt; &lt;rule family="ipv4"&gt; &lt;source address="192.168.56.101"/&gt; &lt;port protocol="tcp" port="9200-9300"/&gt; &lt;accept/&gt; &lt;/rule&gt; &lt;!-- 放通任意ip访问服务器的8081端口 --&gt; &lt;rule family="ipv4"&gt; &lt;port protocol="tcp" port="8081"/&gt; &lt;accept/&gt; &lt;/rule&gt;&lt;/zone&gt; 上述的一个配置文件可以很好的看出：1231、添加需要的规则，开放通源ip为192.168.56.101，端口555，协议tcp2、开放通源ip为192.168.56.101，端口9200-9300，协议tcp3、开放通源ip为任意，端口8081，协议tcp 三、firewall常用命令常用命令介绍12345678910firewall-cmd --state #查看防火墙状态，是否是runningfirewall-cmd --reload #重新载入配置，比如添加规则之后，需要执行此命令firewall-cmd --get-zones #列出支持的zonefirewall-cmd --get-services #列出支持的服务，在列表中的服务是放行的firewall-cmd --query-service ftp #查看ftp服务是否支持，返回yes或者nofirewall-cmd --add-service=ftp #临时开放ftp服务firewall-cmd --add-service=ftp --permanent #永久开放ftp服务firewall-cmd --remove-service=ftp --permanent #永久移除ftp服务firewall-cmd --add-port=80/tcp --permanent #永久添加80端口 iptables -L -n #查看规则，这个命令是和iptables的相同的 重启、关闭、开启firewalld服务123456systemctl start firewalld # 启动systemctl stop firewalld # 关闭systemctl restart firewalld # 重启systemctl enable firewalld # 开机启动systemctl disable firewalld # 取消开机启动 四、CentOS切换为iptables防火墙本节略]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Firewall</tag>
        <tag>iptables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 部署 FTP 服务]]></title>
    <url>%2Fposts%2F9c4dd72b.html</url>
    <content type="text"><![CDATA[安装vsftpd 检测是否已经安装vsftpd 123$ rpm -qa|grep vsftpd# 有打印信息说明已经安装，信息格式如下：vsftpd-3.0.2-27.el7.x86_64 如果已经安装，则可以更新，或者删除重新安装 安装 123456# 使用 yum 安装 vsftpd$ yum install vsftpd# 设置开机启动vsftpd服务$ chkconfig vsftpd on# 启动vsftpd服务$ service vsftpd start 配置防火墙 123456# 打开/etc/sysconfig/iptables文件vi /etc/sysconfig/iptables # 在REJECT行之前添加如下代码-A RH-Firewall-1-INPUT -m state --state NEW -m tcp -p tcp --dport 21 -j ACCEPT# 保存和关闭文件，重启防火墙service iptables restart vsftpd配置 在/etc/vsftpd/vsftpd.conf文件修改以下配置 123456# 禁止匿名用户anonymous登录anonymous_enable=NO# 设置的文件里，是被chroot的用户(无法向上改变目录)chroot_local_user=YES# 500 OOPS: vsftpd: refusing to run with writable root inside chroot()错误解决allow_writeable_chroot=YES 创建用户12345678910111213# 创建用户sudo useradd test_user -s /sbin/nologin# 为用户配置密码，按提示输入两遍密码即可sudo passwd test_user# 查看默认密码过期时间vi /etc/login.defs# 修改密码过期时间sudo chage -M 99999 test_user# 在用户目录下创建目录文件，并赋权给用户sudo mkdir -p /home/test_user/test_dirsudo chown test_user:test_user /home/test_user/test_dir 删除用户12# 删除用户，会连带/home/test_user目录一起删除userdel -rf test_user 常用命令12345678910111213141516171819202122# 启动 ftp 服务sudoservice vsftpd start# 查看 ftp 服务状态sudoservice vsftpd status # 重启 ftp 服务sudoservice vsftpd restart# 关闭 ftp 服务sudoservice vsftpd stop# 在 CentOS 7.x版本使用以下命令# 启动 ftp 服务sudo systemctl start vsftpd.service# 查看 ftp 服务状态sudo systemctl status vsftpd.service# 重启 ftp 服务sudo systemctl restart vsftpd.service# 关闭 ftp 服务sudo systemctl stop vsftpd.service# 开机启动sudo systemctl enable vsftpd.service# 禁止开机启动sudo systemctl disable vsftpd.service]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>CentOS</tag>
        <tag>vsftpd</tag>
        <tag>FTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS安装JDK]]></title>
    <url>%2Fposts%2Fd08f134.html</url>
    <content type="text"><![CDATA[1、准备创建目录12$ mkdir /usr/java$ cd /usr/java 下载 jdk-8u73-linux-x64.tar.gz，解压1$ tar -zxvf jdk-8u73-linux-x64.tar.gz 会解压到 /usr/java/jdk1.8.0_73 下 2、配置环境变量(两种方式二选一配置即可)2.1 编辑 /etc/profile 文件修改 /etc/profile 文件当本机仅仅作为开发使用时推荐使用这种方法，因为此种配置时所有用户的 shell 都有权使用这些环境变量，可能会给系统带来安全性问题。1$ vi /etc/profile 增加如下内容123export JAVA_HOME=/usr/java/jdkexport PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$CLASSPATH 保存退出 :wq12$ . /etc/profile$ echo $JAVA_HOME 2.2 编辑用户目录下的 .bash_profile修改 .bash_profile 文件这种方法更为安全，它可以把使用这些环境变量的权限控制到用户级别，如果需要给某个用户权限使用这些环境变量，只需要修改其个人用户主目录下的 .bash_profile 文件就可以了123export JAVA_HOME=/usr/java/jdkexport PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$CLASSPATH 然后执行使之生效1source .bash_profile 可以看到 JAVA_HOME 不是指向真实的 jdk 目录 /usr/java/jdk1.8.0_73，而是指向 /usr/java/jdk 3、创建软链接为jdk真实目录创建一个命名更加间洁快捷方式123$ ln -s /usr/java/jdk1.8.0_73 /usr/java/jdk$ source /etc/profile#$ source .bash_profile 至此，配置完成]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JDK</tag>
      </tags>
  </entry>
</search>
